{
  "canonical_to_index": {
    "<NONE>": 0,
    "<PAD>": 1,
    "<DATA_INPUT>": 2,
    "<PARAM_INPUT>": 3,
    "<OUTPUT>": 4,
    "<CONST_REF>": 5,
    "<PATTERN_PREFIX>": 6,
    "<COPY_PREFIX>": 7,
    "<CONTROL_FLOW_PREFIX>": 8,
    "<RESERVED>": 9,
    "aten.slice.Tensor:node_args(1):kwargs()": 10,
    "aten.embedding.default:node_args(2):kwargs()": 11,
    "aten.add.Tensor:node_args(2):kwargs()": 12,
    "aten.layer_norm.default:node_args(3):kwargs()": 13,
    "aten.dropout.default:node_args(1):kwargs()": 14,
    "aten.unsqueeze.default:node_args(1):kwargs()": 15,
    "aten.expand.default:node_args(1):kwargs()": 16,
    "aten._to_copy.default:node_args(1):kwargs('dtype',)": 17,
    "aten.lift_fresh_copy.default:node_args(1):kwargs()": 18,
    "aten.detach.default:node_args(1):kwargs()": 19,
    "aten.sub.Tensor:node_args(2):kwargs()": 20,
    "aten.masked_fill.Scalar:node_args(2):kwargs()": 21,
    "aten.linear.default:node_args(3):kwargs()": 22,
    "aten.view.default:node_args(1):kwargs()": 23,
    "aten.transpose.int:node_args(1):kwargs()": 24,
    "aten.scaled_dot_product_attention.default:node_args(4):kwargs()": 25,
    "aten.gelu.default:node_args(1):kwargs()": 26,
    "aten.select.int:node_args(1):kwargs()": 27,
    "aten.tanh.default:node_args(1):kwargs()": 28,
    "aten.ne.Scalar:node_args(1):kwargs()": 29,
    "aten.cumsum.default:node_args(1):kwargs()": 30,
    "aten.type_as.default:node_args(2):kwargs()": 31,
    "aten.add.Tensor:node_args(1):kwargs()": 32,
    "aten.mul.Tensor:node_args(2):kwargs()": 33,
    "aten.eq.Scalar:node_args(1):kwargs()": 34,
    "aten.sum.dim_IntList:node_args(1):kwargs()": 35,
    "aten.div.Tensor:node_args(1):kwargs()": 36,
    "aten.mul.Tensor:node_args(1):kwargs()": 37,
    "aten.rsub.Scalar:node_args(1):kwargs()": 38,
    "aten.div.Tensor:node_args(2):kwargs()": 39,
    "aten.arange.default:node_args(0):kwargs('device', 'pin_memory')": 40,
    "aten.outer.default:node_args(2):kwargs()": 41,
    "aten.cat.default:node_args(1):kwargs()": 42,
    "aten._to_copy.default:node_args(1):kwargs('device', 'dtype', 'layout')": 43,
    "aten.cos.default:node_args(1):kwargs()": 44,
    "aten.sin.default:node_args(1):kwargs()": 45,
    "aten.split.Tensor:node_args(1):kwargs()": 46,
    "<built-in function getitem>:node_args(1):kwargs()": 47,
    "aten.neg.default:node_args(1):kwargs()": 48,
    "aten.cat.default:node_args(2):kwargs()": 49,
    "aten.scaled_dot_product_attention.default:node_args(4):kwargs('scale',)": 50,
    "aten.erf.default:node_args(1):kwargs()": 51,
    "aten.linear.default:node_args(2):kwargs()": 52,
    "aten.matmul.default:node_args(2):kwargs()": 53,
    "aten.softmax.int:node_args(1):kwargs()": 54,
    "aten.permute.default:node_args(1):kwargs()": 55,
    "aten.clone.default:node_args(1):kwargs('memory_format',)": 56,
    "aten.arange.start:node_args(0):kwargs('device', 'pin_memory')": 57,
    "aten.full.default:node_args(0):kwargs('device', 'dtype', 'pin_memory')": 58,
    "aten.triu.default:node_args(1):kwargs()": 59,
    "aten.gt.Tensor:node_args(2):kwargs()": 60,
    "aten.clone.default:node_args(1):kwargs()": 61,
    "aten.copy.default:node_args(2):kwargs()": 62,
    "aten.slice_scatter.default:node_args(2):kwargs()": 63,
    "aten.where.self:node_args(3):kwargs()": 64,
    "aten.pow.Tensor_Scalar:node_args(1):kwargs()": 65,
    "aten.conv2d.default:node_args(2):kwargs()": 66,
    "aten._native_batch_norm_legit_no_training.default:node_args(5):kwargs()": 67,
    "aten.relu.default:node_args(1):kwargs()": 68,
    "aten.max_pool2d.default:node_args(1):kwargs()": 69,
    "aten.adaptive_avg_pool2d.default:node_args(1):kwargs()": 70
  },
  "index_to_canonical": {
    "0": "<NONE>",
    "1": "<PAD>",
    "2": "<DATA_INPUT>",
    "3": "<PARAM_INPUT>",
    "4": "<OUTPUT>",
    "5": "<CONST_REF>",
    "6": "<PATTERN_PREFIX>",
    "7": "<COPY_PREFIX>",
    "8": "<CONTROL_FLOW_PREFIX>",
    "9": "<RESERVED>",
    "10": "aten.slice.Tensor:node_args(1):kwargs()",
    "11": "aten.embedding.default:node_args(2):kwargs()",
    "12": "aten.add.Tensor:node_args(2):kwargs()",
    "13": "aten.layer_norm.default:node_args(3):kwargs()",
    "14": "aten.dropout.default:node_args(1):kwargs()",
    "15": "aten.unsqueeze.default:node_args(1):kwargs()",
    "16": "aten.expand.default:node_args(1):kwargs()",
    "17": "aten._to_copy.default:node_args(1):kwargs('dtype',)",
    "18": "aten.lift_fresh_copy.default:node_args(1):kwargs()",
    "19": "aten.detach.default:node_args(1):kwargs()",
    "20": "aten.sub.Tensor:node_args(2):kwargs()",
    "21": "aten.masked_fill.Scalar:node_args(2):kwargs()",
    "22": "aten.linear.default:node_args(3):kwargs()",
    "23": "aten.view.default:node_args(1):kwargs()",
    "24": "aten.transpose.int:node_args(1):kwargs()",
    "25": "aten.scaled_dot_product_attention.default:node_args(4):kwargs()",
    "26": "aten.gelu.default:node_args(1):kwargs()",
    "27": "aten.select.int:node_args(1):kwargs()",
    "28": "aten.tanh.default:node_args(1):kwargs()",
    "29": "aten.ne.Scalar:node_args(1):kwargs()",
    "30": "aten.cumsum.default:node_args(1):kwargs()",
    "31": "aten.type_as.default:node_args(2):kwargs()",
    "32": "aten.add.Tensor:node_args(1):kwargs()",
    "33": "aten.mul.Tensor:node_args(2):kwargs()",
    "34": "aten.eq.Scalar:node_args(1):kwargs()",
    "35": "aten.sum.dim_IntList:node_args(1):kwargs()",
    "36": "aten.div.Tensor:node_args(1):kwargs()",
    "37": "aten.mul.Tensor:node_args(1):kwargs()",
    "38": "aten.rsub.Scalar:node_args(1):kwargs()",
    "39": "aten.div.Tensor:node_args(2):kwargs()",
    "40": "aten.arange.default:node_args(0):kwargs('device', 'pin_memory')",
    "41": "aten.outer.default:node_args(2):kwargs()",
    "42": "aten.cat.default:node_args(1):kwargs()",
    "43": "aten._to_copy.default:node_args(1):kwargs('device', 'dtype', 'layout')",
    "44": "aten.cos.default:node_args(1):kwargs()",
    "45": "aten.sin.default:node_args(1):kwargs()",
    "46": "aten.split.Tensor:node_args(1):kwargs()",
    "47": "<built-in function getitem>:node_args(1):kwargs()",
    "48": "aten.neg.default:node_args(1):kwargs()",
    "49": "aten.cat.default:node_args(2):kwargs()",
    "50": "aten.scaled_dot_product_attention.default:node_args(4):kwargs('scale',)",
    "51": "aten.erf.default:node_args(1):kwargs()",
    "52": "aten.linear.default:node_args(2):kwargs()",
    "53": "aten.matmul.default:node_args(2):kwargs()",
    "54": "aten.softmax.int:node_args(1):kwargs()",
    "55": "aten.permute.default:node_args(1):kwargs()",
    "56": "aten.clone.default:node_args(1):kwargs('memory_format',)",
    "57": "aten.arange.start:node_args(0):kwargs('device', 'pin_memory')",
    "58": "aten.full.default:node_args(0):kwargs('device', 'dtype', 'pin_memory')",
    "59": "aten.triu.default:node_args(1):kwargs()",
    "60": "aten.gt.Tensor:node_args(2):kwargs()",
    "61": "aten.clone.default:node_args(1):kwargs()",
    "62": "aten.copy.default:node_args(2):kwargs()",
    "63": "aten.slice_scatter.default:node_args(2):kwargs()",
    "64": "aten.where.self:node_args(3):kwargs()",
    "65": "aten.pow.Tensor_Scalar:node_args(1):kwargs()",
    "66": "aten.conv2d.default:node_args(2):kwargs()",
    "67": "aten._native_batch_norm_legit_no_training.default:node_args(5):kwargs()",
    "68": "aten.relu.default:node_args(1):kwargs()",
    "69": "aten.max_pool2d.default:node_args(1):kwargs()",
    "70": "aten.adaptive_avg_pool2d.default:node_args(1):kwargs()"
  },
  "variation_to_index": {
    "in0": 10,
    "in0,in1": 11,
    "in0,in1,in2": 12,
    "in0,in1,in2,in3": 13,
    "in1,in0": 14,
    "in0,in1,in2,in3,in4": 15
  },
  "constants": {
    "10": {
      "type": "int",
      "value": 0
    },
    "11": {
      "type": "int",
      "value": 9223372036854775807
    },
    "12": {
      "type": "int",
      "value": 1
    },
    "13": {
      "type": "int",
      "value": 64
    },
    "14": {
      "type": "immutable_list",
      "value": [
        768
      ]
    },
    "15": {
      "type": "float",
      "value": 1e-12
    },
    "16": {
      "type": "float",
      "value": 0.1
    },
    "17": {
      "type": "int",
      "value": 2
    },
    "18": {
      "type": "int",
      "value": 3
    },
    "19": {
      "type": "immutable_list",
      "value": [
        1,
        1,
        64,
        64
      ]
    },
    "20": {
      "type": "torch.dtype",
      "value": "torch.float32"
    },
    "21": {
      "type": "torch.dtype",
      "value": "torch.bool"
    },
    "22": {
      "type": "float",
      "value": -3.4028234663852886e+38
    },
    "23": {
      "type": "immutable_list",
      "value": [
        1,
        -1,
        12,
        64
      ]
    },
    "24": {
      "type": "immutable_list",
      "value": [
        1,
        64,
        768
      ]
    },
    "25": {
      "type": "torch.dtype",
      "value": "torch.int32"
    },
    "26": {
      "type": "torch.dtype",
      "value": "torch.int64"
    },
    "27": {
      "type": "immutable_list",
      "value": [
        384
      ]
    },
    "28": {
      "type": "float",
      "value": 0.144
    },
    "29": {
      "type": "immutable_list",
      "value": [
        1,
        -1,
        12,
        32
      ]
    },
    "30": {
      "type": "immutable_list",
      "value": [
        1,
        64,
        384
      ]
    },
    "31": {
      "type": "int",
      "value": 32
    },
    "32": {
      "type": "int",
      "value": -1
    },
    "33": {
      "type": "immutable_list",
      "value": [
        -1
      ]
    },
    "34": {
      "type": "float",
      "value": 0.88
    },
    "35": {
      "type": "immutable_list",
      "value": [
        640
      ]
    },
    "36": {
      "type": "immutable_list",
      "value": [
        1,
        64,
        -1,
        32
      ]
    },
    "37": {
      "type": "float",
      "value": 0.1767766952966369
    },
    "38": {
      "type": "torch.device",
      "value": "cpu"
    },
    "39": {
      "type": "torch.layout",
      "value": "torch.strided"
    },
    "40": {
      "type": "int",
      "value": 16
    },
    "41": {
      "type": "immutable_list",
      "value": [
        1,
        64,
        -1
      ]
    },
    "42": {
      "type": "float",
      "value": 0.5
    },
    "43": {
      "type": "float",
      "value": 1.4142135623730951
    },
    "44": {
      "type": "immutable_list",
      "value": [
        1024
      ]
    },
    "45": {
      "type": "immutable_list",
      "value": [
        1,
        -1,
        16,
        64
      ]
    },
    "46": {
      "type": "int",
      "value": -2
    },
    "47": {
      "type": "float",
      "value": 8.0
    },
    "48": {
      "type": "immutable_list",
      "value": [
        0,
        2,
        1,
        3
      ]
    },
    "49": {
      "type": "torch.memory_format",
      "value": "torch.contiguous_format"
    },
    "50": {
      "type": "immutable_list",
      "value": [
        1,
        64,
        1024
      ]
    },
    "51": {
      "type": "immutable_list",
      "value": [
        1,
        -1,
        768
      ]
    },
    "52": {
      "type": "immutable_list",
      "value": [
        64,
        64
      ]
    },
    "53": {
      "type": "immutable_list",
      "value": [
        -1,
        1
      ]
    },
    "54": {
      "type": "immutable_list",
      "value": [
        1,
        1,
        -1,
        -1
      ]
    },
    "55": {
      "type": "immutable_list",
      "value": [
        1,
        64,
        12,
        64
      ]
    },
    "56": {
      "type": "float",
      "value": 0.044715
    },
    "57": {
      "type": "float",
      "value": 0.7978845608028654
    },
    "58": {
      "type": "immutable_list",
      "value": [
        -1,
        64,
        768
      ]
    },
    "59": {
      "type": "NoneType",
      "value": null
    },
    "60": {
      "type": "immutable_list",
      "value": [
        2,
        2
      ]
    },
    "61": {
      "type": "immutable_list",
      "value": [
        3,
        3
      ]
    },
    "62": {
      "type": "float",
      "value": 1e-05
    },
    "63": {
      "type": "immutable_list",
      "value": [
        1,
        1
      ]
    }
  },
  "index_to_constant": {
    "10": "0",
    "11": "9223372036854775807",
    "12": "1",
    "13": "64",
    "14": "[768]",
    "15": "1e-12",
    "16": "0.1",
    "17": "2",
    "18": "3",
    "19": "[1, 1, 64, 64]",
    "20": "torch.float32",
    "21": "torch.bool",
    "22": "-3.4028234663852886e+38",
    "23": "[1, -1, 12, 64]",
    "24": "[1, 64, 768]",
    "25": "torch.int32",
    "26": "torch.int64",
    "27": "[384]",
    "28": "0.144",
    "29": "[1, -1, 12, 32]",
    "30": "[1, 64, 384]",
    "31": "32",
    "32": "-1",
    "33": "[-1]",
    "34": "0.88",
    "35": "[640]",
    "36": "[1, 64, -1, 32]",
    "37": "0.1767766952966369",
    "38": "cpu",
    "39": "torch.strided",
    "40": "16",
    "41": "[1, 64, -1]",
    "42": "0.5",
    "43": "1.4142135623730951",
    "44": "[1024]",
    "45": "[1, -1, 16, 64]",
    "46": "-2",
    "47": "8.0",
    "48": "[0, 2, 1, 3]",
    "49": "torch.contiguous_format",
    "50": "[1, 64, 1024]",
    "51": "[1, -1, 768]",
    "52": "[64, 64]",
    "53": "[-1, 1]",
    "54": "[1, 1, -1, -1]",
    "55": "[1, 64, 12, 64]",
    "56": "0.044715",
    "57": "0.7978845608028654",
    "58": "[-1, 64, 768]",
    "59": "None",
    "60": "[2, 2]",
    "61": "[3, 3]",
    "62": "1e-05",
    "63": "[1, 1]"
  },
  "constant_group_to_index": {
    "arg1=10;arg2=10;arg3=11": 10,
    "arg1=12;arg2=10;arg3=13": 11,
    "arg1=14;arg4=15": 12,
    "arg1=16;arg2=10": 13,
    "arg1=18;arg2=10;arg3=11": 14,
    "arg1=12;arg2=17": 15,
    "arg1=12;arg2=10": 16,
    "arg1=27;arg4=15": 17,
    "arg1=28;arg2=10": 18,
    "arg0=13;device=38;pin_memory=10": 19,
    "device=38;dtype=20;layout=39": 20,
    "arg1=17;arg2=10;arg3=11": 21,
    "arg1=12;arg2=10;arg3=11": 22,
    "arg1=40;arg2=32": 23,
    "arg1=10;arg2=10": 24,
    "arg1=44;arg4=15": 25,
    "arg1=32;arg2=46": 26,
    "arg0=10;arg1=13;device=38;pin_memory=10": 27,
    "arg0=52;arg1=22;device=38;dtype=20;pin_memory=10": 28,
    "device=38;dtype=26;layout=39": 29,
    "arg2=17;arg3=10;arg4=11": 30,
    "arg2=12;arg3=10;arg4=11": 31,
    "arg2=10;arg3=10;arg4=11": 32,
    "arg1=17;arg2=10;arg3=13": 33,
    "arg1=18;arg2=10;arg3=13": 34,
    "arg2=59;arg3=60;arg4=61": 35,
    "arg5=16;arg6=62": 36,
    "arg1=61;arg2=60;arg3=63": 37,
    "arg2=59;arg3=63;arg4=63": 38,
    "arg2=59;arg3=60;arg4=63": 39,
    "arg2=59;arg3=60": 40
  },
  "index_to_constant_group": {
    "10": "arg1=10;arg2=10;arg3=11",
    "11": "arg1=12;arg2=10;arg3=13",
    "12": "arg1=14;arg4=15",
    "13": "arg1=16;arg2=10",
    "14": "arg1=18;arg2=10;arg3=11",
    "15": "arg1=12;arg2=17",
    "16": "arg1=12;arg2=10",
    "17": "arg1=27;arg4=15",
    "18": "arg1=28;arg2=10",
    "19": "arg0=13;device=38;pin_memory=10",
    "20": "device=38;dtype=20;layout=39",
    "21": "arg1=17;arg2=10;arg3=11",
    "22": "arg1=12;arg2=10;arg3=11",
    "23": "arg1=40;arg2=32",
    "24": "arg1=10;arg2=10",
    "25": "arg1=44;arg4=15",
    "26": "arg1=32;arg2=46",
    "27": "arg0=10;arg1=13;device=38;pin_memory=10",
    "28": "arg0=52;arg1=22;device=38;dtype=20;pin_memory=10",
    "29": "device=38;dtype=26;layout=39",
    "30": "arg2=17;arg3=10;arg4=11",
    "31": "arg2=12;arg3=10;arg4=11",
    "32": "arg2=10;arg3=10;arg4=11",
    "33": "arg1=17;arg2=10;arg3=13",
    "34": "arg1=18;arg2=10;arg3=13",
    "35": "arg2=59;arg3=60;arg4=61",
    "36": "arg5=16;arg6=62",
    "37": "arg1=61;arg2=60;arg3=63",
    "38": "arg2=59;arg3=63;arg4=63",
    "39": "arg2=59;arg3=60;arg4=63",
    "40": "arg2=59;arg3=60"
  },
  "param_name_to_index": {
    "p_embeddings_layernorm_bias": 10,
    "p_encoder_layer_0_attention_self_query_weight": 11,
    "p_encoder_layer_0_attention_self_query_bias": 12,
    "p_encoder_layer_0_attention_self_key_weight": 13,
    "p_encoder_layer_0_attention_self_key_bias": 14,
    "p_encoder_layer_0_attention_self_value_weight": 15,
    "p_encoder_layer_0_attention_self_value_bias": 16,
    "p_encoder_layer_0_attention_output_dense_weight": 17,
    "p_encoder_layer_0_attention_output_dense_bias": 18,
    "p_encoder_layer_0_attention_output_layernorm_weight": 19,
    "p_encoder_layer_0_attention_output_layernorm_bias": 20,
    "p_encoder_layer_0_intermediate_dense_weight": 21,
    "p_encoder_layer_0_intermediate_dense_bias": 22,
    "p_encoder_layer_0_output_dense_weight": 23,
    "p_encoder_layer_0_output_dense_bias": 24,
    "p_encoder_layer_0_output_layernorm_weight": 25,
    "p_encoder_layer_0_output_layernorm_bias": 26,
    "p_encoder_layer_1_attention_self_query_weight": 27,
    "p_encoder_layer_1_attention_self_query_bias": 28,
    "p_encoder_layer_1_attention_self_key_weight": 29,
    "p_encoder_layer_1_attention_self_key_bias": 30,
    "p_encoder_layer_1_attention_self_value_weight": 31,
    "p_encoder_layer_1_attention_self_value_bias": 32,
    "p_encoder_layer_1_attention_output_dense_weight": 33,
    "p_encoder_layer_1_attention_output_dense_bias": 34,
    "p_encoder_layer_1_attention_output_layernorm_weight": 35,
    "p_encoder_layer_1_attention_output_layernorm_bias": 36,
    "p_encoder_layer_1_intermediate_dense_weight": 37,
    "p_encoder_layer_1_intermediate_dense_bias": 38,
    "p_encoder_layer_1_output_dense_weight": 39,
    "p_encoder_layer_1_output_dense_bias": 40,
    "p_encoder_layer_1_output_layernorm_weight": 41,
    "p_encoder_layer_1_output_layernorm_bias": 42,
    "p_encoder_layer_2_attention_self_query_weight": 43,
    "p_encoder_layer_2_attention_self_query_bias": 44,
    "p_encoder_layer_2_attention_self_key_weight": 45,
    "p_encoder_layer_2_attention_self_key_bias": 46,
    "p_encoder_layer_2_attention_self_value_weight": 47,
    "p_encoder_layer_2_attention_self_value_bias": 48,
    "p_encoder_layer_2_attention_output_dense_weight": 49,
    "p_encoder_layer_2_attention_output_dense_bias": 50,
    "p_encoder_layer_2_attention_output_layernorm_weight": 51,
    "p_encoder_layer_2_attention_output_layernorm_bias": 52,
    "p_encoder_layer_2_intermediate_dense_weight": 53,
    "p_encoder_layer_2_intermediate_dense_bias": 54,
    "p_encoder_layer_2_output_dense_weight": 55,
    "p_encoder_layer_2_output_dense_bias": 56,
    "p_encoder_layer_2_output_layernorm_weight": 57,
    "p_encoder_layer_2_output_layernorm_bias": 58,
    "p_encoder_layer_3_attention_self_query_weight": 59,
    "p_encoder_layer_3_attention_self_query_bias": 60,
    "p_encoder_layer_3_attention_self_key_weight": 61,
    "p_encoder_layer_3_attention_self_key_bias": 62,
    "p_encoder_layer_3_attention_self_value_weight": 63,
    "p_encoder_layer_3_attention_self_value_bias": 64,
    "p_encoder_layer_3_attention_output_dense_weight": 65,
    "p_encoder_layer_3_attention_output_dense_bias": 66,
    "p_encoder_layer_3_attention_output_layernorm_weight": 67,
    "p_encoder_layer_3_attention_output_layernorm_bias": 68,
    "p_encoder_layer_3_intermediate_dense_weight": 69,
    "p_encoder_layer_3_intermediate_dense_bias": 70,
    "p_encoder_layer_3_output_dense_weight": 71,
    "p_encoder_layer_3_output_dense_bias": 72,
    "p_encoder_layer_3_output_layernorm_weight": 73,
    "p_encoder_layer_3_output_layernorm_bias": 74,
    "p_encoder_layer_4_attention_self_query_weight": 75,
    "p_encoder_layer_4_attention_self_query_bias": 76,
    "p_encoder_layer_4_attention_self_key_weight": 77,
    "p_encoder_layer_4_attention_self_key_bias": 78,
    "p_encoder_layer_4_attention_self_value_weight": 79,
    "p_encoder_layer_4_attention_self_value_bias": 80,
    "p_encoder_layer_4_attention_output_dense_weight": 81,
    "p_encoder_layer_4_attention_output_dense_bias": 82,
    "p_encoder_layer_4_attention_output_layernorm_weight": 83,
    "p_encoder_layer_4_attention_output_layernorm_bias": 84,
    "p_encoder_layer_4_intermediate_dense_weight": 85,
    "p_encoder_layer_4_intermediate_dense_bias": 86,
    "p_encoder_layer_4_output_dense_weight": 87,
    "p_encoder_layer_4_output_dense_bias": 88,
    "p_encoder_layer_4_output_layernorm_weight": 89,
    "p_encoder_layer_4_output_layernorm_bias": 90,
    "p_encoder_layer_5_attention_self_query_weight": 91,
    "p_encoder_layer_5_attention_self_query_bias": 92,
    "p_encoder_layer_5_attention_self_key_weight": 93,
    "p_encoder_layer_5_attention_self_key_bias": 94,
    "p_encoder_layer_5_attention_self_value_weight": 95,
    "p_encoder_layer_5_attention_self_value_bias": 96,
    "p_encoder_layer_5_attention_output_dense_weight": 97,
    "p_encoder_layer_5_attention_output_dense_bias": 98,
    "p_encoder_layer_5_attention_output_layernorm_weight": 99,
    "p_encoder_layer_5_attention_output_layernorm_bias": 100,
    "p_encoder_layer_5_intermediate_dense_weight": 101,
    "p_encoder_layer_5_intermediate_dense_bias": 102,
    "p_encoder_layer_5_output_dense_weight": 103,
    "p_encoder_layer_5_output_dense_bias": 104,
    "p_encoder_layer_5_output_layernorm_weight": 105,
    "p_encoder_layer_5_output_layernorm_bias": 106,
    "p_encoder_layer_6_attention_self_query_weight": 107,
    "p_encoder_layer_6_attention_self_query_bias": 108,
    "p_encoder_layer_6_attention_self_key_weight": 109,
    "p_encoder_layer_6_attention_self_key_bias": 110,
    "p_encoder_layer_6_attention_self_value_weight": 111,
    "p_encoder_layer_6_attention_self_value_bias": 112,
    "p_encoder_layer_6_attention_output_dense_weight": 113,
    "p_encoder_layer_6_attention_output_dense_bias": 114,
    "p_encoder_layer_6_attention_output_layernorm_weight": 115,
    "p_encoder_layer_6_attention_output_layernorm_bias": 116,
    "p_encoder_layer_6_intermediate_dense_weight": 117,
    "p_encoder_layer_6_intermediate_dense_bias": 118,
    "p_encoder_layer_6_output_dense_weight": 119,
    "p_encoder_layer_6_output_dense_bias": 120,
    "p_encoder_layer_6_output_layernorm_weight": 121,
    "p_encoder_layer_6_output_layernorm_bias": 122,
    "p_encoder_layer_7_attention_self_query_weight": 123,
    "p_encoder_layer_7_attention_self_query_bias": 124,
    "p_encoder_layer_7_attention_self_key_weight": 125,
    "p_encoder_layer_7_attention_self_key_bias": 126,
    "p_encoder_layer_7_attention_self_value_weight": 127,
    "p_encoder_layer_7_attention_self_value_bias": 128,
    "p_encoder_layer_7_attention_output_dense_weight": 129,
    "p_encoder_layer_7_attention_output_dense_bias": 130,
    "p_encoder_layer_7_attention_output_layernorm_weight": 131,
    "p_encoder_layer_7_attention_output_layernorm_bias": 132,
    "p_encoder_layer_7_intermediate_dense_weight": 133,
    "p_encoder_layer_7_intermediate_dense_bias": 134,
    "p_encoder_layer_7_output_dense_weight": 135,
    "p_encoder_layer_7_output_dense_bias": 136,
    "p_encoder_layer_7_output_layernorm_weight": 137,
    "p_encoder_layer_7_output_layernorm_bias": 138,
    "p_encoder_layer_8_attention_self_query_weight": 139,
    "p_encoder_layer_8_attention_self_query_bias": 140,
    "p_encoder_layer_8_attention_self_key_weight": 141,
    "p_encoder_layer_8_attention_self_key_bias": 142,
    "p_encoder_layer_8_attention_self_value_weight": 143,
    "p_encoder_layer_8_attention_self_value_bias": 144,
    "p_encoder_layer_8_attention_output_dense_weight": 145,
    "p_encoder_layer_8_attention_output_dense_bias": 146,
    "p_encoder_layer_8_attention_output_layernorm_weight": 147,
    "p_encoder_layer_8_attention_output_layernorm_bias": 148,
    "p_encoder_layer_8_intermediate_dense_weight": 149,
    "p_encoder_layer_8_intermediate_dense_bias": 150,
    "p_encoder_layer_8_output_dense_weight": 151,
    "p_encoder_layer_8_output_dense_bias": 152,
    "p_encoder_layer_8_output_layernorm_weight": 153,
    "p_encoder_layer_8_output_layernorm_bias": 154,
    "p_encoder_layer_9_attention_self_query_weight": 155,
    "p_encoder_layer_9_attention_self_query_bias": 156,
    "p_encoder_layer_9_attention_self_key_weight": 157,
    "p_encoder_layer_9_attention_self_key_bias": 158,
    "p_encoder_layer_9_attention_self_value_weight": 159,
    "p_encoder_layer_9_attention_self_value_bias": 160,
    "p_encoder_layer_9_attention_output_dense_weight": 161,
    "p_encoder_layer_9_attention_output_dense_bias": 162,
    "p_encoder_layer_9_attention_output_layernorm_weight": 163,
    "p_encoder_layer_9_attention_output_layernorm_bias": 164,
    "p_encoder_layer_9_intermediate_dense_weight": 165,
    "p_encoder_layer_9_intermediate_dense_bias": 166,
    "p_encoder_layer_9_output_dense_weight": 167,
    "p_encoder_layer_9_output_dense_bias": 168,
    "p_encoder_layer_9_output_layernorm_weight": 169,
    "p_encoder_layer_9_output_layernorm_bias": 170,
    "p_encoder_layer_10_attention_self_query_weight": 171,
    "p_encoder_layer_10_attention_self_query_bias": 172,
    "p_encoder_layer_10_attention_self_key_weight": 173,
    "p_encoder_layer_10_attention_self_key_bias": 174,
    "p_encoder_layer_10_attention_self_value_weight": 175,
    "p_encoder_layer_10_attention_self_value_bias": 176,
    "p_encoder_layer_10_attention_output_dense_weight": 177,
    "p_encoder_layer_10_attention_output_dense_bias": 178,
    "p_encoder_layer_10_attention_output_layernorm_weight": 179,
    "p_encoder_layer_10_attention_output_layernorm_bias": 180,
    "p_encoder_layer_10_intermediate_dense_weight": 181,
    "p_encoder_layer_10_intermediate_dense_bias": 182,
    "p_encoder_layer_10_output_dense_weight": 183,
    "p_encoder_layer_10_output_dense_bias": 184,
    "p_encoder_layer_10_output_layernorm_weight": 185,
    "p_encoder_layer_10_output_layernorm_bias": 186,
    "p_encoder_layer_11_attention_self_query_weight": 187,
    "p_encoder_layer_11_attention_self_query_bias": 188,
    "p_encoder_layer_11_attention_self_key_weight": 189,
    "p_encoder_layer_11_attention_self_key_bias": 190,
    "p_encoder_layer_11_attention_self_value_weight": 191,
    "p_encoder_layer_11_attention_self_value_bias": 192,
    "p_encoder_layer_11_attention_output_dense_weight": 193,
    "p_encoder_layer_11_attention_output_dense_bias": 194,
    "p_encoder_layer_11_attention_output_layernorm_weight": 195,
    "p_encoder_layer_11_attention_output_layernorm_bias": 196,
    "p_encoder_layer_11_intermediate_dense_weight": 197,
    "p_encoder_layer_11_intermediate_dense_bias": 198,
    "p_encoder_layer_11_output_dense_weight": 199,
    "p_encoder_layer_11_output_dense_bias": 200,
    "p_encoder_layer_11_output_layernorm_weight": 201,
    "p_encoder_layer_11_output_layernorm_bias": 202,
    "p_pooler_dense_weight": 203,
    "p_pooler_dense_bias": 204,
    "b_embeddings_position_ids": 205,
    "c_lifted_tensor_0": 206,
    "input_ids": 207,
    "token_type_ids": 208,
    "attention_mask": 209,
    "use_cache": 210,
    "p_fn_bias": 211,
    "input": 212,
    "p_predictions_transform_dense_bias": 213,
    "p_predictions_transform_layernorm_weight": 214,
    "p_predictions_transform_layernorm_bias": 215,
    "p_predictions_decoder_weight": 216,
    "p_predictions_decoder_bias": 217,
    "sequence_output": 218,
    "p_encoder_layer_0_layernorm_weight": 219,
    "p_encoder_layer_0_layernorm_bias": 220,
    "p_encoder_layer_1_attention_layernorm_weight": 221,
    "p_encoder_layer_1_attention_layernorm_bias": 222,
    "p_encoder_layer_1_layernorm_weight": 223,
    "p_encoder_layer_1_layernorm_bias": 224,
    "p_encoder_layer_2_attention_layernorm_weight": 225,
    "p_encoder_layer_2_attention_layernorm_bias": 226,
    "p_encoder_layer_2_layernorm_weight": 227,
    "p_encoder_layer_2_layernorm_bias": 228,
    "p_encoder_layer_3_attention_layernorm_weight": 229,
    "p_encoder_layer_3_attention_layernorm_bias": 230,
    "p_encoder_layer_3_layernorm_weight": 231,
    "p_encoder_layer_3_layernorm_bias": 232,
    "p_encoder_layer_4_attention_layernorm_weight": 233,
    "p_encoder_layer_4_attention_layernorm_bias": 234,
    "p_encoder_layer_4_layernorm_weight": 235,
    "p_encoder_layer_4_layernorm_bias": 236,
    "p_encoder_layer_5_attention_layernorm_weight": 237,
    "p_encoder_layer_5_attention_layernorm_bias": 238,
    "p_encoder_layer_5_layernorm_weight": 239,
    "p_encoder_layer_5_layernorm_bias": 240,
    "p_encoder_layer_6_attention_layernorm_weight": 241,
    "p_encoder_layer_6_attention_layernorm_bias": 242,
    "p_encoder_layer_6_layernorm_weight": 243,
    "p_encoder_layer_6_layernorm_bias": 244,
    "p_encoder_layer_7_attention_layernorm_weight": 245,
    "p_encoder_layer_7_attention_layernorm_bias": 246,
    "p_encoder_layer_7_layernorm_weight": 247,
    "p_encoder_layer_7_layernorm_bias": 248,
    "p_encoder_layer_8_attention_layernorm_weight": 249,
    "p_encoder_layer_8_attention_layernorm_bias": 250,
    "p_encoder_layer_8_layernorm_weight": 251,
    "p_encoder_layer_8_layernorm_bias": 252,
    "p_encoder_layer_9_attention_layernorm_weight": 253,
    "p_encoder_layer_9_attention_layernorm_bias": 254,
    "p_encoder_layer_9_layernorm_weight": 255,
    "p_encoder_layer_9_layernorm_bias": 256,
    "p_encoder_layer_10_attention_layernorm_weight": 257,
    "p_encoder_layer_10_attention_layernorm_bias": 258,
    "p_encoder_layer_10_layernorm_weight": 259,
    "p_encoder_layer_10_layernorm_bias": 260,
    "p_encoder_layer_11_attention_layernorm_weight": 261,
    "p_encoder_layer_11_attention_layernorm_bias": 262,
    "p_encoder_layer_11_layernorm_weight": 263,
    "p_encoder_layer_11_layernorm_bias": 264,
    "p_encoder_layer_12_attention_layernorm_weight": 265,
    "p_encoder_layer_12_attention_layernorm_bias": 266,
    "p_encoder_layer_12_attention_self_query_weight": 267,
    "p_encoder_layer_12_attention_self_query_bias": 268,
    "p_encoder_layer_12_attention_self_key_weight": 269,
    "p_encoder_layer_12_attention_self_key_bias": 270,
    "p_encoder_layer_12_attention_self_value_weight": 271,
    "p_encoder_layer_12_attention_self_value_bias": 272,
    "p_encoder_layer_12_attention_output_dense_weight": 273,
    "p_encoder_layer_12_attention_output_dense_bias": 274,
    "p_encoder_layer_12_layernorm_weight": 275,
    "p_encoder_layer_12_layernorm_bias": 276,
    "p_encoder_layer_12_intermediate_dense_weight": 277,
    "p_encoder_layer_12_intermediate_dense_bias": 278,
    "p_encoder_layer_12_output_dense_weight": 279,
    "p_encoder_layer_12_output_dense_bias": 280,
    "p_encoder_layer_13_attention_layernorm_weight": 281,
    "p_encoder_layer_13_attention_layernorm_bias": 282,
    "p_encoder_layer_13_attention_self_query_weight": 283,
    "p_encoder_layer_13_attention_self_query_bias": 284,
    "p_encoder_layer_13_attention_self_key_weight": 285,
    "p_encoder_layer_13_attention_self_key_bias": 286,
    "p_encoder_layer_13_attention_self_value_weight": 287,
    "p_encoder_layer_13_attention_self_value_bias": 288,
    "p_encoder_layer_13_attention_output_dense_weight": 289,
    "p_encoder_layer_13_attention_output_dense_bias": 290,
    "p_encoder_layer_13_layernorm_weight": 291,
    "p_encoder_layer_13_layernorm_bias": 292,
    "p_encoder_layer_13_intermediate_dense_weight": 293,
    "p_encoder_layer_13_intermediate_dense_bias": 294,
    "p_encoder_layer_13_output_dense_weight": 295,
    "p_encoder_layer_13_output_dense_bias": 296,
    "p_encoder_layer_14_attention_layernorm_weight": 297,
    "p_encoder_layer_14_attention_layernorm_bias": 298,
    "p_encoder_layer_14_attention_self_query_weight": 299,
    "p_encoder_layer_14_attention_self_query_bias": 300,
    "p_encoder_layer_14_attention_self_key_weight": 301,
    "p_encoder_layer_14_attention_self_key_bias": 302,
    "p_encoder_layer_14_attention_self_value_weight": 303,
    "p_encoder_layer_14_attention_self_value_bias": 304,
    "p_encoder_layer_14_attention_output_dense_weight": 305,
    "p_encoder_layer_14_attention_output_dense_bias": 306,
    "p_encoder_layer_14_layernorm_weight": 307,
    "p_encoder_layer_14_layernorm_bias": 308,
    "p_encoder_layer_14_intermediate_dense_weight": 309,
    "p_encoder_layer_14_intermediate_dense_bias": 310,
    "p_encoder_layer_14_output_dense_weight": 311,
    "p_encoder_layer_14_output_dense_bias": 312,
    "p_encoder_layer_15_attention_layernorm_weight": 313,
    "p_encoder_layer_15_attention_layernorm_bias": 314,
    "p_encoder_layer_15_attention_self_query_weight": 315,
    "p_encoder_layer_15_attention_self_query_bias": 316,
    "p_encoder_layer_15_attention_self_key_weight": 317,
    "p_encoder_layer_15_attention_self_key_bias": 318,
    "p_encoder_layer_15_attention_self_value_weight": 319,
    "p_encoder_layer_15_attention_self_value_bias": 320,
    "p_encoder_layer_15_attention_output_dense_weight": 321,
    "p_encoder_layer_15_attention_output_dense_bias": 322,
    "p_encoder_layer_15_layernorm_weight": 323,
    "p_encoder_layer_15_layernorm_bias": 324,
    "p_encoder_layer_15_intermediate_dense_weight": 325,
    "p_encoder_layer_15_intermediate_dense_bias": 326,
    "p_encoder_layer_15_output_dense_weight": 327,
    "p_encoder_layer_15_output_dense_bias": 328,
    "p_encoder_layer_16_attention_layernorm_weight": 329,
    "p_encoder_layer_16_attention_layernorm_bias": 330,
    "p_encoder_layer_16_attention_self_query_weight": 331,
    "p_encoder_layer_16_attention_self_query_bias": 332,
    "p_encoder_layer_16_attention_self_key_weight": 333,
    "p_encoder_layer_16_attention_self_key_bias": 334,
    "p_encoder_layer_16_attention_self_value_weight": 335,
    "p_encoder_layer_16_attention_self_value_bias": 336,
    "p_encoder_layer_16_attention_output_dense_weight": 337,
    "p_encoder_layer_16_attention_output_dense_bias": 338,
    "p_encoder_layer_16_layernorm_weight": 339,
    "p_encoder_layer_16_layernorm_bias": 340,
    "p_encoder_layer_16_intermediate_dense_weight": 341,
    "p_encoder_layer_16_intermediate_dense_bias": 342,
    "p_encoder_layer_16_output_dense_weight": 343,
    "p_encoder_layer_16_output_dense_bias": 344,
    "p_encoder_layer_17_attention_layernorm_weight": 345,
    "p_encoder_layer_17_attention_layernorm_bias": 346,
    "p_encoder_layer_17_attention_self_query_weight": 347,
    "p_encoder_layer_17_attention_self_query_bias": 348,
    "p_encoder_layer_17_attention_self_key_weight": 349,
    "p_encoder_layer_17_attention_self_key_bias": 350,
    "p_encoder_layer_17_attention_self_value_weight": 351,
    "p_encoder_layer_17_attention_self_value_bias": 352,
    "p_encoder_layer_17_attention_output_dense_weight": 353,
    "p_encoder_layer_17_attention_output_dense_bias": 354,
    "p_encoder_layer_17_layernorm_weight": 355,
    "p_encoder_layer_17_layernorm_bias": 356,
    "p_encoder_layer_17_intermediate_dense_weight": 357,
    "p_encoder_layer_17_intermediate_dense_bias": 358,
    "p_encoder_layer_17_output_dense_weight": 359,
    "p_encoder_layer_17_output_dense_bias": 360,
    "p_encoder_layer_18_attention_layernorm_weight": 361,
    "p_encoder_layer_18_attention_layernorm_bias": 362,
    "p_encoder_layer_18_attention_self_query_weight": 363,
    "p_encoder_layer_18_attention_self_query_bias": 364,
    "p_encoder_layer_18_attention_self_key_weight": 365,
    "p_encoder_layer_18_attention_self_key_bias": 366,
    "p_encoder_layer_18_attention_self_value_weight": 367,
    "p_encoder_layer_18_attention_self_value_bias": 368,
    "p_encoder_layer_18_attention_output_dense_weight": 369,
    "p_encoder_layer_18_attention_output_dense_bias": 370,
    "p_encoder_layer_18_layernorm_weight": 371,
    "p_encoder_layer_18_layernorm_bias": 372,
    "p_encoder_layer_18_intermediate_dense_weight": 373,
    "p_encoder_layer_18_intermediate_dense_bias": 374,
    "p_encoder_layer_18_output_dense_weight": 375,
    "p_encoder_layer_18_output_dense_bias": 376,
    "p_encoder_layer_19_attention_layernorm_weight": 377,
    "p_encoder_layer_19_attention_layernorm_bias": 378,
    "p_encoder_layer_19_attention_self_query_weight": 379,
    "p_encoder_layer_19_attention_self_query_bias": 380,
    "p_encoder_layer_19_attention_self_key_weight": 381,
    "p_encoder_layer_19_attention_self_key_bias": 382,
    "p_encoder_layer_19_attention_self_value_weight": 383,
    "p_encoder_layer_19_attention_self_value_bias": 384,
    "p_encoder_layer_19_attention_output_dense_weight": 385,
    "p_encoder_layer_19_attention_output_dense_bias": 386,
    "p_encoder_layer_19_layernorm_weight": 387,
    "p_encoder_layer_19_layernorm_bias": 388,
    "p_encoder_layer_19_intermediate_dense_weight": 389,
    "p_encoder_layer_19_intermediate_dense_bias": 390,
    "p_encoder_layer_19_output_dense_weight": 391,
    "p_encoder_layer_19_output_dense_bias": 392,
    "p_encoder_layer_20_attention_layernorm_weight": 393,
    "p_encoder_layer_20_attention_layernorm_bias": 394,
    "p_encoder_layer_20_attention_self_query_weight": 395,
    "p_encoder_layer_20_attention_self_query_bias": 396,
    "p_encoder_layer_20_attention_self_key_weight": 397,
    "p_encoder_layer_20_attention_self_key_bias": 398,
    "p_encoder_layer_20_attention_self_value_weight": 399,
    "p_encoder_layer_20_attention_self_value_bias": 400,
    "p_encoder_layer_20_attention_output_dense_weight": 401,
    "p_encoder_layer_20_attention_output_dense_bias": 402,
    "p_encoder_layer_20_layernorm_weight": 403,
    "p_encoder_layer_20_layernorm_bias": 404,
    "p_encoder_layer_20_intermediate_dense_weight": 405,
    "p_encoder_layer_20_intermediate_dense_bias": 406,
    "p_encoder_layer_20_output_dense_weight": 407,
    "p_encoder_layer_20_output_dense_bias": 408,
    "p_encoder_layer_21_attention_layernorm_weight": 409,
    "p_encoder_layer_21_attention_layernorm_bias": 410,
    "p_encoder_layer_21_attention_self_query_weight": 411,
    "p_encoder_layer_21_attention_self_query_bias": 412,
    "p_encoder_layer_21_attention_self_key_weight": 413,
    "p_encoder_layer_21_attention_self_key_bias": 414,
    "p_encoder_layer_21_attention_self_value_weight": 415,
    "p_encoder_layer_21_attention_self_value_bias": 416,
    "p_encoder_layer_21_attention_output_dense_weight": 417,
    "p_encoder_layer_21_attention_output_dense_bias": 418,
    "p_encoder_layer_21_layernorm_weight": 419,
    "p_encoder_layer_21_layernorm_bias": 420,
    "p_encoder_layer_21_intermediate_dense_weight": 421,
    "p_encoder_layer_21_intermediate_dense_bias": 422,
    "p_encoder_layer_21_output_dense_weight": 423,
    "p_encoder_layer_21_output_dense_bias": 424,
    "p_encoder_layer_22_attention_layernorm_weight": 425,
    "p_encoder_layer_22_attention_layernorm_bias": 426,
    "p_encoder_layer_22_attention_self_query_weight": 427,
    "p_encoder_layer_22_attention_self_query_bias": 428,
    "p_encoder_layer_22_attention_self_key_weight": 429,
    "p_encoder_layer_22_attention_self_key_bias": 430,
    "p_encoder_layer_22_attention_self_value_weight": 431,
    "p_encoder_layer_22_attention_self_value_bias": 432,
    "p_encoder_layer_22_attention_output_dense_weight": 433,
    "p_encoder_layer_22_attention_output_dense_bias": 434,
    "p_encoder_layer_22_layernorm_weight": 435,
    "p_encoder_layer_22_layernorm_bias": 436,
    "p_encoder_layer_22_intermediate_dense_weight": 437,
    "p_encoder_layer_22_intermediate_dense_bias": 438,
    "p_encoder_layer_22_output_dense_weight": 439,
    "p_encoder_layer_22_output_dense_bias": 440,
    "p_encoder_layer_23_attention_layernorm_weight": 441,
    "p_encoder_layer_23_attention_layernorm_bias": 442,
    "p_encoder_layer_23_attention_self_query_weight": 443,
    "p_encoder_layer_23_attention_self_query_bias": 444,
    "p_encoder_layer_23_attention_self_key_weight": 445,
    "p_encoder_layer_23_attention_self_key_bias": 446,
    "p_encoder_layer_23_attention_self_value_weight": 447,
    "p_encoder_layer_23_attention_self_value_bias": 448,
    "p_encoder_layer_23_attention_output_dense_weight": 449,
    "p_encoder_layer_23_attention_output_dense_bias": 450,
    "p_encoder_layer_23_layernorm_weight": 451,
    "p_encoder_layer_23_layernorm_bias": 452,
    "p_encoder_layer_23_intermediate_dense_weight": 453,
    "p_encoder_layer_23_intermediate_dense_bias": 454,
    "p_encoder_layer_23_output_dense_weight": 455,
    "p_encoder_layer_23_output_dense_bias": 456,
    "p_encoder_layer_24_attention_layernorm_weight": 457,
    "p_encoder_layer_24_attention_layernorm_bias": 458,
    "p_encoder_layer_24_attention_self_query_weight": 459,
    "p_encoder_layer_24_attention_self_query_bias": 460,
    "p_encoder_layer_24_attention_self_key_weight": 461,
    "p_encoder_layer_24_attention_self_key_bias": 462,
    "p_encoder_layer_24_attention_self_value_weight": 463,
    "p_encoder_layer_24_attention_self_value_bias": 464,
    "p_encoder_layer_24_attention_output_dense_weight": 465,
    "p_encoder_layer_24_attention_output_dense_bias": 466,
    "p_encoder_layer_24_layernorm_weight": 467,
    "p_encoder_layer_24_layernorm_bias": 468,
    "p_encoder_layer_24_intermediate_dense_weight": 469,
    "p_encoder_layer_24_intermediate_dense_bias": 470,
    "p_encoder_layer_24_output_dense_weight": 471,
    "p_encoder_layer_24_output_dense_bias": 472,
    "p_encoder_layer_25_attention_layernorm_weight": 473,
    "p_encoder_layer_25_attention_layernorm_bias": 474,
    "p_encoder_layer_25_attention_self_query_weight": 475,
    "p_encoder_layer_25_attention_self_query_bias": 476,
    "p_encoder_layer_25_attention_self_key_weight": 477,
    "p_encoder_layer_25_attention_self_key_bias": 478,
    "p_encoder_layer_25_attention_self_value_weight": 479,
    "p_encoder_layer_25_attention_self_value_bias": 480,
    "p_encoder_layer_25_attention_output_dense_weight": 481,
    "p_encoder_layer_25_attention_output_dense_bias": 482,
    "p_encoder_layer_25_layernorm_weight": 483,
    "p_encoder_layer_25_layernorm_bias": 484,
    "p_encoder_layer_25_intermediate_dense_weight": 485,
    "p_encoder_layer_25_intermediate_dense_bias": 486,
    "p_encoder_layer_25_output_dense_weight": 487,
    "p_encoder_layer_25_output_dense_bias": 488,
    "p_encoder_layer_26_attention_layernorm_weight": 489,
    "p_encoder_layer_26_attention_layernorm_bias": 490,
    "p_encoder_layer_26_attention_self_query_weight": 491,
    "p_encoder_layer_26_attention_self_query_bias": 492,
    "p_encoder_layer_26_attention_self_key_weight": 493,
    "p_encoder_layer_26_attention_self_key_bias": 494,
    "p_encoder_layer_26_attention_self_value_weight": 495,
    "p_encoder_layer_26_attention_self_value_bias": 496,
    "p_encoder_layer_26_attention_output_dense_weight": 497,
    "p_encoder_layer_26_attention_output_dense_bias": 498,
    "p_encoder_layer_26_layernorm_weight": 499,
    "p_encoder_layer_26_layernorm_bias": 500,
    "p_encoder_layer_26_intermediate_dense_weight": 501,
    "p_encoder_layer_26_intermediate_dense_bias": 502,
    "p_encoder_layer_26_output_dense_weight": 503,
    "p_encoder_layer_26_output_dense_bias": 504,
    "p_encoder_layer_27_attention_layernorm_weight": 505,
    "p_encoder_layer_27_attention_layernorm_bias": 506,
    "p_encoder_layer_27_attention_self_query_weight": 507,
    "p_encoder_layer_27_attention_self_query_bias": 508,
    "p_encoder_layer_27_attention_self_key_weight": 509,
    "p_encoder_layer_27_attention_self_key_bias": 510,
    "p_encoder_layer_27_attention_self_value_weight": 511,
    "p_encoder_layer_27_attention_self_value_bias": 512,
    "p_encoder_layer_27_attention_output_dense_weight": 513,
    "p_encoder_layer_27_attention_output_dense_bias": 514,
    "p_encoder_layer_27_layernorm_weight": 515,
    "p_encoder_layer_27_layernorm_bias": 516,
    "p_encoder_layer_27_intermediate_dense_weight": 517,
    "p_encoder_layer_27_intermediate_dense_bias": 518,
    "p_encoder_layer_27_output_dense_weight": 519,
    "p_encoder_layer_27_output_dense_bias": 520,
    "p_encoder_layer_28_attention_layernorm_weight": 521,
    "p_encoder_layer_28_attention_layernorm_bias": 522,
    "p_encoder_layer_28_attention_self_query_weight": 523,
    "p_encoder_layer_28_attention_self_query_bias": 524,
    "p_encoder_layer_28_attention_self_key_weight": 525,
    "p_encoder_layer_28_attention_self_key_bias": 526,
    "p_encoder_layer_28_attention_self_value_weight": 527,
    "p_encoder_layer_28_attention_self_value_bias": 528,
    "p_encoder_layer_28_attention_output_dense_weight": 529,
    "p_encoder_layer_28_attention_output_dense_bias": 530,
    "p_encoder_layer_28_layernorm_weight": 531,
    "p_encoder_layer_28_layernorm_bias": 532,
    "p_encoder_layer_28_intermediate_dense_weight": 533,
    "p_encoder_layer_28_intermediate_dense_bias": 534,
    "p_encoder_layer_28_output_dense_weight": 535,
    "p_encoder_layer_28_output_dense_bias": 536,
    "p_encoder_layer_29_attention_layernorm_weight": 537,
    "p_encoder_layer_29_attention_layernorm_bias": 538,
    "p_encoder_layer_29_attention_self_query_weight": 539,
    "p_encoder_layer_29_attention_self_query_bias": 540,
    "p_encoder_layer_29_attention_self_key_weight": 541,
    "p_encoder_layer_29_attention_self_key_bias": 542,
    "p_encoder_layer_29_attention_self_value_weight": 543,
    "p_encoder_layer_29_attention_self_value_bias": 544,
    "p_encoder_layer_29_attention_output_dense_weight": 545,
    "p_encoder_layer_29_attention_output_dense_bias": 546,
    "p_encoder_layer_29_layernorm_weight": 547,
    "p_encoder_layer_29_layernorm_bias": 548,
    "p_encoder_layer_29_intermediate_dense_weight": 549,
    "p_encoder_layer_29_intermediate_dense_bias": 550,
    "p_encoder_layer_29_output_dense_weight": 551,
    "p_encoder_layer_29_output_dense_bias": 552,
    "p_encoder_emb_layer_norm_after_weight": 553,
    "p_encoder_emb_layer_norm_after_bias": 554,
    "b___encoder_layer_0_attention_self_rotary_embeddings__buffers__inv_freq": 555,
    "b___encoder_layer_1_attention_self_rotary_embeddings__buffers__inv_freq": 556,
    "b___encoder_layer_2_attention_self_rotary_embeddings__buffers__inv_freq": 557,
    "b___encoder_layer_3_attention_self_rotary_embeddings__buffers__inv_freq": 558,
    "b___encoder_layer_4_attention_self_rotary_embeddings__buffers__inv_freq": 559,
    "b___encoder_layer_5_attention_self_rotary_embeddings__buffers__inv_freq": 560,
    "b___encoder_layer_6_attention_self_rotary_embeddings__buffers__inv_freq": 561,
    "b___encoder_layer_7_attention_self_rotary_embeddings__buffers__inv_freq": 562,
    "b___encoder_layer_8_attention_self_rotary_embeddings__buffers__inv_freq": 563,
    "b___encoder_layer_9_attention_self_rotary_embeddings__buffers__inv_freq": 564,
    "b___encoder_layer_10_attention_self_rotary_embeddings__buffers__inv_freq": 565,
    "b___encoder_layer_11_attention_self_rotary_embeddings__buffers__inv_freq": 566,
    "b___encoder_layer_12_attention_self_rotary_embeddings__buffers__inv_freq": 567,
    "b___encoder_layer_13_attention_self_rotary_embeddings__buffers__inv_freq": 568,
    "b___encoder_layer_14_attention_self_rotary_embeddings__buffers__inv_freq": 569,
    "b___encoder_layer_15_attention_self_rotary_embeddings__buffers__inv_freq": 570,
    "b___encoder_layer_16_attention_self_rotary_embeddings__buffers__inv_freq": 571,
    "b___encoder_layer_17_attention_self_rotary_embeddings__buffers__inv_freq": 572,
    "b___encoder_layer_18_attention_self_rotary_embeddings__buffers__inv_freq": 573,
    "b___encoder_layer_19_attention_self_rotary_embeddings__buffers__inv_freq": 574,
    "b___encoder_layer_20_attention_self_rotary_embeddings__buffers__inv_freq": 575,
    "b___encoder_layer_21_attention_self_rotary_embeddings__buffers__inv_freq": 576,
    "b___encoder_layer_22_attention_self_rotary_embeddings__buffers__inv_freq": 577,
    "b___encoder_layer_23_attention_self_rotary_embeddings__buffers__inv_freq": 578,
    "b___encoder_layer_24_attention_self_rotary_embeddings__buffers__inv_freq": 579,
    "b___encoder_layer_25_attention_self_rotary_embeddings__buffers__inv_freq": 580,
    "b___encoder_layer_26_attention_self_rotary_embeddings__buffers__inv_freq": 581,
    "b___encoder_layer_27_attention_self_rotary_embeddings__buffers__inv_freq": 582,
    "b___encoder_layer_28_attention_self_rotary_embeddings__buffers__inv_freq": 583,
    "b___encoder_layer_29_attention_self_rotary_embeddings__buffers__inv_freq": 584,
    "p_encoder_layer_0_attention_ln_bias": 585,
    "p_encoder_layer_0_ln_weight": 586,
    "p_encoder_layer_0_ln_bias": 587,
    "p_encoder_layer_1_attention_ln_weight": 588,
    "p_encoder_layer_1_attention_ln_bias": 589,
    "p_encoder_layer_1_ln_weight": 590,
    "p_encoder_layer_1_ln_bias": 591,
    "p_encoder_layer_2_attention_ln_weight": 592,
    "p_encoder_layer_2_attention_ln_bias": 593,
    "p_encoder_layer_2_ln_weight": 594,
    "p_encoder_layer_2_ln_bias": 595,
    "p_encoder_layer_3_attention_ln_weight": 596,
    "p_encoder_layer_3_attention_ln_bias": 597,
    "p_encoder_layer_3_ln_weight": 598,
    "p_encoder_layer_3_ln_bias": 599,
    "p_encoder_layer_4_attention_ln_weight": 600,
    "p_encoder_layer_4_attention_ln_bias": 601,
    "p_encoder_layer_4_ln_weight": 602,
    "p_encoder_layer_4_ln_bias": 603,
    "p_encoder_layer_5_attention_ln_weight": 604,
    "p_encoder_layer_5_attention_ln_bias": 605,
    "p_encoder_layer_5_ln_weight": 606,
    "p_encoder_layer_5_ln_bias": 607,
    "p_encoder_layer_6_attention_ln_weight": 608,
    "p_encoder_layer_6_attention_ln_bias": 609,
    "p_encoder_layer_6_ln_weight": 610,
    "p_encoder_layer_6_ln_bias": 611,
    "p_encoder_layer_7_attention_ln_weight": 612,
    "p_encoder_layer_7_attention_ln_bias": 613,
    "p_encoder_layer_7_ln_weight": 614,
    "p_encoder_layer_7_ln_bias": 615,
    "p_encoder_layer_8_attention_ln_weight": 616,
    "p_encoder_layer_8_attention_ln_bias": 617,
    "p_encoder_layer_8_ln_weight": 618,
    "p_encoder_layer_8_ln_bias": 619,
    "p_encoder_layer_9_attention_ln_weight": 620,
    "p_encoder_layer_9_attention_ln_bias": 621,
    "p_encoder_layer_9_ln_weight": 622,
    "p_encoder_layer_9_ln_bias": 623,
    "p_encoder_layer_10_attention_ln_weight": 624,
    "p_encoder_layer_10_attention_ln_bias": 625,
    "p_encoder_layer_10_ln_weight": 626,
    "p_encoder_layer_10_ln_bias": 627,
    "p_encoder_layer_11_attention_ln_weight": 628,
    "p_encoder_layer_11_attention_ln_bias": 629,
    "p_encoder_layer_11_ln_weight": 630,
    "p_encoder_layer_11_ln_bias": 631,
    "p_encoder_layer_12_attention_ln_weight": 632,
    "p_encoder_layer_12_attention_ln_bias": 633,
    "p_encoder_layer_12_ln_weight": 634,
    "p_encoder_layer_12_ln_bias": 635,
    "p_encoder_layer_13_attention_ln_weight": 636,
    "p_encoder_layer_13_attention_ln_bias": 637,
    "p_encoder_layer_13_ln_weight": 638,
    "p_encoder_layer_13_ln_bias": 639,
    "p_encoder_layer_14_attention_ln_weight": 640,
    "p_encoder_layer_14_attention_ln_bias": 641,
    "p_encoder_layer_14_ln_weight": 642,
    "p_encoder_layer_14_ln_bias": 643,
    "p_encoder_layer_15_attention_ln_weight": 644,
    "p_encoder_layer_15_attention_ln_bias": 645,
    "p_encoder_layer_15_ln_weight": 646,
    "p_encoder_layer_15_ln_bias": 647,
    "p_encoder_layer_16_attention_ln_weight": 648,
    "p_encoder_layer_16_attention_ln_bias": 649,
    "p_encoder_layer_16_ln_weight": 650,
    "p_encoder_layer_16_ln_bias": 651,
    "p_encoder_layer_17_attention_ln_weight": 652,
    "p_encoder_layer_17_attention_ln_bias": 653,
    "p_encoder_layer_17_ln_weight": 654,
    "p_encoder_layer_17_ln_bias": 655,
    "p_encoder_layer_18_attention_ln_weight": 656,
    "p_encoder_layer_18_attention_ln_bias": 657,
    "p_encoder_layer_18_ln_weight": 658,
    "p_encoder_layer_18_ln_bias": 659,
    "p_encoder_layer_19_attention_ln_weight": 660,
    "p_encoder_layer_19_attention_ln_bias": 661,
    "p_encoder_layer_19_ln_weight": 662,
    "p_encoder_layer_19_ln_bias": 663,
    "p_encoder_layer_20_attention_ln_weight": 664,
    "p_encoder_layer_20_attention_ln_bias": 665,
    "p_encoder_layer_20_ln_weight": 666,
    "p_encoder_layer_20_ln_bias": 667,
    "p_encoder_layer_21_attention_ln_weight": 668,
    "p_encoder_layer_21_attention_ln_bias": 669,
    "p_encoder_layer_21_ln_weight": 670,
    "p_encoder_layer_21_ln_bias": 671,
    "p_encoder_layer_22_attention_ln_weight": 672,
    "p_encoder_layer_22_attention_ln_bias": 673,
    "p_encoder_layer_22_ln_weight": 674,
    "p_encoder_layer_22_ln_bias": 675,
    "p_encoder_layer_23_attention_ln_weight": 676,
    "p_encoder_layer_23_attention_ln_bias": 677,
    "p_encoder_layer_23_ln_weight": 678,
    "p_encoder_layer_23_ln_bias": 679,
    "p_encoder_ln_weight": 680,
    "p_encoder_ln_bias": 681,
    "p_embeddings_layernorm_weight": 682,
    "p_transformer_layer_0_attention_q_lin_weight": 683,
    "p_transformer_layer_0_attention_q_lin_bias": 684,
    "p_transformer_layer_0_attention_k_lin_weight": 685,
    "p_transformer_layer_0_attention_k_lin_bias": 686,
    "p_transformer_layer_0_attention_v_lin_weight": 687,
    "p_transformer_layer_0_attention_v_lin_bias": 688,
    "p_transformer_layer_0_attention_out_lin_weight": 689,
    "p_transformer_layer_0_attention_out_lin_bias": 690,
    "p_transformer_layer_0_sa_layer_norm_weight": 691,
    "p_transformer_layer_0_sa_layer_norm_bias": 692,
    "p_transformer_layer_0_ffn_lin1_weight": 693,
    "p_transformer_layer_0_ffn_lin1_bias": 694,
    "p_transformer_layer_0_ffn_lin2_weight": 695,
    "p_transformer_layer_0_ffn_lin2_bias": 696,
    "p_transformer_layer_0_output_layer_norm_weight": 697,
    "p_transformer_layer_0_output_layer_norm_bias": 698,
    "p_transformer_layer_1_attention_q_lin_weight": 699,
    "p_transformer_layer_1_attention_q_lin_bias": 700,
    "p_transformer_layer_1_attention_k_lin_weight": 701,
    "p_transformer_layer_1_attention_k_lin_bias": 702,
    "p_transformer_layer_1_attention_v_lin_weight": 703,
    "p_transformer_layer_1_attention_v_lin_bias": 704,
    "p_transformer_layer_1_attention_out_lin_weight": 705,
    "p_transformer_layer_1_attention_out_lin_bias": 706,
    "p_transformer_layer_1_sa_layer_norm_weight": 707,
    "p_transformer_layer_1_sa_layer_norm_bias": 708,
    "p_transformer_layer_1_ffn_lin1_weight": 709,
    "p_transformer_layer_1_ffn_lin1_bias": 710,
    "p_transformer_layer_1_ffn_lin2_weight": 711,
    "p_transformer_layer_1_ffn_lin2_bias": 712,
    "p_transformer_layer_1_output_layer_norm_weight": 713,
    "p_transformer_layer_1_output_layer_norm_bias": 714,
    "p_transformer_layer_2_attention_q_lin_weight": 715,
    "p_transformer_layer_2_attention_q_lin_bias": 716,
    "p_transformer_layer_2_attention_k_lin_weight": 717,
    "p_transformer_layer_2_attention_k_lin_bias": 718,
    "p_transformer_layer_2_attention_v_lin_weight": 719,
    "p_transformer_layer_2_attention_v_lin_bias": 720,
    "p_transformer_layer_2_attention_out_lin_weight": 721,
    "p_transformer_layer_2_attention_out_lin_bias": 722,
    "p_transformer_layer_2_sa_layer_norm_weight": 723,
    "p_transformer_layer_2_sa_layer_norm_bias": 724,
    "p_transformer_layer_2_ffn_lin1_weight": 725,
    "p_transformer_layer_2_ffn_lin1_bias": 726,
    "p_transformer_layer_2_ffn_lin2_weight": 727,
    "p_transformer_layer_2_ffn_lin2_bias": 728,
    "p_transformer_layer_2_output_layer_norm_weight": 729,
    "p_transformer_layer_2_output_layer_norm_bias": 730,
    "p_transformer_layer_3_attention_q_lin_weight": 731,
    "p_transformer_layer_3_attention_q_lin_bias": 732,
    "p_transformer_layer_3_attention_k_lin_weight": 733,
    "p_transformer_layer_3_attention_k_lin_bias": 734,
    "p_transformer_layer_3_attention_v_lin_weight": 735,
    "p_transformer_layer_3_attention_v_lin_bias": 736,
    "p_transformer_layer_3_attention_out_lin_weight": 737,
    "p_transformer_layer_3_attention_out_lin_bias": 738,
    "p_transformer_layer_3_sa_layer_norm_weight": 739,
    "p_transformer_layer_3_sa_layer_norm_bias": 740,
    "p_transformer_layer_3_ffn_lin1_weight": 741,
    "p_transformer_layer_3_ffn_lin1_bias": 742,
    "p_transformer_layer_3_ffn_lin2_weight": 743,
    "p_transformer_layer_3_ffn_lin2_bias": 744,
    "p_transformer_layer_3_output_layer_norm_weight": 745,
    "p_transformer_layer_3_output_layer_norm_bias": 746,
    "p_transformer_layer_4_attention_q_lin_weight": 747,
    "p_transformer_layer_4_attention_q_lin_bias": 748,
    "p_transformer_layer_4_attention_k_lin_weight": 749,
    "p_transformer_layer_4_attention_k_lin_bias": 750,
    "p_transformer_layer_4_attention_v_lin_weight": 751,
    "p_transformer_layer_4_attention_v_lin_bias": 752,
    "p_transformer_layer_4_attention_out_lin_weight": 753,
    "p_transformer_layer_4_attention_out_lin_bias": 754,
    "p_transformer_layer_4_sa_layer_norm_weight": 755,
    "p_transformer_layer_4_sa_layer_norm_bias": 756,
    "p_transformer_layer_4_ffn_lin1_weight": 757,
    "p_transformer_layer_4_ffn_lin1_bias": 758,
    "p_transformer_layer_4_ffn_lin2_weight": 759,
    "p_transformer_layer_4_ffn_lin2_bias": 760,
    "p_transformer_layer_4_output_layer_norm_weight": 761,
    "p_transformer_layer_4_output_layer_norm_bias": 762,
    "p_transformer_layer_5_attention_q_lin_weight": 763,
    "p_transformer_layer_5_attention_q_lin_bias": 764,
    "p_transformer_layer_5_attention_k_lin_weight": 765,
    "p_transformer_layer_5_attention_k_lin_bias": 766,
    "p_transformer_layer_5_attention_v_lin_weight": 767,
    "p_transformer_layer_5_attention_v_lin_bias": 768,
    "p_transformer_layer_5_attention_out_lin_weight": 769,
    "p_transformer_layer_5_attention_out_lin_bias": 770,
    "p_transformer_layer_5_sa_layer_norm_weight": 771,
    "p_transformer_layer_5_sa_layer_norm_bias": 772,
    "p_transformer_layer_5_ffn_lin1_weight": 773,
    "p_transformer_layer_5_ffn_lin1_bias": 774,
    "p_transformer_layer_5_ffn_lin2_weight": 775,
    "p_transformer_layer_5_ffn_lin2_bias": 776,
    "p_transformer_layer_5_output_layer_norm_weight": 777,
    "p_transformer_layer_5_output_layer_norm_bias": 778,
    "p_dense_bias": 779,
    "p_out_proj_weight": 780,
    "p_out_proj_bias": 781,
    "features": 782,
    "p_h_0_ln_1_bias": 783,
    "p_h_0_attn_attention_q_proj_weight": 784,
    "p_h_0_attn_attention_k_proj_weight": 785,
    "p_h_0_attn_attention_v_proj_weight": 786,
    "p_h_0_attn_attention_out_proj_weight": 787,
    "p_h_0_attn_attention_out_proj_bias": 788,
    "p_h_0_ln_2_weight": 789,
    "p_h_0_ln_2_bias": 790,
    "p_h_0_mlp_c_fc_weight": 791,
    "p_h_0_mlp_c_fc_bias": 792,
    "p_h_0_mlp_c_proj_weight": 793,
    "p_h_0_mlp_c_proj_bias": 794,
    "p_h_1_ln_1_weight": 795,
    "p_h_1_ln_1_bias": 796,
    "p_h_1_attn_attention_q_proj_weight": 797,
    "p_h_1_attn_attention_k_proj_weight": 798,
    "p_h_1_attn_attention_v_proj_weight": 799,
    "p_h_1_attn_attention_out_proj_weight": 800,
    "p_h_1_attn_attention_out_proj_bias": 801,
    "p_h_1_ln_2_weight": 802,
    "p_h_1_ln_2_bias": 803,
    "p_h_1_mlp_c_fc_weight": 804,
    "p_h_1_mlp_c_fc_bias": 805,
    "p_h_1_mlp_c_proj_weight": 806,
    "p_h_1_mlp_c_proj_bias": 807,
    "p_h_2_ln_1_weight": 808,
    "p_h_2_ln_1_bias": 809,
    "p_h_2_attn_attention_q_proj_weight": 810,
    "p_h_2_attn_attention_k_proj_weight": 811,
    "p_h_2_attn_attention_v_proj_weight": 812,
    "p_h_2_attn_attention_out_proj_weight": 813,
    "p_h_2_attn_attention_out_proj_bias": 814,
    "p_h_2_ln_2_weight": 815,
    "p_h_2_ln_2_bias": 816,
    "p_h_2_mlp_c_fc_weight": 817,
    "p_h_2_mlp_c_fc_bias": 818,
    "p_h_2_mlp_c_proj_weight": 819,
    "p_h_2_mlp_c_proj_bias": 820,
    "p_h_3_ln_1_weight": 821,
    "p_h_3_ln_1_bias": 822,
    "p_h_3_attn_attention_q_proj_weight": 823,
    "p_h_3_attn_attention_k_proj_weight": 824,
    "p_h_3_attn_attention_v_proj_weight": 825,
    "p_h_3_attn_attention_out_proj_weight": 826,
    "p_h_3_attn_attention_out_proj_bias": 827,
    "p_h_3_ln_2_weight": 828,
    "p_h_3_ln_2_bias": 829,
    "p_h_3_mlp_c_fc_weight": 830,
    "p_h_3_mlp_c_fc_bias": 831,
    "p_h_3_mlp_c_proj_weight": 832,
    "p_h_3_mlp_c_proj_bias": 833,
    "p_h_4_ln_1_weight": 834,
    "p_h_4_ln_1_bias": 835,
    "p_h_4_attn_attention_q_proj_weight": 836,
    "p_h_4_attn_attention_k_proj_weight": 837,
    "p_h_4_attn_attention_v_proj_weight": 838,
    "p_h_4_attn_attention_out_proj_weight": 839,
    "p_h_4_attn_attention_out_proj_bias": 840,
    "p_h_4_ln_2_weight": 841,
    "p_h_4_ln_2_bias": 842,
    "p_h_4_mlp_c_fc_weight": 843,
    "p_h_4_mlp_c_fc_bias": 844,
    "p_h_4_mlp_c_proj_weight": 845,
    "p_h_4_mlp_c_proj_bias": 846,
    "p_h_5_ln_1_weight": 847,
    "p_h_5_ln_1_bias": 848,
    "p_h_5_attn_attention_q_proj_weight": 849,
    "p_h_5_attn_attention_k_proj_weight": 850,
    "p_h_5_attn_attention_v_proj_weight": 851,
    "p_h_5_attn_attention_out_proj_weight": 852,
    "p_h_5_attn_attention_out_proj_bias": 853,
    "p_h_5_ln_2_weight": 854,
    "p_h_5_ln_2_bias": 855,
    "p_h_5_mlp_c_fc_weight": 856,
    "p_h_5_mlp_c_fc_bias": 857,
    "p_h_5_mlp_c_proj_weight": 858,
    "p_h_5_mlp_c_proj_bias": 859,
    "p_h_6_ln_1_weight": 860,
    "p_h_6_ln_1_bias": 861,
    "p_h_6_attn_attention_q_proj_weight": 862,
    "p_h_6_attn_attention_k_proj_weight": 863,
    "p_h_6_attn_attention_v_proj_weight": 864,
    "p_h_6_attn_attention_out_proj_weight": 865,
    "p_h_6_attn_attention_out_proj_bias": 866,
    "p_h_6_ln_2_weight": 867,
    "p_h_6_ln_2_bias": 868,
    "p_h_6_mlp_c_fc_weight": 869,
    "p_h_6_mlp_c_fc_bias": 870,
    "p_h_6_mlp_c_proj_weight": 871,
    "p_h_6_mlp_c_proj_bias": 872,
    "p_h_7_ln_1_weight": 873,
    "p_h_7_ln_1_bias": 874,
    "p_h_7_attn_attention_q_proj_weight": 875,
    "p_h_7_attn_attention_k_proj_weight": 876,
    "p_h_7_attn_attention_v_proj_weight": 877,
    "p_h_7_attn_attention_out_proj_weight": 878,
    "p_h_7_attn_attention_out_proj_bias": 879,
    "p_h_7_ln_2_weight": 880,
    "p_h_7_ln_2_bias": 881,
    "p_h_7_mlp_c_fc_weight": 882,
    "p_h_7_mlp_c_fc_bias": 883,
    "p_h_7_mlp_c_proj_weight": 884,
    "p_h_7_mlp_c_proj_bias": 885,
    "p_h_8_ln_1_weight": 886,
    "p_h_8_ln_1_bias": 887,
    "p_h_8_attn_attention_q_proj_weight": 888,
    "p_h_8_attn_attention_k_proj_weight": 889,
    "p_h_8_attn_attention_v_proj_weight": 890,
    "p_h_8_attn_attention_out_proj_weight": 891,
    "p_h_8_attn_attention_out_proj_bias": 892,
    "p_h_8_ln_2_weight": 893,
    "p_h_8_ln_2_bias": 894,
    "p_h_8_mlp_c_fc_weight": 895,
    "p_h_8_mlp_c_fc_bias": 896,
    "p_h_8_mlp_c_proj_weight": 897,
    "p_h_8_mlp_c_proj_bias": 898,
    "p_h_9_ln_1_weight": 899,
    "p_h_9_ln_1_bias": 900,
    "p_h_9_attn_attention_q_proj_weight": 901,
    "p_h_9_attn_attention_k_proj_weight": 902,
    "p_h_9_attn_attention_v_proj_weight": 903,
    "p_h_9_attn_attention_out_proj_weight": 904,
    "p_h_9_attn_attention_out_proj_bias": 905,
    "p_h_9_ln_2_weight": 906,
    "p_h_9_ln_2_bias": 907,
    "p_h_9_mlp_c_fc_weight": 908,
    "p_h_9_mlp_c_fc_bias": 909,
    "p_h_9_mlp_c_proj_weight": 910,
    "p_h_9_mlp_c_proj_bias": 911,
    "p_h_10_ln_1_weight": 912,
    "p_h_10_ln_1_bias": 913,
    "p_h_10_attn_attention_q_proj_weight": 914,
    "p_h_10_attn_attention_k_proj_weight": 915,
    "p_h_10_attn_attention_v_proj_weight": 916,
    "p_h_10_attn_attention_out_proj_weight": 917,
    "p_h_10_attn_attention_out_proj_bias": 918,
    "p_h_10_ln_2_weight": 919,
    "p_h_10_ln_2_bias": 920,
    "p_h_10_mlp_c_fc_weight": 921,
    "p_h_10_mlp_c_fc_bias": 922,
    "p_h_10_mlp_c_proj_weight": 923,
    "p_h_10_mlp_c_proj_bias": 924,
    "p_h_11_ln_1_weight": 925,
    "p_h_11_ln_1_bias": 926,
    "p_h_11_attn_attention_q_proj_weight": 927,
    "p_h_11_attn_attention_k_proj_weight": 928,
    "p_h_11_attn_attention_v_proj_weight": 929,
    "p_h_11_attn_attention_out_proj_weight": 930,
    "p_h_11_attn_attention_out_proj_bias": 931,
    "p_h_11_ln_2_weight": 932,
    "p_h_11_ln_2_bias": 933,
    "p_h_11_mlp_c_fc_weight": 934,
    "p_h_11_mlp_c_fc_bias": 935,
    "p_h_11_mlp_c_proj_weight": 936,
    "p_h_11_mlp_c_proj_bias": 937,
    "p_ln_f_weight": 938,
    "p_ln_f_bias": 939,
    "b_h_0_attn_attention_bias": 940,
    "b_h_1_attn_attention_bias": 941,
    "b_h_2_attn_attention_bias": 942,
    "b_h_3_attn_attention_bias": 943,
    "b_h_4_attn_attention_bias": 944,
    "b_h_5_attn_attention_bias": 945,
    "b_h_6_attn_attention_bias": 946,
    "b_h_7_attn_attention_bias": 947,
    "b_h_8_attn_attention_bias": 948,
    "b_h_9_attn_attention_bias": 949,
    "b_h_10_attn_attention_bias": 950,
    "b_h_11_attn_attention_bias": 951,
    "c_h_0_attn_attention_lifted_tensor_0": 952,
    "c_h_1_attn_attention_lifted_tensor_1": 953,
    "c_h_2_attn_attention_lifted_tensor_2": 954,
    "c_h_3_attn_attention_lifted_tensor_3": 955,
    "c_h_4_attn_attention_lifted_tensor_4": 956,
    "c_h_5_attn_attention_lifted_tensor_5": 957,
    "c_h_6_attn_attention_lifted_tensor_6": 958,
    "c_h_7_attn_attention_lifted_tensor_7": 959,
    "c_h_8_attn_attention_lifted_tensor_8": 960,
    "c_h_9_attn_attention_lifted_tensor_9": 961,
    "c_h_10_attn_attention_lifted_tensor_10": 962,
    "c_h_11_attn_attention_lifted_tensor_11": 963,
    "p_encoder_layer_12_attention_output_layernorm_weight": 964,
    "p_encoder_layer_12_attention_output_layernorm_bias": 965,
    "p_encoder_layer_12_output_layernorm_weight": 966,
    "p_encoder_layer_12_output_layernorm_bias": 967,
    "p_encoder_layer_13_attention_output_layernorm_weight": 968,
    "p_encoder_layer_13_attention_output_layernorm_bias": 969,
    "p_encoder_layer_13_output_layernorm_weight": 970,
    "p_encoder_layer_13_output_layernorm_bias": 971,
    "p_encoder_layer_14_attention_output_layernorm_weight": 972,
    "p_encoder_layer_14_attention_output_layernorm_bias": 973,
    "p_encoder_layer_14_output_layernorm_weight": 974,
    "p_encoder_layer_14_output_layernorm_bias": 975,
    "p_encoder_layer_15_attention_output_layernorm_weight": 976,
    "p_encoder_layer_15_attention_output_layernorm_bias": 977,
    "p_encoder_layer_15_output_layernorm_weight": 978,
    "p_encoder_layer_15_output_layernorm_bias": 979,
    "p_encoder_layer_16_attention_output_layernorm_weight": 980,
    "p_encoder_layer_16_attention_output_layernorm_bias": 981,
    "p_encoder_layer_16_output_layernorm_weight": 982,
    "p_encoder_layer_16_output_layernorm_bias": 983,
    "p_encoder_layer_17_attention_output_layernorm_weight": 984,
    "p_encoder_layer_17_attention_output_layernorm_bias": 985,
    "p_encoder_layer_17_output_layernorm_weight": 986,
    "p_encoder_layer_17_output_layernorm_bias": 987,
    "p_encoder_layer_18_attention_output_layernorm_weight": 988,
    "p_encoder_layer_18_attention_output_layernorm_bias": 989,
    "p_encoder_layer_18_output_layernorm_weight": 990,
    "p_encoder_layer_18_output_layernorm_bias": 991,
    "p_encoder_layer_19_attention_output_layernorm_weight": 992,
    "p_encoder_layer_19_attention_output_layernorm_bias": 993,
    "p_encoder_layer_19_output_layernorm_weight": 994,
    "p_encoder_layer_19_output_layernorm_bias": 995,
    "p_encoder_layer_20_attention_output_layernorm_weight": 996,
    "p_encoder_layer_20_attention_output_layernorm_bias": 997,
    "p_encoder_layer_20_output_layernorm_weight": 998,
    "p_encoder_layer_20_output_layernorm_bias": 999,
    "p_encoder_layer_21_attention_output_layernorm_weight": 1000,
    "p_encoder_layer_21_attention_output_layernorm_bias": 1001,
    "p_encoder_layer_21_output_layernorm_weight": 1002,
    "p_encoder_layer_21_output_layernorm_bias": 1003,
    "p_encoder_layer_22_attention_output_layernorm_weight": 1004,
    "p_encoder_layer_22_attention_output_layernorm_bias": 1005,
    "p_encoder_layer_22_output_layernorm_weight": 1006,
    "p_encoder_layer_22_output_layernorm_bias": 1007,
    "p_encoder_layer_23_attention_output_layernorm_weight": 1008,
    "p_encoder_layer_23_attention_output_layernorm_bias": 1009,
    "p_encoder_layer_23_output_layernorm_weight": 1010,
    "p_encoder_layer_23_output_layernorm_bias": 1011,
    "p_encoder_layer_24_attention_output_layernorm_weight": 1012,
    "p_encoder_layer_24_attention_output_layernorm_bias": 1013,
    "p_encoder_layer_24_output_layernorm_weight": 1014,
    "p_encoder_layer_24_output_layernorm_bias": 1015,
    "p_encoder_layer_25_attention_output_layernorm_weight": 1016,
    "p_encoder_layer_25_attention_output_layernorm_bias": 1017,
    "p_encoder_layer_25_output_layernorm_weight": 1018,
    "p_encoder_layer_25_output_layernorm_bias": 1019,
    "p_encoder_layer_26_attention_output_layernorm_weight": 1020,
    "p_encoder_layer_26_attention_output_layernorm_bias": 1021,
    "p_encoder_layer_26_output_layernorm_weight": 1022,
    "p_encoder_layer_26_output_layernorm_bias": 1023,
    "p_encoder_layer_27_attention_output_layernorm_weight": 1024,
    "p_encoder_layer_27_attention_output_layernorm_bias": 1025,
    "p_encoder_layer_27_output_layernorm_weight": 1026,
    "p_encoder_layer_27_output_layernorm_bias": 1027,
    "p_encoder_layer_28_attention_output_layernorm_weight": 1028,
    "p_encoder_layer_28_attention_output_layernorm_bias": 1029,
    "p_encoder_layer_28_output_layernorm_weight": 1030,
    "p_encoder_layer_28_output_layernorm_bias": 1031,
    "p_encoder_layer_29_attention_output_layernorm_weight": 1032,
    "p_encoder_layer_29_attention_output_layernorm_bias": 1033,
    "p_encoder_layer_29_output_layernorm_weight": 1034,
    "p_encoder_layer_29_output_layernorm_bias": 1035,
    "p_fn_1_weight": 1036,
    "p_fn_1_bias": 1037,
    "p_getattr_getattr_l__fn_____4_____0___conv1_weight": 1038,
    "p_getattr_getattr_l__fn_____4_____0___bn1_weight": 1039,
    "p_getattr_getattr_l__fn_____4_____0___bn1_bias": 1040,
    "p_getattr_getattr_l__fn_____4_____0___conv2_weight": 1041,
    "p_getattr_getattr_l__fn_____4_____0___bn2_weight": 1042,
    "p_getattr_getattr_l__fn_____4_____0___bn2_bias": 1043,
    "p_getattr_getattr_l__fn_____4_____1___conv1_weight": 1044,
    "p_getattr_getattr_l__fn_____4_____1___bn1_weight": 1045,
    "p_getattr_getattr_l__fn_____4_____1___bn1_bias": 1046,
    "p_getattr_getattr_l__fn_____4_____1___conv2_weight": 1047,
    "p_getattr_getattr_l__fn_____4_____1___bn2_weight": 1048,
    "p_getattr_getattr_l__fn_____4_____1___bn2_bias": 1049,
    "p_getattr_getattr_l__fn_____5_____0___conv1_weight": 1050,
    "p_getattr_getattr_l__fn_____5_____0___bn1_weight": 1051,
    "p_getattr_getattr_l__fn_____5_____0___bn1_bias": 1052,
    "p_getattr_getattr_l__fn_____5_____0___conv2_weight": 1053,
    "p_getattr_getattr_l__fn_____5_____0___bn2_weight": 1054,
    "p_getattr_getattr_l__fn_____5_____0___bn2_bias": 1055,
    "p_getattr_getattr_l__fn_____5_____0___downsample_0_weight": 1056,
    "p_getattr_getattr_l__fn_____5_____0___downsample_1_weight": 1057,
    "p_getattr_getattr_l__fn_____5_____0___downsample_1_bias": 1058,
    "p_getattr_getattr_l__fn_____5_____1___conv1_weight": 1059,
    "p_getattr_getattr_l__fn_____5_____1___bn1_weight": 1060,
    "p_getattr_getattr_l__fn_____5_____1___bn1_bias": 1061,
    "p_getattr_getattr_l__fn_____5_____1___conv2_weight": 1062,
    "p_getattr_getattr_l__fn_____5_____1___bn2_weight": 1063,
    "p_getattr_getattr_l__fn_____5_____1___bn2_bias": 1064,
    "p_getattr_getattr_l__fn_____6_____0___conv1_weight": 1065,
    "p_getattr_getattr_l__fn_____6_____0___bn1_weight": 1066,
    "p_getattr_getattr_l__fn_____6_____0___bn1_bias": 1067,
    "p_getattr_getattr_l__fn_____6_____0___conv2_weight": 1068,
    "p_getattr_getattr_l__fn_____6_____0___bn2_weight": 1069,
    "p_getattr_getattr_l__fn_____6_____0___bn2_bias": 1070,
    "p_getattr_getattr_l__fn_____6_____0___downsample_0_weight": 1071,
    "p_getattr_getattr_l__fn_____6_____0___downsample_1_weight": 1072,
    "p_getattr_getattr_l__fn_____6_____0___downsample_1_bias": 1073,
    "p_getattr_getattr_l__fn_____6_____1___conv1_weight": 1074,
    "p_getattr_getattr_l__fn_____6_____1___bn1_weight": 1075,
    "p_getattr_getattr_l__fn_____6_____1___bn1_bias": 1076,
    "p_getattr_getattr_l__fn_____6_____1___conv2_weight": 1077,
    "p_getattr_getattr_l__fn_____6_____1___bn2_weight": 1078,
    "p_getattr_getattr_l__fn_____6_____1___bn2_bias": 1079,
    "p_getattr_getattr_l__fn_____7_____0___conv1_weight": 1080,
    "p_getattr_getattr_l__fn_____7_____0___bn1_weight": 1081,
    "p_getattr_getattr_l__fn_____7_____0___bn1_bias": 1082,
    "p_getattr_getattr_l__fn_____7_____0___conv2_weight": 1083,
    "p_getattr_getattr_l__fn_____7_____0___bn2_weight": 1084,
    "p_getattr_getattr_l__fn_____7_____0___bn2_bias": 1085,
    "p_getattr_getattr_l__fn_____7_____0___downsample_0_weight": 1086,
    "p_getattr_getattr_l__fn_____7_____0___downsample_1_weight": 1087,
    "p_getattr_getattr_l__fn_____7_____0___downsample_1_bias": 1088,
    "p_getattr_getattr_l__fn_____7_____1___conv1_weight": 1089,
    "p_getattr_getattr_l__fn_____7_____1___bn1_weight": 1090,
    "p_getattr_getattr_l__fn_____7_____1___bn1_bias": 1091,
    "p_getattr_getattr_l__fn_____7_____1___conv2_weight": 1092,
    "p_getattr_getattr_l__fn_____7_____1___bn2_weight": 1093,
    "p_getattr_getattr_l__fn_____7_____1___bn2_bias": 1094,
    "b_fn_1_running_mean": 1095,
    "b_fn_1_running_var": 1096,
    "b_fn_1_num_batches_tracked": 1097,
    "b_getattr_getattr_l__fn_____4_____0___bn1_running_mean": 1098,
    "b_getattr_getattr_l__fn_____4_____0___bn1_running_var": 1099,
    "b_getattr_getattr_l__fn_____4_____0___bn1_num_batches_tracked": 1100,
    "b_getattr_getattr_l__fn_____4_____0___bn2_running_mean": 1101,
    "b_getattr_getattr_l__fn_____4_____0___bn2_running_var": 1102,
    "b_getattr_getattr_l__fn_____4_____0___bn2_num_batches_tracked": 1103,
    "b_getattr_getattr_l__fn_____4_____1___bn1_running_mean": 1104,
    "b_getattr_getattr_l__fn_____4_____1___bn1_running_var": 1105,
    "b_getattr_getattr_l__fn_____4_____1___bn1_num_batches_tracked": 1106,
    "b_getattr_getattr_l__fn_____4_____1___bn2_running_mean": 1107,
    "b_getattr_getattr_l__fn_____4_____1___bn2_running_var": 1108,
    "b_getattr_getattr_l__fn_____4_____1___bn2_num_batches_tracked": 1109,
    "b_getattr_getattr_l__fn_____5_____0___bn1_running_mean": 1110,
    "b_getattr_getattr_l__fn_____5_____0___bn1_running_var": 1111,
    "b_getattr_getattr_l__fn_____5_____0___bn1_num_batches_tracked": 1112,
    "b_getattr_getattr_l__fn_____5_____0___bn2_running_mean": 1113,
    "b_getattr_getattr_l__fn_____5_____0___bn2_running_var": 1114,
    "b_getattr_getattr_l__fn_____5_____0___bn2_num_batches_tracked": 1115,
    "b_getattr_getattr_l__fn_____5_____0___downsample_1_running_mean": 1116,
    "b_getattr_getattr_l__fn_____5_____0___downsample_1_running_var": 1117,
    "b_getattr_getattr_l__fn_____5_____0___downsample_1_num_batches_tracked": 1118,
    "b_getattr_getattr_l__fn_____5_____1___bn1_running_mean": 1119,
    "b_getattr_getattr_l__fn_____5_____1___bn1_running_var": 1120,
    "b_getattr_getattr_l__fn_____5_____1___bn1_num_batches_tracked": 1121,
    "b_getattr_getattr_l__fn_____5_____1___bn2_running_mean": 1122,
    "b_getattr_getattr_l__fn_____5_____1___bn2_running_var": 1123,
    "b_getattr_getattr_l__fn_____5_____1___bn2_num_batches_tracked": 1124,
    "b_getattr_getattr_l__fn_____6_____0___bn1_running_mean": 1125,
    "b_getattr_getattr_l__fn_____6_____0___bn1_running_var": 1126,
    "b_getattr_getattr_l__fn_____6_____0___bn1_num_batches_tracked": 1127,
    "b_getattr_getattr_l__fn_____6_____0___bn2_running_mean": 1128,
    "b_getattr_getattr_l__fn_____6_____0___bn2_running_var": 1129,
    "b_getattr_getattr_l__fn_____6_____0___bn2_num_batches_tracked": 1130,
    "b_getattr_getattr_l__fn_____6_____0___downsample_1_running_mean": 1131,
    "b_getattr_getattr_l__fn_____6_____0___downsample_1_running_var": 1132,
    "b_getattr_getattr_l__fn_____6_____0___downsample_1_num_batches_tracked": 1133,
    "b_getattr_getattr_l__fn_____6_____1___bn1_running_mean": 1134,
    "b_getattr_getattr_l__fn_____6_____1___bn1_running_var": 1135,
    "b_getattr_getattr_l__fn_____6_____1___bn1_num_batches_tracked": 1136,
    "b_getattr_getattr_l__fn_____6_____1___bn2_running_mean": 1137,
    "b_getattr_getattr_l__fn_____6_____1___bn2_running_var": 1138,
    "b_getattr_getattr_l__fn_____6_____1___bn2_num_batches_tracked": 1139,
    "b_getattr_getattr_l__fn_____7_____0___bn1_running_mean": 1140,
    "b_getattr_getattr_l__fn_____7_____0___bn1_running_var": 1141,
    "b_getattr_getattr_l__fn_____7_____0___bn1_num_batches_tracked": 1142,
    "b_getattr_getattr_l__fn_____7_____0___bn2_running_mean": 1143,
    "b_getattr_getattr_l__fn_____7_____0___bn2_running_var": 1144,
    "b_getattr_getattr_l__fn_____7_____0___bn2_num_batches_tracked": 1145,
    "b_getattr_getattr_l__fn_____7_____0___downsample_1_running_mean": 1146,
    "b_getattr_getattr_l__fn_____7_____0___downsample_1_running_var": 1147,
    "b_getattr_getattr_l__fn_____7_____0___downsample_1_num_batches_tracked": 1148,
    "b_getattr_getattr_l__fn_____7_____1___bn1_running_mean": 1149,
    "b_getattr_getattr_l__fn_____7_____1___bn1_running_var": 1150,
    "b_getattr_getattr_l__fn_____7_____1___bn1_num_batches_tracked": 1151,
    "b_getattr_getattr_l__fn_____7_____1___bn2_running_mean": 1152,
    "b_getattr_getattr_l__fn_____7_____1___bn2_running_var": 1153,
    "b_getattr_getattr_l__fn_____7_____1___bn2_num_batches_tracked": 1154
  },
  "index_to_param_name": {
    "10": "p_embeddings_layernorm_bias",
    "11": "p_encoder_layer_0_attention_self_query_weight",
    "12": "p_encoder_layer_0_attention_self_query_bias",
    "13": "p_encoder_layer_0_attention_self_key_weight",
    "14": "p_encoder_layer_0_attention_self_key_bias",
    "15": "p_encoder_layer_0_attention_self_value_weight",
    "16": "p_encoder_layer_0_attention_self_value_bias",
    "17": "p_encoder_layer_0_attention_output_dense_weight",
    "18": "p_encoder_layer_0_attention_output_dense_bias",
    "19": "p_encoder_layer_0_attention_output_layernorm_weight",
    "20": "p_encoder_layer_0_attention_output_layernorm_bias",
    "21": "p_encoder_layer_0_intermediate_dense_weight",
    "22": "p_encoder_layer_0_intermediate_dense_bias",
    "23": "p_encoder_layer_0_output_dense_weight",
    "24": "p_encoder_layer_0_output_dense_bias",
    "25": "p_encoder_layer_0_output_layernorm_weight",
    "26": "p_encoder_layer_0_output_layernorm_bias",
    "27": "p_encoder_layer_1_attention_self_query_weight",
    "28": "p_encoder_layer_1_attention_self_query_bias",
    "29": "p_encoder_layer_1_attention_self_key_weight",
    "30": "p_encoder_layer_1_attention_self_key_bias",
    "31": "p_encoder_layer_1_attention_self_value_weight",
    "32": "p_encoder_layer_1_attention_self_value_bias",
    "33": "p_encoder_layer_1_attention_output_dense_weight",
    "34": "p_encoder_layer_1_attention_output_dense_bias",
    "35": "p_encoder_layer_1_attention_output_layernorm_weight",
    "36": "p_encoder_layer_1_attention_output_layernorm_bias",
    "37": "p_encoder_layer_1_intermediate_dense_weight",
    "38": "p_encoder_layer_1_intermediate_dense_bias",
    "39": "p_encoder_layer_1_output_dense_weight",
    "40": "p_encoder_layer_1_output_dense_bias",
    "41": "p_encoder_layer_1_output_layernorm_weight",
    "42": "p_encoder_layer_1_output_layernorm_bias",
    "43": "p_encoder_layer_2_attention_self_query_weight",
    "44": "p_encoder_layer_2_attention_self_query_bias",
    "45": "p_encoder_layer_2_attention_self_key_weight",
    "46": "p_encoder_layer_2_attention_self_key_bias",
    "47": "p_encoder_layer_2_attention_self_value_weight",
    "48": "p_encoder_layer_2_attention_self_value_bias",
    "49": "p_encoder_layer_2_attention_output_dense_weight",
    "50": "p_encoder_layer_2_attention_output_dense_bias",
    "51": "p_encoder_layer_2_attention_output_layernorm_weight",
    "52": "p_encoder_layer_2_attention_output_layernorm_bias",
    "53": "p_encoder_layer_2_intermediate_dense_weight",
    "54": "p_encoder_layer_2_intermediate_dense_bias",
    "55": "p_encoder_layer_2_output_dense_weight",
    "56": "p_encoder_layer_2_output_dense_bias",
    "57": "p_encoder_layer_2_output_layernorm_weight",
    "58": "p_encoder_layer_2_output_layernorm_bias",
    "59": "p_encoder_layer_3_attention_self_query_weight",
    "60": "p_encoder_layer_3_attention_self_query_bias",
    "61": "p_encoder_layer_3_attention_self_key_weight",
    "62": "p_encoder_layer_3_attention_self_key_bias",
    "63": "p_encoder_layer_3_attention_self_value_weight",
    "64": "p_encoder_layer_3_attention_self_value_bias",
    "65": "p_encoder_layer_3_attention_output_dense_weight",
    "66": "p_encoder_layer_3_attention_output_dense_bias",
    "67": "p_encoder_layer_3_attention_output_layernorm_weight",
    "68": "p_encoder_layer_3_attention_output_layernorm_bias",
    "69": "p_encoder_layer_3_intermediate_dense_weight",
    "70": "p_encoder_layer_3_intermediate_dense_bias",
    "71": "p_encoder_layer_3_output_dense_weight",
    "72": "p_encoder_layer_3_output_dense_bias",
    "73": "p_encoder_layer_3_output_layernorm_weight",
    "74": "p_encoder_layer_3_output_layernorm_bias",
    "75": "p_encoder_layer_4_attention_self_query_weight",
    "76": "p_encoder_layer_4_attention_self_query_bias",
    "77": "p_encoder_layer_4_attention_self_key_weight",
    "78": "p_encoder_layer_4_attention_self_key_bias",
    "79": "p_encoder_layer_4_attention_self_value_weight",
    "80": "p_encoder_layer_4_attention_self_value_bias",
    "81": "p_encoder_layer_4_attention_output_dense_weight",
    "82": "p_encoder_layer_4_attention_output_dense_bias",
    "83": "p_encoder_layer_4_attention_output_layernorm_weight",
    "84": "p_encoder_layer_4_attention_output_layernorm_bias",
    "85": "p_encoder_layer_4_intermediate_dense_weight",
    "86": "p_encoder_layer_4_intermediate_dense_bias",
    "87": "p_encoder_layer_4_output_dense_weight",
    "88": "p_encoder_layer_4_output_dense_bias",
    "89": "p_encoder_layer_4_output_layernorm_weight",
    "90": "p_encoder_layer_4_output_layernorm_bias",
    "91": "p_encoder_layer_5_attention_self_query_weight",
    "92": "p_encoder_layer_5_attention_self_query_bias",
    "93": "p_encoder_layer_5_attention_self_key_weight",
    "94": "p_encoder_layer_5_attention_self_key_bias",
    "95": "p_encoder_layer_5_attention_self_value_weight",
    "96": "p_encoder_layer_5_attention_self_value_bias",
    "97": "p_encoder_layer_5_attention_output_dense_weight",
    "98": "p_encoder_layer_5_attention_output_dense_bias",
    "99": "p_encoder_layer_5_attention_output_layernorm_weight",
    "100": "p_encoder_layer_5_attention_output_layernorm_bias",
    "101": "p_encoder_layer_5_intermediate_dense_weight",
    "102": "p_encoder_layer_5_intermediate_dense_bias",
    "103": "p_encoder_layer_5_output_dense_weight",
    "104": "p_encoder_layer_5_output_dense_bias",
    "105": "p_encoder_layer_5_output_layernorm_weight",
    "106": "p_encoder_layer_5_output_layernorm_bias",
    "107": "p_encoder_layer_6_attention_self_query_weight",
    "108": "p_encoder_layer_6_attention_self_query_bias",
    "109": "p_encoder_layer_6_attention_self_key_weight",
    "110": "p_encoder_layer_6_attention_self_key_bias",
    "111": "p_encoder_layer_6_attention_self_value_weight",
    "112": "p_encoder_layer_6_attention_self_value_bias",
    "113": "p_encoder_layer_6_attention_output_dense_weight",
    "114": "p_encoder_layer_6_attention_output_dense_bias",
    "115": "p_encoder_layer_6_attention_output_layernorm_weight",
    "116": "p_encoder_layer_6_attention_output_layernorm_bias",
    "117": "p_encoder_layer_6_intermediate_dense_weight",
    "118": "p_encoder_layer_6_intermediate_dense_bias",
    "119": "p_encoder_layer_6_output_dense_weight",
    "120": "p_encoder_layer_6_output_dense_bias",
    "121": "p_encoder_layer_6_output_layernorm_weight",
    "122": "p_encoder_layer_6_output_layernorm_bias",
    "123": "p_encoder_layer_7_attention_self_query_weight",
    "124": "p_encoder_layer_7_attention_self_query_bias",
    "125": "p_encoder_layer_7_attention_self_key_weight",
    "126": "p_encoder_layer_7_attention_self_key_bias",
    "127": "p_encoder_layer_7_attention_self_value_weight",
    "128": "p_encoder_layer_7_attention_self_value_bias",
    "129": "p_encoder_layer_7_attention_output_dense_weight",
    "130": "p_encoder_layer_7_attention_output_dense_bias",
    "131": "p_encoder_layer_7_attention_output_layernorm_weight",
    "132": "p_encoder_layer_7_attention_output_layernorm_bias",
    "133": "p_encoder_layer_7_intermediate_dense_weight",
    "134": "p_encoder_layer_7_intermediate_dense_bias",
    "135": "p_encoder_layer_7_output_dense_weight",
    "136": "p_encoder_layer_7_output_dense_bias",
    "137": "p_encoder_layer_7_output_layernorm_weight",
    "138": "p_encoder_layer_7_output_layernorm_bias",
    "139": "p_encoder_layer_8_attention_self_query_weight",
    "140": "p_encoder_layer_8_attention_self_query_bias",
    "141": "p_encoder_layer_8_attention_self_key_weight",
    "142": "p_encoder_layer_8_attention_self_key_bias",
    "143": "p_encoder_layer_8_attention_self_value_weight",
    "144": "p_encoder_layer_8_attention_self_value_bias",
    "145": "p_encoder_layer_8_attention_output_dense_weight",
    "146": "p_encoder_layer_8_attention_output_dense_bias",
    "147": "p_encoder_layer_8_attention_output_layernorm_weight",
    "148": "p_encoder_layer_8_attention_output_layernorm_bias",
    "149": "p_encoder_layer_8_intermediate_dense_weight",
    "150": "p_encoder_layer_8_intermediate_dense_bias",
    "151": "p_encoder_layer_8_output_dense_weight",
    "152": "p_encoder_layer_8_output_dense_bias",
    "153": "p_encoder_layer_8_output_layernorm_weight",
    "154": "p_encoder_layer_8_output_layernorm_bias",
    "155": "p_encoder_layer_9_attention_self_query_weight",
    "156": "p_encoder_layer_9_attention_self_query_bias",
    "157": "p_encoder_layer_9_attention_self_key_weight",
    "158": "p_encoder_layer_9_attention_self_key_bias",
    "159": "p_encoder_layer_9_attention_self_value_weight",
    "160": "p_encoder_layer_9_attention_self_value_bias",
    "161": "p_encoder_layer_9_attention_output_dense_weight",
    "162": "p_encoder_layer_9_attention_output_dense_bias",
    "163": "p_encoder_layer_9_attention_output_layernorm_weight",
    "164": "p_encoder_layer_9_attention_output_layernorm_bias",
    "165": "p_encoder_layer_9_intermediate_dense_weight",
    "166": "p_encoder_layer_9_intermediate_dense_bias",
    "167": "p_encoder_layer_9_output_dense_weight",
    "168": "p_encoder_layer_9_output_dense_bias",
    "169": "p_encoder_layer_9_output_layernorm_weight",
    "170": "p_encoder_layer_9_output_layernorm_bias",
    "171": "p_encoder_layer_10_attention_self_query_weight",
    "172": "p_encoder_layer_10_attention_self_query_bias",
    "173": "p_encoder_layer_10_attention_self_key_weight",
    "174": "p_encoder_layer_10_attention_self_key_bias",
    "175": "p_encoder_layer_10_attention_self_value_weight",
    "176": "p_encoder_layer_10_attention_self_value_bias",
    "177": "p_encoder_layer_10_attention_output_dense_weight",
    "178": "p_encoder_layer_10_attention_output_dense_bias",
    "179": "p_encoder_layer_10_attention_output_layernorm_weight",
    "180": "p_encoder_layer_10_attention_output_layernorm_bias",
    "181": "p_encoder_layer_10_intermediate_dense_weight",
    "182": "p_encoder_layer_10_intermediate_dense_bias",
    "183": "p_encoder_layer_10_output_dense_weight",
    "184": "p_encoder_layer_10_output_dense_bias",
    "185": "p_encoder_layer_10_output_layernorm_weight",
    "186": "p_encoder_layer_10_output_layernorm_bias",
    "187": "p_encoder_layer_11_attention_self_query_weight",
    "188": "p_encoder_layer_11_attention_self_query_bias",
    "189": "p_encoder_layer_11_attention_self_key_weight",
    "190": "p_encoder_layer_11_attention_self_key_bias",
    "191": "p_encoder_layer_11_attention_self_value_weight",
    "192": "p_encoder_layer_11_attention_self_value_bias",
    "193": "p_encoder_layer_11_attention_output_dense_weight",
    "194": "p_encoder_layer_11_attention_output_dense_bias",
    "195": "p_encoder_layer_11_attention_output_layernorm_weight",
    "196": "p_encoder_layer_11_attention_output_layernorm_bias",
    "197": "p_encoder_layer_11_intermediate_dense_weight",
    "198": "p_encoder_layer_11_intermediate_dense_bias",
    "199": "p_encoder_layer_11_output_dense_weight",
    "200": "p_encoder_layer_11_output_dense_bias",
    "201": "p_encoder_layer_11_output_layernorm_weight",
    "202": "p_encoder_layer_11_output_layernorm_bias",
    "203": "p_pooler_dense_weight",
    "204": "p_pooler_dense_bias",
    "205": "b_embeddings_position_ids",
    "206": "c_lifted_tensor_0",
    "207": "input_ids",
    "208": "token_type_ids",
    "209": "attention_mask",
    "210": "use_cache",
    "211": "p_fn_bias",
    "212": "input",
    "213": "p_predictions_transform_dense_bias",
    "214": "p_predictions_transform_layernorm_weight",
    "215": "p_predictions_transform_layernorm_bias",
    "216": "p_predictions_decoder_weight",
    "217": "p_predictions_decoder_bias",
    "218": "sequence_output",
    "219": "p_encoder_layer_0_layernorm_weight",
    "220": "p_encoder_layer_0_layernorm_bias",
    "221": "p_encoder_layer_1_attention_layernorm_weight",
    "222": "p_encoder_layer_1_attention_layernorm_bias",
    "223": "p_encoder_layer_1_layernorm_weight",
    "224": "p_encoder_layer_1_layernorm_bias",
    "225": "p_encoder_layer_2_attention_layernorm_weight",
    "226": "p_encoder_layer_2_attention_layernorm_bias",
    "227": "p_encoder_layer_2_layernorm_weight",
    "228": "p_encoder_layer_2_layernorm_bias",
    "229": "p_encoder_layer_3_attention_layernorm_weight",
    "230": "p_encoder_layer_3_attention_layernorm_bias",
    "231": "p_encoder_layer_3_layernorm_weight",
    "232": "p_encoder_layer_3_layernorm_bias",
    "233": "p_encoder_layer_4_attention_layernorm_weight",
    "234": "p_encoder_layer_4_attention_layernorm_bias",
    "235": "p_encoder_layer_4_layernorm_weight",
    "236": "p_encoder_layer_4_layernorm_bias",
    "237": "p_encoder_layer_5_attention_layernorm_weight",
    "238": "p_encoder_layer_5_attention_layernorm_bias",
    "239": "p_encoder_layer_5_layernorm_weight",
    "240": "p_encoder_layer_5_layernorm_bias",
    "241": "p_encoder_layer_6_attention_layernorm_weight",
    "242": "p_encoder_layer_6_attention_layernorm_bias",
    "243": "p_encoder_layer_6_layernorm_weight",
    "244": "p_encoder_layer_6_layernorm_bias",
    "245": "p_encoder_layer_7_attention_layernorm_weight",
    "246": "p_encoder_layer_7_attention_layernorm_bias",
    "247": "p_encoder_layer_7_layernorm_weight",
    "248": "p_encoder_layer_7_layernorm_bias",
    "249": "p_encoder_layer_8_attention_layernorm_weight",
    "250": "p_encoder_layer_8_attention_layernorm_bias",
    "251": "p_encoder_layer_8_layernorm_weight",
    "252": "p_encoder_layer_8_layernorm_bias",
    "253": "p_encoder_layer_9_attention_layernorm_weight",
    "254": "p_encoder_layer_9_attention_layernorm_bias",
    "255": "p_encoder_layer_9_layernorm_weight",
    "256": "p_encoder_layer_9_layernorm_bias",
    "257": "p_encoder_layer_10_attention_layernorm_weight",
    "258": "p_encoder_layer_10_attention_layernorm_bias",
    "259": "p_encoder_layer_10_layernorm_weight",
    "260": "p_encoder_layer_10_layernorm_bias",
    "261": "p_encoder_layer_11_attention_layernorm_weight",
    "262": "p_encoder_layer_11_attention_layernorm_bias",
    "263": "p_encoder_layer_11_layernorm_weight",
    "264": "p_encoder_layer_11_layernorm_bias",
    "265": "p_encoder_layer_12_attention_layernorm_weight",
    "266": "p_encoder_layer_12_attention_layernorm_bias",
    "267": "p_encoder_layer_12_attention_self_query_weight",
    "268": "p_encoder_layer_12_attention_self_query_bias",
    "269": "p_encoder_layer_12_attention_self_key_weight",
    "270": "p_encoder_layer_12_attention_self_key_bias",
    "271": "p_encoder_layer_12_attention_self_value_weight",
    "272": "p_encoder_layer_12_attention_self_value_bias",
    "273": "p_encoder_layer_12_attention_output_dense_weight",
    "274": "p_encoder_layer_12_attention_output_dense_bias",
    "275": "p_encoder_layer_12_layernorm_weight",
    "276": "p_encoder_layer_12_layernorm_bias",
    "277": "p_encoder_layer_12_intermediate_dense_weight",
    "278": "p_encoder_layer_12_intermediate_dense_bias",
    "279": "p_encoder_layer_12_output_dense_weight",
    "280": "p_encoder_layer_12_output_dense_bias",
    "281": "p_encoder_layer_13_attention_layernorm_weight",
    "282": "p_encoder_layer_13_attention_layernorm_bias",
    "283": "p_encoder_layer_13_attention_self_query_weight",
    "284": "p_encoder_layer_13_attention_self_query_bias",
    "285": "p_encoder_layer_13_attention_self_key_weight",
    "286": "p_encoder_layer_13_attention_self_key_bias",
    "287": "p_encoder_layer_13_attention_self_value_weight",
    "288": "p_encoder_layer_13_attention_self_value_bias",
    "289": "p_encoder_layer_13_attention_output_dense_weight",
    "290": "p_encoder_layer_13_attention_output_dense_bias",
    "291": "p_encoder_layer_13_layernorm_weight",
    "292": "p_encoder_layer_13_layernorm_bias",
    "293": "p_encoder_layer_13_intermediate_dense_weight",
    "294": "p_encoder_layer_13_intermediate_dense_bias",
    "295": "p_encoder_layer_13_output_dense_weight",
    "296": "p_encoder_layer_13_output_dense_bias",
    "297": "p_encoder_layer_14_attention_layernorm_weight",
    "298": "p_encoder_layer_14_attention_layernorm_bias",
    "299": "p_encoder_layer_14_attention_self_query_weight",
    "300": "p_encoder_layer_14_attention_self_query_bias",
    "301": "p_encoder_layer_14_attention_self_key_weight",
    "302": "p_encoder_layer_14_attention_self_key_bias",
    "303": "p_encoder_layer_14_attention_self_value_weight",
    "304": "p_encoder_layer_14_attention_self_value_bias",
    "305": "p_encoder_layer_14_attention_output_dense_weight",
    "306": "p_encoder_layer_14_attention_output_dense_bias",
    "307": "p_encoder_layer_14_layernorm_weight",
    "308": "p_encoder_layer_14_layernorm_bias",
    "309": "p_encoder_layer_14_intermediate_dense_weight",
    "310": "p_encoder_layer_14_intermediate_dense_bias",
    "311": "p_encoder_layer_14_output_dense_weight",
    "312": "p_encoder_layer_14_output_dense_bias",
    "313": "p_encoder_layer_15_attention_layernorm_weight",
    "314": "p_encoder_layer_15_attention_layernorm_bias",
    "315": "p_encoder_layer_15_attention_self_query_weight",
    "316": "p_encoder_layer_15_attention_self_query_bias",
    "317": "p_encoder_layer_15_attention_self_key_weight",
    "318": "p_encoder_layer_15_attention_self_key_bias",
    "319": "p_encoder_layer_15_attention_self_value_weight",
    "320": "p_encoder_layer_15_attention_self_value_bias",
    "321": "p_encoder_layer_15_attention_output_dense_weight",
    "322": "p_encoder_layer_15_attention_output_dense_bias",
    "323": "p_encoder_layer_15_layernorm_weight",
    "324": "p_encoder_layer_15_layernorm_bias",
    "325": "p_encoder_layer_15_intermediate_dense_weight",
    "326": "p_encoder_layer_15_intermediate_dense_bias",
    "327": "p_encoder_layer_15_output_dense_weight",
    "328": "p_encoder_layer_15_output_dense_bias",
    "329": "p_encoder_layer_16_attention_layernorm_weight",
    "330": "p_encoder_layer_16_attention_layernorm_bias",
    "331": "p_encoder_layer_16_attention_self_query_weight",
    "332": "p_encoder_layer_16_attention_self_query_bias",
    "333": "p_encoder_layer_16_attention_self_key_weight",
    "334": "p_encoder_layer_16_attention_self_key_bias",
    "335": "p_encoder_layer_16_attention_self_value_weight",
    "336": "p_encoder_layer_16_attention_self_value_bias",
    "337": "p_encoder_layer_16_attention_output_dense_weight",
    "338": "p_encoder_layer_16_attention_output_dense_bias",
    "339": "p_encoder_layer_16_layernorm_weight",
    "340": "p_encoder_layer_16_layernorm_bias",
    "341": "p_encoder_layer_16_intermediate_dense_weight",
    "342": "p_encoder_layer_16_intermediate_dense_bias",
    "343": "p_encoder_layer_16_output_dense_weight",
    "344": "p_encoder_layer_16_output_dense_bias",
    "345": "p_encoder_layer_17_attention_layernorm_weight",
    "346": "p_encoder_layer_17_attention_layernorm_bias",
    "347": "p_encoder_layer_17_attention_self_query_weight",
    "348": "p_encoder_layer_17_attention_self_query_bias",
    "349": "p_encoder_layer_17_attention_self_key_weight",
    "350": "p_encoder_layer_17_attention_self_key_bias",
    "351": "p_encoder_layer_17_attention_self_value_weight",
    "352": "p_encoder_layer_17_attention_self_value_bias",
    "353": "p_encoder_layer_17_attention_output_dense_weight",
    "354": "p_encoder_layer_17_attention_output_dense_bias",
    "355": "p_encoder_layer_17_layernorm_weight",
    "356": "p_encoder_layer_17_layernorm_bias",
    "357": "p_encoder_layer_17_intermediate_dense_weight",
    "358": "p_encoder_layer_17_intermediate_dense_bias",
    "359": "p_encoder_layer_17_output_dense_weight",
    "360": "p_encoder_layer_17_output_dense_bias",
    "361": "p_encoder_layer_18_attention_layernorm_weight",
    "362": "p_encoder_layer_18_attention_layernorm_bias",
    "363": "p_encoder_layer_18_attention_self_query_weight",
    "364": "p_encoder_layer_18_attention_self_query_bias",
    "365": "p_encoder_layer_18_attention_self_key_weight",
    "366": "p_encoder_layer_18_attention_self_key_bias",
    "367": "p_encoder_layer_18_attention_self_value_weight",
    "368": "p_encoder_layer_18_attention_self_value_bias",
    "369": "p_encoder_layer_18_attention_output_dense_weight",
    "370": "p_encoder_layer_18_attention_output_dense_bias",
    "371": "p_encoder_layer_18_layernorm_weight",
    "372": "p_encoder_layer_18_layernorm_bias",
    "373": "p_encoder_layer_18_intermediate_dense_weight",
    "374": "p_encoder_layer_18_intermediate_dense_bias",
    "375": "p_encoder_layer_18_output_dense_weight",
    "376": "p_encoder_layer_18_output_dense_bias",
    "377": "p_encoder_layer_19_attention_layernorm_weight",
    "378": "p_encoder_layer_19_attention_layernorm_bias",
    "379": "p_encoder_layer_19_attention_self_query_weight",
    "380": "p_encoder_layer_19_attention_self_query_bias",
    "381": "p_encoder_layer_19_attention_self_key_weight",
    "382": "p_encoder_layer_19_attention_self_key_bias",
    "383": "p_encoder_layer_19_attention_self_value_weight",
    "384": "p_encoder_layer_19_attention_self_value_bias",
    "385": "p_encoder_layer_19_attention_output_dense_weight",
    "386": "p_encoder_layer_19_attention_output_dense_bias",
    "387": "p_encoder_layer_19_layernorm_weight",
    "388": "p_encoder_layer_19_layernorm_bias",
    "389": "p_encoder_layer_19_intermediate_dense_weight",
    "390": "p_encoder_layer_19_intermediate_dense_bias",
    "391": "p_encoder_layer_19_output_dense_weight",
    "392": "p_encoder_layer_19_output_dense_bias",
    "393": "p_encoder_layer_20_attention_layernorm_weight",
    "394": "p_encoder_layer_20_attention_layernorm_bias",
    "395": "p_encoder_layer_20_attention_self_query_weight",
    "396": "p_encoder_layer_20_attention_self_query_bias",
    "397": "p_encoder_layer_20_attention_self_key_weight",
    "398": "p_encoder_layer_20_attention_self_key_bias",
    "399": "p_encoder_layer_20_attention_self_value_weight",
    "400": "p_encoder_layer_20_attention_self_value_bias",
    "401": "p_encoder_layer_20_attention_output_dense_weight",
    "402": "p_encoder_layer_20_attention_output_dense_bias",
    "403": "p_encoder_layer_20_layernorm_weight",
    "404": "p_encoder_layer_20_layernorm_bias",
    "405": "p_encoder_layer_20_intermediate_dense_weight",
    "406": "p_encoder_layer_20_intermediate_dense_bias",
    "407": "p_encoder_layer_20_output_dense_weight",
    "408": "p_encoder_layer_20_output_dense_bias",
    "409": "p_encoder_layer_21_attention_layernorm_weight",
    "410": "p_encoder_layer_21_attention_layernorm_bias",
    "411": "p_encoder_layer_21_attention_self_query_weight",
    "412": "p_encoder_layer_21_attention_self_query_bias",
    "413": "p_encoder_layer_21_attention_self_key_weight",
    "414": "p_encoder_layer_21_attention_self_key_bias",
    "415": "p_encoder_layer_21_attention_self_value_weight",
    "416": "p_encoder_layer_21_attention_self_value_bias",
    "417": "p_encoder_layer_21_attention_output_dense_weight",
    "418": "p_encoder_layer_21_attention_output_dense_bias",
    "419": "p_encoder_layer_21_layernorm_weight",
    "420": "p_encoder_layer_21_layernorm_bias",
    "421": "p_encoder_layer_21_intermediate_dense_weight",
    "422": "p_encoder_layer_21_intermediate_dense_bias",
    "423": "p_encoder_layer_21_output_dense_weight",
    "424": "p_encoder_layer_21_output_dense_bias",
    "425": "p_encoder_layer_22_attention_layernorm_weight",
    "426": "p_encoder_layer_22_attention_layernorm_bias",
    "427": "p_encoder_layer_22_attention_self_query_weight",
    "428": "p_encoder_layer_22_attention_self_query_bias",
    "429": "p_encoder_layer_22_attention_self_key_weight",
    "430": "p_encoder_layer_22_attention_self_key_bias",
    "431": "p_encoder_layer_22_attention_self_value_weight",
    "432": "p_encoder_layer_22_attention_self_value_bias",
    "433": "p_encoder_layer_22_attention_output_dense_weight",
    "434": "p_encoder_layer_22_attention_output_dense_bias",
    "435": "p_encoder_layer_22_layernorm_weight",
    "436": "p_encoder_layer_22_layernorm_bias",
    "437": "p_encoder_layer_22_intermediate_dense_weight",
    "438": "p_encoder_layer_22_intermediate_dense_bias",
    "439": "p_encoder_layer_22_output_dense_weight",
    "440": "p_encoder_layer_22_output_dense_bias",
    "441": "p_encoder_layer_23_attention_layernorm_weight",
    "442": "p_encoder_layer_23_attention_layernorm_bias",
    "443": "p_encoder_layer_23_attention_self_query_weight",
    "444": "p_encoder_layer_23_attention_self_query_bias",
    "445": "p_encoder_layer_23_attention_self_key_weight",
    "446": "p_encoder_layer_23_attention_self_key_bias",
    "447": "p_encoder_layer_23_attention_self_value_weight",
    "448": "p_encoder_layer_23_attention_self_value_bias",
    "449": "p_encoder_layer_23_attention_output_dense_weight",
    "450": "p_encoder_layer_23_attention_output_dense_bias",
    "451": "p_encoder_layer_23_layernorm_weight",
    "452": "p_encoder_layer_23_layernorm_bias",
    "453": "p_encoder_layer_23_intermediate_dense_weight",
    "454": "p_encoder_layer_23_intermediate_dense_bias",
    "455": "p_encoder_layer_23_output_dense_weight",
    "456": "p_encoder_layer_23_output_dense_bias",
    "457": "p_encoder_layer_24_attention_layernorm_weight",
    "458": "p_encoder_layer_24_attention_layernorm_bias",
    "459": "p_encoder_layer_24_attention_self_query_weight",
    "460": "p_encoder_layer_24_attention_self_query_bias",
    "461": "p_encoder_layer_24_attention_self_key_weight",
    "462": "p_encoder_layer_24_attention_self_key_bias",
    "463": "p_encoder_layer_24_attention_self_value_weight",
    "464": "p_encoder_layer_24_attention_self_value_bias",
    "465": "p_encoder_layer_24_attention_output_dense_weight",
    "466": "p_encoder_layer_24_attention_output_dense_bias",
    "467": "p_encoder_layer_24_layernorm_weight",
    "468": "p_encoder_layer_24_layernorm_bias",
    "469": "p_encoder_layer_24_intermediate_dense_weight",
    "470": "p_encoder_layer_24_intermediate_dense_bias",
    "471": "p_encoder_layer_24_output_dense_weight",
    "472": "p_encoder_layer_24_output_dense_bias",
    "473": "p_encoder_layer_25_attention_layernorm_weight",
    "474": "p_encoder_layer_25_attention_layernorm_bias",
    "475": "p_encoder_layer_25_attention_self_query_weight",
    "476": "p_encoder_layer_25_attention_self_query_bias",
    "477": "p_encoder_layer_25_attention_self_key_weight",
    "478": "p_encoder_layer_25_attention_self_key_bias",
    "479": "p_encoder_layer_25_attention_self_value_weight",
    "480": "p_encoder_layer_25_attention_self_value_bias",
    "481": "p_encoder_layer_25_attention_output_dense_weight",
    "482": "p_encoder_layer_25_attention_output_dense_bias",
    "483": "p_encoder_layer_25_layernorm_weight",
    "484": "p_encoder_layer_25_layernorm_bias",
    "485": "p_encoder_layer_25_intermediate_dense_weight",
    "486": "p_encoder_layer_25_intermediate_dense_bias",
    "487": "p_encoder_layer_25_output_dense_weight",
    "488": "p_encoder_layer_25_output_dense_bias",
    "489": "p_encoder_layer_26_attention_layernorm_weight",
    "490": "p_encoder_layer_26_attention_layernorm_bias",
    "491": "p_encoder_layer_26_attention_self_query_weight",
    "492": "p_encoder_layer_26_attention_self_query_bias",
    "493": "p_encoder_layer_26_attention_self_key_weight",
    "494": "p_encoder_layer_26_attention_self_key_bias",
    "495": "p_encoder_layer_26_attention_self_value_weight",
    "496": "p_encoder_layer_26_attention_self_value_bias",
    "497": "p_encoder_layer_26_attention_output_dense_weight",
    "498": "p_encoder_layer_26_attention_output_dense_bias",
    "499": "p_encoder_layer_26_layernorm_weight",
    "500": "p_encoder_layer_26_layernorm_bias",
    "501": "p_encoder_layer_26_intermediate_dense_weight",
    "502": "p_encoder_layer_26_intermediate_dense_bias",
    "503": "p_encoder_layer_26_output_dense_weight",
    "504": "p_encoder_layer_26_output_dense_bias",
    "505": "p_encoder_layer_27_attention_layernorm_weight",
    "506": "p_encoder_layer_27_attention_layernorm_bias",
    "507": "p_encoder_layer_27_attention_self_query_weight",
    "508": "p_encoder_layer_27_attention_self_query_bias",
    "509": "p_encoder_layer_27_attention_self_key_weight",
    "510": "p_encoder_layer_27_attention_self_key_bias",
    "511": "p_encoder_layer_27_attention_self_value_weight",
    "512": "p_encoder_layer_27_attention_self_value_bias",
    "513": "p_encoder_layer_27_attention_output_dense_weight",
    "514": "p_encoder_layer_27_attention_output_dense_bias",
    "515": "p_encoder_layer_27_layernorm_weight",
    "516": "p_encoder_layer_27_layernorm_bias",
    "517": "p_encoder_layer_27_intermediate_dense_weight",
    "518": "p_encoder_layer_27_intermediate_dense_bias",
    "519": "p_encoder_layer_27_output_dense_weight",
    "520": "p_encoder_layer_27_output_dense_bias",
    "521": "p_encoder_layer_28_attention_layernorm_weight",
    "522": "p_encoder_layer_28_attention_layernorm_bias",
    "523": "p_encoder_layer_28_attention_self_query_weight",
    "524": "p_encoder_layer_28_attention_self_query_bias",
    "525": "p_encoder_layer_28_attention_self_key_weight",
    "526": "p_encoder_layer_28_attention_self_key_bias",
    "527": "p_encoder_layer_28_attention_self_value_weight",
    "528": "p_encoder_layer_28_attention_self_value_bias",
    "529": "p_encoder_layer_28_attention_output_dense_weight",
    "530": "p_encoder_layer_28_attention_output_dense_bias",
    "531": "p_encoder_layer_28_layernorm_weight",
    "532": "p_encoder_layer_28_layernorm_bias",
    "533": "p_encoder_layer_28_intermediate_dense_weight",
    "534": "p_encoder_layer_28_intermediate_dense_bias",
    "535": "p_encoder_layer_28_output_dense_weight",
    "536": "p_encoder_layer_28_output_dense_bias",
    "537": "p_encoder_layer_29_attention_layernorm_weight",
    "538": "p_encoder_layer_29_attention_layernorm_bias",
    "539": "p_encoder_layer_29_attention_self_query_weight",
    "540": "p_encoder_layer_29_attention_self_query_bias",
    "541": "p_encoder_layer_29_attention_self_key_weight",
    "542": "p_encoder_layer_29_attention_self_key_bias",
    "543": "p_encoder_layer_29_attention_self_value_weight",
    "544": "p_encoder_layer_29_attention_self_value_bias",
    "545": "p_encoder_layer_29_attention_output_dense_weight",
    "546": "p_encoder_layer_29_attention_output_dense_bias",
    "547": "p_encoder_layer_29_layernorm_weight",
    "548": "p_encoder_layer_29_layernorm_bias",
    "549": "p_encoder_layer_29_intermediate_dense_weight",
    "550": "p_encoder_layer_29_intermediate_dense_bias",
    "551": "p_encoder_layer_29_output_dense_weight",
    "552": "p_encoder_layer_29_output_dense_bias",
    "553": "p_encoder_emb_layer_norm_after_weight",
    "554": "p_encoder_emb_layer_norm_after_bias",
    "555": "b___encoder_layer_0_attention_self_rotary_embeddings__buffers__inv_freq",
    "556": "b___encoder_layer_1_attention_self_rotary_embeddings__buffers__inv_freq",
    "557": "b___encoder_layer_2_attention_self_rotary_embeddings__buffers__inv_freq",
    "558": "b___encoder_layer_3_attention_self_rotary_embeddings__buffers__inv_freq",
    "559": "b___encoder_layer_4_attention_self_rotary_embeddings__buffers__inv_freq",
    "560": "b___encoder_layer_5_attention_self_rotary_embeddings__buffers__inv_freq",
    "561": "b___encoder_layer_6_attention_self_rotary_embeddings__buffers__inv_freq",
    "562": "b___encoder_layer_7_attention_self_rotary_embeddings__buffers__inv_freq",
    "563": "b___encoder_layer_8_attention_self_rotary_embeddings__buffers__inv_freq",
    "564": "b___encoder_layer_9_attention_self_rotary_embeddings__buffers__inv_freq",
    "565": "b___encoder_layer_10_attention_self_rotary_embeddings__buffers__inv_freq",
    "566": "b___encoder_layer_11_attention_self_rotary_embeddings__buffers__inv_freq",
    "567": "b___encoder_layer_12_attention_self_rotary_embeddings__buffers__inv_freq",
    "568": "b___encoder_layer_13_attention_self_rotary_embeddings__buffers__inv_freq",
    "569": "b___encoder_layer_14_attention_self_rotary_embeddings__buffers__inv_freq",
    "570": "b___encoder_layer_15_attention_self_rotary_embeddings__buffers__inv_freq",
    "571": "b___encoder_layer_16_attention_self_rotary_embeddings__buffers__inv_freq",
    "572": "b___encoder_layer_17_attention_self_rotary_embeddings__buffers__inv_freq",
    "573": "b___encoder_layer_18_attention_self_rotary_embeddings__buffers__inv_freq",
    "574": "b___encoder_layer_19_attention_self_rotary_embeddings__buffers__inv_freq",
    "575": "b___encoder_layer_20_attention_self_rotary_embeddings__buffers__inv_freq",
    "576": "b___encoder_layer_21_attention_self_rotary_embeddings__buffers__inv_freq",
    "577": "b___encoder_layer_22_attention_self_rotary_embeddings__buffers__inv_freq",
    "578": "b___encoder_layer_23_attention_self_rotary_embeddings__buffers__inv_freq",
    "579": "b___encoder_layer_24_attention_self_rotary_embeddings__buffers__inv_freq",
    "580": "b___encoder_layer_25_attention_self_rotary_embeddings__buffers__inv_freq",
    "581": "b___encoder_layer_26_attention_self_rotary_embeddings__buffers__inv_freq",
    "582": "b___encoder_layer_27_attention_self_rotary_embeddings__buffers__inv_freq",
    "583": "b___encoder_layer_28_attention_self_rotary_embeddings__buffers__inv_freq",
    "584": "b___encoder_layer_29_attention_self_rotary_embeddings__buffers__inv_freq",
    "585": "p_encoder_layer_0_attention_ln_bias",
    "586": "p_encoder_layer_0_ln_weight",
    "587": "p_encoder_layer_0_ln_bias",
    "588": "p_encoder_layer_1_attention_ln_weight",
    "589": "p_encoder_layer_1_attention_ln_bias",
    "590": "p_encoder_layer_1_ln_weight",
    "591": "p_encoder_layer_1_ln_bias",
    "592": "p_encoder_layer_2_attention_ln_weight",
    "593": "p_encoder_layer_2_attention_ln_bias",
    "594": "p_encoder_layer_2_ln_weight",
    "595": "p_encoder_layer_2_ln_bias",
    "596": "p_encoder_layer_3_attention_ln_weight",
    "597": "p_encoder_layer_3_attention_ln_bias",
    "598": "p_encoder_layer_3_ln_weight",
    "599": "p_encoder_layer_3_ln_bias",
    "600": "p_encoder_layer_4_attention_ln_weight",
    "601": "p_encoder_layer_4_attention_ln_bias",
    "602": "p_encoder_layer_4_ln_weight",
    "603": "p_encoder_layer_4_ln_bias",
    "604": "p_encoder_layer_5_attention_ln_weight",
    "605": "p_encoder_layer_5_attention_ln_bias",
    "606": "p_encoder_layer_5_ln_weight",
    "607": "p_encoder_layer_5_ln_bias",
    "608": "p_encoder_layer_6_attention_ln_weight",
    "609": "p_encoder_layer_6_attention_ln_bias",
    "610": "p_encoder_layer_6_ln_weight",
    "611": "p_encoder_layer_6_ln_bias",
    "612": "p_encoder_layer_7_attention_ln_weight",
    "613": "p_encoder_layer_7_attention_ln_bias",
    "614": "p_encoder_layer_7_ln_weight",
    "615": "p_encoder_layer_7_ln_bias",
    "616": "p_encoder_layer_8_attention_ln_weight",
    "617": "p_encoder_layer_8_attention_ln_bias",
    "618": "p_encoder_layer_8_ln_weight",
    "619": "p_encoder_layer_8_ln_bias",
    "620": "p_encoder_layer_9_attention_ln_weight",
    "621": "p_encoder_layer_9_attention_ln_bias",
    "622": "p_encoder_layer_9_ln_weight",
    "623": "p_encoder_layer_9_ln_bias",
    "624": "p_encoder_layer_10_attention_ln_weight",
    "625": "p_encoder_layer_10_attention_ln_bias",
    "626": "p_encoder_layer_10_ln_weight",
    "627": "p_encoder_layer_10_ln_bias",
    "628": "p_encoder_layer_11_attention_ln_weight",
    "629": "p_encoder_layer_11_attention_ln_bias",
    "630": "p_encoder_layer_11_ln_weight",
    "631": "p_encoder_layer_11_ln_bias",
    "632": "p_encoder_layer_12_attention_ln_weight",
    "633": "p_encoder_layer_12_attention_ln_bias",
    "634": "p_encoder_layer_12_ln_weight",
    "635": "p_encoder_layer_12_ln_bias",
    "636": "p_encoder_layer_13_attention_ln_weight",
    "637": "p_encoder_layer_13_attention_ln_bias",
    "638": "p_encoder_layer_13_ln_weight",
    "639": "p_encoder_layer_13_ln_bias",
    "640": "p_encoder_layer_14_attention_ln_weight",
    "641": "p_encoder_layer_14_attention_ln_bias",
    "642": "p_encoder_layer_14_ln_weight",
    "643": "p_encoder_layer_14_ln_bias",
    "644": "p_encoder_layer_15_attention_ln_weight",
    "645": "p_encoder_layer_15_attention_ln_bias",
    "646": "p_encoder_layer_15_ln_weight",
    "647": "p_encoder_layer_15_ln_bias",
    "648": "p_encoder_layer_16_attention_ln_weight",
    "649": "p_encoder_layer_16_attention_ln_bias",
    "650": "p_encoder_layer_16_ln_weight",
    "651": "p_encoder_layer_16_ln_bias",
    "652": "p_encoder_layer_17_attention_ln_weight",
    "653": "p_encoder_layer_17_attention_ln_bias",
    "654": "p_encoder_layer_17_ln_weight",
    "655": "p_encoder_layer_17_ln_bias",
    "656": "p_encoder_layer_18_attention_ln_weight",
    "657": "p_encoder_layer_18_attention_ln_bias",
    "658": "p_encoder_layer_18_ln_weight",
    "659": "p_encoder_layer_18_ln_bias",
    "660": "p_encoder_layer_19_attention_ln_weight",
    "661": "p_encoder_layer_19_attention_ln_bias",
    "662": "p_encoder_layer_19_ln_weight",
    "663": "p_encoder_layer_19_ln_bias",
    "664": "p_encoder_layer_20_attention_ln_weight",
    "665": "p_encoder_layer_20_attention_ln_bias",
    "666": "p_encoder_layer_20_ln_weight",
    "667": "p_encoder_layer_20_ln_bias",
    "668": "p_encoder_layer_21_attention_ln_weight",
    "669": "p_encoder_layer_21_attention_ln_bias",
    "670": "p_encoder_layer_21_ln_weight",
    "671": "p_encoder_layer_21_ln_bias",
    "672": "p_encoder_layer_22_attention_ln_weight",
    "673": "p_encoder_layer_22_attention_ln_bias",
    "674": "p_encoder_layer_22_ln_weight",
    "675": "p_encoder_layer_22_ln_bias",
    "676": "p_encoder_layer_23_attention_ln_weight",
    "677": "p_encoder_layer_23_attention_ln_bias",
    "678": "p_encoder_layer_23_ln_weight",
    "679": "p_encoder_layer_23_ln_bias",
    "680": "p_encoder_ln_weight",
    "681": "p_encoder_ln_bias",
    "682": "p_embeddings_layernorm_weight",
    "683": "p_transformer_layer_0_attention_q_lin_weight",
    "684": "p_transformer_layer_0_attention_q_lin_bias",
    "685": "p_transformer_layer_0_attention_k_lin_weight",
    "686": "p_transformer_layer_0_attention_k_lin_bias",
    "687": "p_transformer_layer_0_attention_v_lin_weight",
    "688": "p_transformer_layer_0_attention_v_lin_bias",
    "689": "p_transformer_layer_0_attention_out_lin_weight",
    "690": "p_transformer_layer_0_attention_out_lin_bias",
    "691": "p_transformer_layer_0_sa_layer_norm_weight",
    "692": "p_transformer_layer_0_sa_layer_norm_bias",
    "693": "p_transformer_layer_0_ffn_lin1_weight",
    "694": "p_transformer_layer_0_ffn_lin1_bias",
    "695": "p_transformer_layer_0_ffn_lin2_weight",
    "696": "p_transformer_layer_0_ffn_lin2_bias",
    "697": "p_transformer_layer_0_output_layer_norm_weight",
    "698": "p_transformer_layer_0_output_layer_norm_bias",
    "699": "p_transformer_layer_1_attention_q_lin_weight",
    "700": "p_transformer_layer_1_attention_q_lin_bias",
    "701": "p_transformer_layer_1_attention_k_lin_weight",
    "702": "p_transformer_layer_1_attention_k_lin_bias",
    "703": "p_transformer_layer_1_attention_v_lin_weight",
    "704": "p_transformer_layer_1_attention_v_lin_bias",
    "705": "p_transformer_layer_1_attention_out_lin_weight",
    "706": "p_transformer_layer_1_attention_out_lin_bias",
    "707": "p_transformer_layer_1_sa_layer_norm_weight",
    "708": "p_transformer_layer_1_sa_layer_norm_bias",
    "709": "p_transformer_layer_1_ffn_lin1_weight",
    "710": "p_transformer_layer_1_ffn_lin1_bias",
    "711": "p_transformer_layer_1_ffn_lin2_weight",
    "712": "p_transformer_layer_1_ffn_lin2_bias",
    "713": "p_transformer_layer_1_output_layer_norm_weight",
    "714": "p_transformer_layer_1_output_layer_norm_bias",
    "715": "p_transformer_layer_2_attention_q_lin_weight",
    "716": "p_transformer_layer_2_attention_q_lin_bias",
    "717": "p_transformer_layer_2_attention_k_lin_weight",
    "718": "p_transformer_layer_2_attention_k_lin_bias",
    "719": "p_transformer_layer_2_attention_v_lin_weight",
    "720": "p_transformer_layer_2_attention_v_lin_bias",
    "721": "p_transformer_layer_2_attention_out_lin_weight",
    "722": "p_transformer_layer_2_attention_out_lin_bias",
    "723": "p_transformer_layer_2_sa_layer_norm_weight",
    "724": "p_transformer_layer_2_sa_layer_norm_bias",
    "725": "p_transformer_layer_2_ffn_lin1_weight",
    "726": "p_transformer_layer_2_ffn_lin1_bias",
    "727": "p_transformer_layer_2_ffn_lin2_weight",
    "728": "p_transformer_layer_2_ffn_lin2_bias",
    "729": "p_transformer_layer_2_output_layer_norm_weight",
    "730": "p_transformer_layer_2_output_layer_norm_bias",
    "731": "p_transformer_layer_3_attention_q_lin_weight",
    "732": "p_transformer_layer_3_attention_q_lin_bias",
    "733": "p_transformer_layer_3_attention_k_lin_weight",
    "734": "p_transformer_layer_3_attention_k_lin_bias",
    "735": "p_transformer_layer_3_attention_v_lin_weight",
    "736": "p_transformer_layer_3_attention_v_lin_bias",
    "737": "p_transformer_layer_3_attention_out_lin_weight",
    "738": "p_transformer_layer_3_attention_out_lin_bias",
    "739": "p_transformer_layer_3_sa_layer_norm_weight",
    "740": "p_transformer_layer_3_sa_layer_norm_bias",
    "741": "p_transformer_layer_3_ffn_lin1_weight",
    "742": "p_transformer_layer_3_ffn_lin1_bias",
    "743": "p_transformer_layer_3_ffn_lin2_weight",
    "744": "p_transformer_layer_3_ffn_lin2_bias",
    "745": "p_transformer_layer_3_output_layer_norm_weight",
    "746": "p_transformer_layer_3_output_layer_norm_bias",
    "747": "p_transformer_layer_4_attention_q_lin_weight",
    "748": "p_transformer_layer_4_attention_q_lin_bias",
    "749": "p_transformer_layer_4_attention_k_lin_weight",
    "750": "p_transformer_layer_4_attention_k_lin_bias",
    "751": "p_transformer_layer_4_attention_v_lin_weight",
    "752": "p_transformer_layer_4_attention_v_lin_bias",
    "753": "p_transformer_layer_4_attention_out_lin_weight",
    "754": "p_transformer_layer_4_attention_out_lin_bias",
    "755": "p_transformer_layer_4_sa_layer_norm_weight",
    "756": "p_transformer_layer_4_sa_layer_norm_bias",
    "757": "p_transformer_layer_4_ffn_lin1_weight",
    "758": "p_transformer_layer_4_ffn_lin1_bias",
    "759": "p_transformer_layer_4_ffn_lin2_weight",
    "760": "p_transformer_layer_4_ffn_lin2_bias",
    "761": "p_transformer_layer_4_output_layer_norm_weight",
    "762": "p_transformer_layer_4_output_layer_norm_bias",
    "763": "p_transformer_layer_5_attention_q_lin_weight",
    "764": "p_transformer_layer_5_attention_q_lin_bias",
    "765": "p_transformer_layer_5_attention_k_lin_weight",
    "766": "p_transformer_layer_5_attention_k_lin_bias",
    "767": "p_transformer_layer_5_attention_v_lin_weight",
    "768": "p_transformer_layer_5_attention_v_lin_bias",
    "769": "p_transformer_layer_5_attention_out_lin_weight",
    "770": "p_transformer_layer_5_attention_out_lin_bias",
    "771": "p_transformer_layer_5_sa_layer_norm_weight",
    "772": "p_transformer_layer_5_sa_layer_norm_bias",
    "773": "p_transformer_layer_5_ffn_lin1_weight",
    "774": "p_transformer_layer_5_ffn_lin1_bias",
    "775": "p_transformer_layer_5_ffn_lin2_weight",
    "776": "p_transformer_layer_5_ffn_lin2_bias",
    "777": "p_transformer_layer_5_output_layer_norm_weight",
    "778": "p_transformer_layer_5_output_layer_norm_bias",
    "779": "p_dense_bias",
    "780": "p_out_proj_weight",
    "781": "p_out_proj_bias",
    "782": "features",
    "783": "p_h_0_ln_1_bias",
    "784": "p_h_0_attn_attention_q_proj_weight",
    "785": "p_h_0_attn_attention_k_proj_weight",
    "786": "p_h_0_attn_attention_v_proj_weight",
    "787": "p_h_0_attn_attention_out_proj_weight",
    "788": "p_h_0_attn_attention_out_proj_bias",
    "789": "p_h_0_ln_2_weight",
    "790": "p_h_0_ln_2_bias",
    "791": "p_h_0_mlp_c_fc_weight",
    "792": "p_h_0_mlp_c_fc_bias",
    "793": "p_h_0_mlp_c_proj_weight",
    "794": "p_h_0_mlp_c_proj_bias",
    "795": "p_h_1_ln_1_weight",
    "796": "p_h_1_ln_1_bias",
    "797": "p_h_1_attn_attention_q_proj_weight",
    "798": "p_h_1_attn_attention_k_proj_weight",
    "799": "p_h_1_attn_attention_v_proj_weight",
    "800": "p_h_1_attn_attention_out_proj_weight",
    "801": "p_h_1_attn_attention_out_proj_bias",
    "802": "p_h_1_ln_2_weight",
    "803": "p_h_1_ln_2_bias",
    "804": "p_h_1_mlp_c_fc_weight",
    "805": "p_h_1_mlp_c_fc_bias",
    "806": "p_h_1_mlp_c_proj_weight",
    "807": "p_h_1_mlp_c_proj_bias",
    "808": "p_h_2_ln_1_weight",
    "809": "p_h_2_ln_1_bias",
    "810": "p_h_2_attn_attention_q_proj_weight",
    "811": "p_h_2_attn_attention_k_proj_weight",
    "812": "p_h_2_attn_attention_v_proj_weight",
    "813": "p_h_2_attn_attention_out_proj_weight",
    "814": "p_h_2_attn_attention_out_proj_bias",
    "815": "p_h_2_ln_2_weight",
    "816": "p_h_2_ln_2_bias",
    "817": "p_h_2_mlp_c_fc_weight",
    "818": "p_h_2_mlp_c_fc_bias",
    "819": "p_h_2_mlp_c_proj_weight",
    "820": "p_h_2_mlp_c_proj_bias",
    "821": "p_h_3_ln_1_weight",
    "822": "p_h_3_ln_1_bias",
    "823": "p_h_3_attn_attention_q_proj_weight",
    "824": "p_h_3_attn_attention_k_proj_weight",
    "825": "p_h_3_attn_attention_v_proj_weight",
    "826": "p_h_3_attn_attention_out_proj_weight",
    "827": "p_h_3_attn_attention_out_proj_bias",
    "828": "p_h_3_ln_2_weight",
    "829": "p_h_3_ln_2_bias",
    "830": "p_h_3_mlp_c_fc_weight",
    "831": "p_h_3_mlp_c_fc_bias",
    "832": "p_h_3_mlp_c_proj_weight",
    "833": "p_h_3_mlp_c_proj_bias",
    "834": "p_h_4_ln_1_weight",
    "835": "p_h_4_ln_1_bias",
    "836": "p_h_4_attn_attention_q_proj_weight",
    "837": "p_h_4_attn_attention_k_proj_weight",
    "838": "p_h_4_attn_attention_v_proj_weight",
    "839": "p_h_4_attn_attention_out_proj_weight",
    "840": "p_h_4_attn_attention_out_proj_bias",
    "841": "p_h_4_ln_2_weight",
    "842": "p_h_4_ln_2_bias",
    "843": "p_h_4_mlp_c_fc_weight",
    "844": "p_h_4_mlp_c_fc_bias",
    "845": "p_h_4_mlp_c_proj_weight",
    "846": "p_h_4_mlp_c_proj_bias",
    "847": "p_h_5_ln_1_weight",
    "848": "p_h_5_ln_1_bias",
    "849": "p_h_5_attn_attention_q_proj_weight",
    "850": "p_h_5_attn_attention_k_proj_weight",
    "851": "p_h_5_attn_attention_v_proj_weight",
    "852": "p_h_5_attn_attention_out_proj_weight",
    "853": "p_h_5_attn_attention_out_proj_bias",
    "854": "p_h_5_ln_2_weight",
    "855": "p_h_5_ln_2_bias",
    "856": "p_h_5_mlp_c_fc_weight",
    "857": "p_h_5_mlp_c_fc_bias",
    "858": "p_h_5_mlp_c_proj_weight",
    "859": "p_h_5_mlp_c_proj_bias",
    "860": "p_h_6_ln_1_weight",
    "861": "p_h_6_ln_1_bias",
    "862": "p_h_6_attn_attention_q_proj_weight",
    "863": "p_h_6_attn_attention_k_proj_weight",
    "864": "p_h_6_attn_attention_v_proj_weight",
    "865": "p_h_6_attn_attention_out_proj_weight",
    "866": "p_h_6_attn_attention_out_proj_bias",
    "867": "p_h_6_ln_2_weight",
    "868": "p_h_6_ln_2_bias",
    "869": "p_h_6_mlp_c_fc_weight",
    "870": "p_h_6_mlp_c_fc_bias",
    "871": "p_h_6_mlp_c_proj_weight",
    "872": "p_h_6_mlp_c_proj_bias",
    "873": "p_h_7_ln_1_weight",
    "874": "p_h_7_ln_1_bias",
    "875": "p_h_7_attn_attention_q_proj_weight",
    "876": "p_h_7_attn_attention_k_proj_weight",
    "877": "p_h_7_attn_attention_v_proj_weight",
    "878": "p_h_7_attn_attention_out_proj_weight",
    "879": "p_h_7_attn_attention_out_proj_bias",
    "880": "p_h_7_ln_2_weight",
    "881": "p_h_7_ln_2_bias",
    "882": "p_h_7_mlp_c_fc_weight",
    "883": "p_h_7_mlp_c_fc_bias",
    "884": "p_h_7_mlp_c_proj_weight",
    "885": "p_h_7_mlp_c_proj_bias",
    "886": "p_h_8_ln_1_weight",
    "887": "p_h_8_ln_1_bias",
    "888": "p_h_8_attn_attention_q_proj_weight",
    "889": "p_h_8_attn_attention_k_proj_weight",
    "890": "p_h_8_attn_attention_v_proj_weight",
    "891": "p_h_8_attn_attention_out_proj_weight",
    "892": "p_h_8_attn_attention_out_proj_bias",
    "893": "p_h_8_ln_2_weight",
    "894": "p_h_8_ln_2_bias",
    "895": "p_h_8_mlp_c_fc_weight",
    "896": "p_h_8_mlp_c_fc_bias",
    "897": "p_h_8_mlp_c_proj_weight",
    "898": "p_h_8_mlp_c_proj_bias",
    "899": "p_h_9_ln_1_weight",
    "900": "p_h_9_ln_1_bias",
    "901": "p_h_9_attn_attention_q_proj_weight",
    "902": "p_h_9_attn_attention_k_proj_weight",
    "903": "p_h_9_attn_attention_v_proj_weight",
    "904": "p_h_9_attn_attention_out_proj_weight",
    "905": "p_h_9_attn_attention_out_proj_bias",
    "906": "p_h_9_ln_2_weight",
    "907": "p_h_9_ln_2_bias",
    "908": "p_h_9_mlp_c_fc_weight",
    "909": "p_h_9_mlp_c_fc_bias",
    "910": "p_h_9_mlp_c_proj_weight",
    "911": "p_h_9_mlp_c_proj_bias",
    "912": "p_h_10_ln_1_weight",
    "913": "p_h_10_ln_1_bias",
    "914": "p_h_10_attn_attention_q_proj_weight",
    "915": "p_h_10_attn_attention_k_proj_weight",
    "916": "p_h_10_attn_attention_v_proj_weight",
    "917": "p_h_10_attn_attention_out_proj_weight",
    "918": "p_h_10_attn_attention_out_proj_bias",
    "919": "p_h_10_ln_2_weight",
    "920": "p_h_10_ln_2_bias",
    "921": "p_h_10_mlp_c_fc_weight",
    "922": "p_h_10_mlp_c_fc_bias",
    "923": "p_h_10_mlp_c_proj_weight",
    "924": "p_h_10_mlp_c_proj_bias",
    "925": "p_h_11_ln_1_weight",
    "926": "p_h_11_ln_1_bias",
    "927": "p_h_11_attn_attention_q_proj_weight",
    "928": "p_h_11_attn_attention_k_proj_weight",
    "929": "p_h_11_attn_attention_v_proj_weight",
    "930": "p_h_11_attn_attention_out_proj_weight",
    "931": "p_h_11_attn_attention_out_proj_bias",
    "932": "p_h_11_ln_2_weight",
    "933": "p_h_11_ln_2_bias",
    "934": "p_h_11_mlp_c_fc_weight",
    "935": "p_h_11_mlp_c_fc_bias",
    "936": "p_h_11_mlp_c_proj_weight",
    "937": "p_h_11_mlp_c_proj_bias",
    "938": "p_ln_f_weight",
    "939": "p_ln_f_bias",
    "940": "b_h_0_attn_attention_bias",
    "941": "b_h_1_attn_attention_bias",
    "942": "b_h_2_attn_attention_bias",
    "943": "b_h_3_attn_attention_bias",
    "944": "b_h_4_attn_attention_bias",
    "945": "b_h_5_attn_attention_bias",
    "946": "b_h_6_attn_attention_bias",
    "947": "b_h_7_attn_attention_bias",
    "948": "b_h_8_attn_attention_bias",
    "949": "b_h_9_attn_attention_bias",
    "950": "b_h_10_attn_attention_bias",
    "951": "b_h_11_attn_attention_bias",
    "952": "c_h_0_attn_attention_lifted_tensor_0",
    "953": "c_h_1_attn_attention_lifted_tensor_1",
    "954": "c_h_2_attn_attention_lifted_tensor_2",
    "955": "c_h_3_attn_attention_lifted_tensor_3",
    "956": "c_h_4_attn_attention_lifted_tensor_4",
    "957": "c_h_5_attn_attention_lifted_tensor_5",
    "958": "c_h_6_attn_attention_lifted_tensor_6",
    "959": "c_h_7_attn_attention_lifted_tensor_7",
    "960": "c_h_8_attn_attention_lifted_tensor_8",
    "961": "c_h_9_attn_attention_lifted_tensor_9",
    "962": "c_h_10_attn_attention_lifted_tensor_10",
    "963": "c_h_11_attn_attention_lifted_tensor_11",
    "964": "p_encoder_layer_12_attention_output_layernorm_weight",
    "965": "p_encoder_layer_12_attention_output_layernorm_bias",
    "966": "p_encoder_layer_12_output_layernorm_weight",
    "967": "p_encoder_layer_12_output_layernorm_bias",
    "968": "p_encoder_layer_13_attention_output_layernorm_weight",
    "969": "p_encoder_layer_13_attention_output_layernorm_bias",
    "970": "p_encoder_layer_13_output_layernorm_weight",
    "971": "p_encoder_layer_13_output_layernorm_bias",
    "972": "p_encoder_layer_14_attention_output_layernorm_weight",
    "973": "p_encoder_layer_14_attention_output_layernorm_bias",
    "974": "p_encoder_layer_14_output_layernorm_weight",
    "975": "p_encoder_layer_14_output_layernorm_bias",
    "976": "p_encoder_layer_15_attention_output_layernorm_weight",
    "977": "p_encoder_layer_15_attention_output_layernorm_bias",
    "978": "p_encoder_layer_15_output_layernorm_weight",
    "979": "p_encoder_layer_15_output_layernorm_bias",
    "980": "p_encoder_layer_16_attention_output_layernorm_weight",
    "981": "p_encoder_layer_16_attention_output_layernorm_bias",
    "982": "p_encoder_layer_16_output_layernorm_weight",
    "983": "p_encoder_layer_16_output_layernorm_bias",
    "984": "p_encoder_layer_17_attention_output_layernorm_weight",
    "985": "p_encoder_layer_17_attention_output_layernorm_bias",
    "986": "p_encoder_layer_17_output_layernorm_weight",
    "987": "p_encoder_layer_17_output_layernorm_bias",
    "988": "p_encoder_layer_18_attention_output_layernorm_weight",
    "989": "p_encoder_layer_18_attention_output_layernorm_bias",
    "990": "p_encoder_layer_18_output_layernorm_weight",
    "991": "p_encoder_layer_18_output_layernorm_bias",
    "992": "p_encoder_layer_19_attention_output_layernorm_weight",
    "993": "p_encoder_layer_19_attention_output_layernorm_bias",
    "994": "p_encoder_layer_19_output_layernorm_weight",
    "995": "p_encoder_layer_19_output_layernorm_bias",
    "996": "p_encoder_layer_20_attention_output_layernorm_weight",
    "997": "p_encoder_layer_20_attention_output_layernorm_bias",
    "998": "p_encoder_layer_20_output_layernorm_weight",
    "999": "p_encoder_layer_20_output_layernorm_bias",
    "1000": "p_encoder_layer_21_attention_output_layernorm_weight",
    "1001": "p_encoder_layer_21_attention_output_layernorm_bias",
    "1002": "p_encoder_layer_21_output_layernorm_weight",
    "1003": "p_encoder_layer_21_output_layernorm_bias",
    "1004": "p_encoder_layer_22_attention_output_layernorm_weight",
    "1005": "p_encoder_layer_22_attention_output_layernorm_bias",
    "1006": "p_encoder_layer_22_output_layernorm_weight",
    "1007": "p_encoder_layer_22_output_layernorm_bias",
    "1008": "p_encoder_layer_23_attention_output_layernorm_weight",
    "1009": "p_encoder_layer_23_attention_output_layernorm_bias",
    "1010": "p_encoder_layer_23_output_layernorm_weight",
    "1011": "p_encoder_layer_23_output_layernorm_bias",
    "1012": "p_encoder_layer_24_attention_output_layernorm_weight",
    "1013": "p_encoder_layer_24_attention_output_layernorm_bias",
    "1014": "p_encoder_layer_24_output_layernorm_weight",
    "1015": "p_encoder_layer_24_output_layernorm_bias",
    "1016": "p_encoder_layer_25_attention_output_layernorm_weight",
    "1017": "p_encoder_layer_25_attention_output_layernorm_bias",
    "1018": "p_encoder_layer_25_output_layernorm_weight",
    "1019": "p_encoder_layer_25_output_layernorm_bias",
    "1020": "p_encoder_layer_26_attention_output_layernorm_weight",
    "1021": "p_encoder_layer_26_attention_output_layernorm_bias",
    "1022": "p_encoder_layer_26_output_layernorm_weight",
    "1023": "p_encoder_layer_26_output_layernorm_bias",
    "1024": "p_encoder_layer_27_attention_output_layernorm_weight",
    "1025": "p_encoder_layer_27_attention_output_layernorm_bias",
    "1026": "p_encoder_layer_27_output_layernorm_weight",
    "1027": "p_encoder_layer_27_output_layernorm_bias",
    "1028": "p_encoder_layer_28_attention_output_layernorm_weight",
    "1029": "p_encoder_layer_28_attention_output_layernorm_bias",
    "1030": "p_encoder_layer_28_output_layernorm_weight",
    "1031": "p_encoder_layer_28_output_layernorm_bias",
    "1032": "p_encoder_layer_29_attention_output_layernorm_weight",
    "1033": "p_encoder_layer_29_attention_output_layernorm_bias",
    "1034": "p_encoder_layer_29_output_layernorm_weight",
    "1035": "p_encoder_layer_29_output_layernorm_bias",
    "1036": "p_fn_1_weight",
    "1037": "p_fn_1_bias",
    "1038": "p_getattr_getattr_l__fn_____4_____0___conv1_weight",
    "1039": "p_getattr_getattr_l__fn_____4_____0___bn1_weight",
    "1040": "p_getattr_getattr_l__fn_____4_____0___bn1_bias",
    "1041": "p_getattr_getattr_l__fn_____4_____0___conv2_weight",
    "1042": "p_getattr_getattr_l__fn_____4_____0___bn2_weight",
    "1043": "p_getattr_getattr_l__fn_____4_____0___bn2_bias",
    "1044": "p_getattr_getattr_l__fn_____4_____1___conv1_weight",
    "1045": "p_getattr_getattr_l__fn_____4_____1___bn1_weight",
    "1046": "p_getattr_getattr_l__fn_____4_____1___bn1_bias",
    "1047": "p_getattr_getattr_l__fn_____4_____1___conv2_weight",
    "1048": "p_getattr_getattr_l__fn_____4_____1___bn2_weight",
    "1049": "p_getattr_getattr_l__fn_____4_____1___bn2_bias",
    "1050": "p_getattr_getattr_l__fn_____5_____0___conv1_weight",
    "1051": "p_getattr_getattr_l__fn_____5_____0___bn1_weight",
    "1052": "p_getattr_getattr_l__fn_____5_____0___bn1_bias",
    "1053": "p_getattr_getattr_l__fn_____5_____0___conv2_weight",
    "1054": "p_getattr_getattr_l__fn_____5_____0___bn2_weight",
    "1055": "p_getattr_getattr_l__fn_____5_____0___bn2_bias",
    "1056": "p_getattr_getattr_l__fn_____5_____0___downsample_0_weight",
    "1057": "p_getattr_getattr_l__fn_____5_____0___downsample_1_weight",
    "1058": "p_getattr_getattr_l__fn_____5_____0___downsample_1_bias",
    "1059": "p_getattr_getattr_l__fn_____5_____1___conv1_weight",
    "1060": "p_getattr_getattr_l__fn_____5_____1___bn1_weight",
    "1061": "p_getattr_getattr_l__fn_____5_____1___bn1_bias",
    "1062": "p_getattr_getattr_l__fn_____5_____1___conv2_weight",
    "1063": "p_getattr_getattr_l__fn_____5_____1___bn2_weight",
    "1064": "p_getattr_getattr_l__fn_____5_____1___bn2_bias",
    "1065": "p_getattr_getattr_l__fn_____6_____0___conv1_weight",
    "1066": "p_getattr_getattr_l__fn_____6_____0___bn1_weight",
    "1067": "p_getattr_getattr_l__fn_____6_____0___bn1_bias",
    "1068": "p_getattr_getattr_l__fn_____6_____0___conv2_weight",
    "1069": "p_getattr_getattr_l__fn_____6_____0___bn2_weight",
    "1070": "p_getattr_getattr_l__fn_____6_____0___bn2_bias",
    "1071": "p_getattr_getattr_l__fn_____6_____0___downsample_0_weight",
    "1072": "p_getattr_getattr_l__fn_____6_____0___downsample_1_weight",
    "1073": "p_getattr_getattr_l__fn_____6_____0___downsample_1_bias",
    "1074": "p_getattr_getattr_l__fn_____6_____1___conv1_weight",
    "1075": "p_getattr_getattr_l__fn_____6_____1___bn1_weight",
    "1076": "p_getattr_getattr_l__fn_____6_____1___bn1_bias",
    "1077": "p_getattr_getattr_l__fn_____6_____1___conv2_weight",
    "1078": "p_getattr_getattr_l__fn_____6_____1___bn2_weight",
    "1079": "p_getattr_getattr_l__fn_____6_____1___bn2_bias",
    "1080": "p_getattr_getattr_l__fn_____7_____0___conv1_weight",
    "1081": "p_getattr_getattr_l__fn_____7_____0___bn1_weight",
    "1082": "p_getattr_getattr_l__fn_____7_____0___bn1_bias",
    "1083": "p_getattr_getattr_l__fn_____7_____0___conv2_weight",
    "1084": "p_getattr_getattr_l__fn_____7_____0___bn2_weight",
    "1085": "p_getattr_getattr_l__fn_____7_____0___bn2_bias",
    "1086": "p_getattr_getattr_l__fn_____7_____0___downsample_0_weight",
    "1087": "p_getattr_getattr_l__fn_____7_____0___downsample_1_weight",
    "1088": "p_getattr_getattr_l__fn_____7_____0___downsample_1_bias",
    "1089": "p_getattr_getattr_l__fn_____7_____1___conv1_weight",
    "1090": "p_getattr_getattr_l__fn_____7_____1___bn1_weight",
    "1091": "p_getattr_getattr_l__fn_____7_____1___bn1_bias",
    "1092": "p_getattr_getattr_l__fn_____7_____1___conv2_weight",
    "1093": "p_getattr_getattr_l__fn_____7_____1___bn2_weight",
    "1094": "p_getattr_getattr_l__fn_____7_____1___bn2_bias",
    "1095": "b_fn_1_running_mean",
    "1096": "b_fn_1_running_var",
    "1097": "b_fn_1_num_batches_tracked",
    "1098": "b_getattr_getattr_l__fn_____4_____0___bn1_running_mean",
    "1099": "b_getattr_getattr_l__fn_____4_____0___bn1_running_var",
    "1100": "b_getattr_getattr_l__fn_____4_____0___bn1_num_batches_tracked",
    "1101": "b_getattr_getattr_l__fn_____4_____0___bn2_running_mean",
    "1102": "b_getattr_getattr_l__fn_____4_____0___bn2_running_var",
    "1103": "b_getattr_getattr_l__fn_____4_____0___bn2_num_batches_tracked",
    "1104": "b_getattr_getattr_l__fn_____4_____1___bn1_running_mean",
    "1105": "b_getattr_getattr_l__fn_____4_____1___bn1_running_var",
    "1106": "b_getattr_getattr_l__fn_____4_____1___bn1_num_batches_tracked",
    "1107": "b_getattr_getattr_l__fn_____4_____1___bn2_running_mean",
    "1108": "b_getattr_getattr_l__fn_____4_____1___bn2_running_var",
    "1109": "b_getattr_getattr_l__fn_____4_____1___bn2_num_batches_tracked",
    "1110": "b_getattr_getattr_l__fn_____5_____0___bn1_running_mean",
    "1111": "b_getattr_getattr_l__fn_____5_____0___bn1_running_var",
    "1112": "b_getattr_getattr_l__fn_____5_____0___bn1_num_batches_tracked",
    "1113": "b_getattr_getattr_l__fn_____5_____0___bn2_running_mean",
    "1114": "b_getattr_getattr_l__fn_____5_____0___bn2_running_var",
    "1115": "b_getattr_getattr_l__fn_____5_____0___bn2_num_batches_tracked",
    "1116": "b_getattr_getattr_l__fn_____5_____0___downsample_1_running_mean",
    "1117": "b_getattr_getattr_l__fn_____5_____0___downsample_1_running_var",
    "1118": "b_getattr_getattr_l__fn_____5_____0___downsample_1_num_batches_tracked",
    "1119": "b_getattr_getattr_l__fn_____5_____1___bn1_running_mean",
    "1120": "b_getattr_getattr_l__fn_____5_____1___bn1_running_var",
    "1121": "b_getattr_getattr_l__fn_____5_____1___bn1_num_batches_tracked",
    "1122": "b_getattr_getattr_l__fn_____5_____1___bn2_running_mean",
    "1123": "b_getattr_getattr_l__fn_____5_____1___bn2_running_var",
    "1124": "b_getattr_getattr_l__fn_____5_____1___bn2_num_batches_tracked",
    "1125": "b_getattr_getattr_l__fn_____6_____0___bn1_running_mean",
    "1126": "b_getattr_getattr_l__fn_____6_____0___bn1_running_var",
    "1127": "b_getattr_getattr_l__fn_____6_____0___bn1_num_batches_tracked",
    "1128": "b_getattr_getattr_l__fn_____6_____0___bn2_running_mean",
    "1129": "b_getattr_getattr_l__fn_____6_____0___bn2_running_var",
    "1130": "b_getattr_getattr_l__fn_____6_____0___bn2_num_batches_tracked",
    "1131": "b_getattr_getattr_l__fn_____6_____0___downsample_1_running_mean",
    "1132": "b_getattr_getattr_l__fn_____6_____0___downsample_1_running_var",
    "1133": "b_getattr_getattr_l__fn_____6_____0___downsample_1_num_batches_tracked",
    "1134": "b_getattr_getattr_l__fn_____6_____1___bn1_running_mean",
    "1135": "b_getattr_getattr_l__fn_____6_____1___bn1_running_var",
    "1136": "b_getattr_getattr_l__fn_____6_____1___bn1_num_batches_tracked",
    "1137": "b_getattr_getattr_l__fn_____6_____1___bn2_running_mean",
    "1138": "b_getattr_getattr_l__fn_____6_____1___bn2_running_var",
    "1139": "b_getattr_getattr_l__fn_____6_____1___bn2_num_batches_tracked",
    "1140": "b_getattr_getattr_l__fn_____7_____0___bn1_running_mean",
    "1141": "b_getattr_getattr_l__fn_____7_____0___bn1_running_var",
    "1142": "b_getattr_getattr_l__fn_____7_____0___bn1_num_batches_tracked",
    "1143": "b_getattr_getattr_l__fn_____7_____0___bn2_running_mean",
    "1144": "b_getattr_getattr_l__fn_____7_____0___bn2_running_var",
    "1145": "b_getattr_getattr_l__fn_____7_____0___bn2_num_batches_tracked",
    "1146": "b_getattr_getattr_l__fn_____7_____0___downsample_1_running_mean",
    "1147": "b_getattr_getattr_l__fn_____7_____0___downsample_1_running_var",
    "1148": "b_getattr_getattr_l__fn_____7_____0___downsample_1_num_batches_tracked",
    "1149": "b_getattr_getattr_l__fn_____7_____1___bn1_running_mean",
    "1150": "b_getattr_getattr_l__fn_____7_____1___bn1_running_var",
    "1151": "b_getattr_getattr_l__fn_____7_____1___bn1_num_batches_tracked",
    "1152": "b_getattr_getattr_l__fn_____7_____1___bn2_running_mean",
    "1153": "b_getattr_getattr_l__fn_____7_____1___bn2_running_var",
    "1154": "b_getattr_getattr_l__fn_____7_____1___bn2_num_batches_tracked"
  },
  "patterns": {
    "10": "KgEAIAH//ysK/+sB//8sCgAAAf//DwoACgH//w8KAAwB//8KCv/qAf//Cgr/8QH//y0KAAAB//oPCgAKAf//DwoADAH//woK/+oB//8KCv/xAf//Cgr/9QH/+goK/+kB//8KCv/xAf//Cgr/9QH//AoK/+kB//8KCv/xAf//IQsAAAL/6v/8Lgr/6AH/6S8KAAoB//8vCgAMAf/+MAoAAAH//zEBACAC//3//yELAAAC//n//wwLAAAC//n//xEKABQB//8KCv/1Af/rCgr/6QH//woK//EB//8KCv/1Af/tCgr/6QH//woK//EB//8hDgAAAv/X//wuCv/oAf/WLwoACgH//y8KAAwB//4wCgAAAf//MQEAIAL//f//IQsAAAL/+f//",
    "11": "BwIABAIAAQAACgr/9QH/+goK//QB//8LCwAKAv80//oLCwAAAv8z//oMCwAAAv/+//8LCwAAAv8x//wMCwAAAv/+//8NDP/zA/8v/zD//w4K//IB//8KCv/1Af/1DwoADAH//w8KABEB//8KCv/xAf//EAoAEwH//xEKABQB//8SCgAAAf/sEwoAAAH//xQLAAAC//3//xEKABUB//8VCwAWAv/+//8WDAAAA/8k/yX/9BcKABcB//8YCv/wAf//FgwAAAP/I/8k//EXCgAXAf//GAr/8AH//xYMAAAD/yL/I//uFwoAFwH//xgK//AB//8ZDQAABP/2//n//P//GAr/8AH//xcKABgB//8WDAAAA/8e/x///w4K//IB//8MDgAAAv/m//8NDP/zA/8d/x7//xYMAAAD/x7/H///GgoAAAH//xYMAAAD/x7/H///",
    "12": "Dgr/8gH//wwLAAAC//v//w0M//MD/x3/Hv//FgwAAAP/Hv8f//8XCgAXAf//GAr/8AH//xYMAAAD/x3/Hv/8FwoAFwH//xgK//AB//8WDAAAA/8c/x3/+RcKABcB//8YCv/wAf//GQ0AAAT/4P/5//z//xgK//AB//8XCgAYAf//FgwAAAP/GP8Z//8OCv/yAf//DAsAAAL/8f//DQz/8wP/F/8Y//8WDAAAA/8Y/xn//xoKAAAB//8WDAAAA/8Y/xn//w4K//IB//8MCwAAAv/7//8NDP/zA/8X/xj//xYMAAAD/xj/Gf//FwoAFwH//xgK//AB//8WDAAAA/8X/xj//BcKABcB//8YCv/wAf//FgwAAAP/Fv8X//kXCgAXAf//GAr/8AH//xkNAAAE/8r/+f/8//8YCv/wAf//FwoAGAH//xYMAAAD/xL/E///Dgr/8gH//wwLAAAC//H//w==",
    "13": "DQz/8wP/Ef8S//8WDAAAA/8S/xP//xoKAAAB//8WDAAAA/8S/xP//w4K//IB//8MCwAAAv/7//8NDP/zA/8R/xL//xYMAAAD/xL/E///FwoAFwH//xgK//AB//8WDAAAA/8R/xL//BcKABcB//8YCv/wAf//FgwAAAP/EP8R//kXCgAXAf//GAr/8AH//xkNAAAE/7T/+f/8//8YCv/wAf//FwoAGAH//xYMAAAD/wz/Df//Dgr/8gH//wwLAAAC//H//w0M//MD/wv/DP//FgwAAAP/DP8N//8aCgAAAf//FgwAAAP/DP8N//8OCv/yAf//DAsAAAL/+///DQz/8wP/C/8M//8WDAAAA/8M/w3//xcKABcB//8YCv/wAf//FgwAAAP/C/8M//wXCgAXAf//GAr/8AH//xYMAAAD/wr/C//5FwoAFwH//xgK//AB//8ZDQAABP+e//n//P//GAr/8AH//w==",
    "14": "FwoAGAH//xYMAAAD/wb/B///Dgr/8gH//wwLAAAC//H//w0M//MD/wX/Bv//FgwAAAP/Bv8H//8aCgAAAf//FgwAAAP/Bv8H//8OCv/yAf//DAsAAAL/+///DQz/8wP/Bf8G//8WDAAAA/8G/wf//xcKABcB//8YCv/wAf//FgwAAAP/Bf8G//wXCgAXAf//GAr/8AH//xYMAAAD/wT/Bf/5FwoAFwH//xgK//AB//8ZDQAABP+I//n//P//GAr/8AH//xcKABgB//8WDAAAA/8A/wH//w4K//IB//8MCwAAAv/x//8NDP/zA/7//wD//xYMAAAD/wD/Af//GgoAAAH//xYMAAAD/wD/Af//Dgr/8gH//wwLAAAC//v//w0M//MD/v//AP//FgwAAAP/AP8B//8XCgAXAf//GAr/8AH//xYMAAAD/v//AP/8FwoAFwH//xgK//AB//8WDAAAA/7+/v//+Q==",
    "15": "FwoAFwH//xgK//AB//8ZDQAABP9y//n//P//GAr/8AH//xcKABgB//8WDAAAA/76/vv//w4K//IB//8MCwAAAv/x//8NDP/zA/75/vr//xYMAAAD/vr++///GgoAAAH//xYMAAAD/vr++///Dgr/8gH//wwLAAAC//v//w0M//MD/vn++v//FgwAAAP++v77//8XCgAXAf//GAr/8AH//xYMAAAD/vn++v/8FwoAFwH//xgK//AB//8WDAAAA/74/vn/+RcKABcB//8YCv/wAf//GQ0AAAT/XP/5//z//xgK//AB//8XCgAYAf//FgwAAAP+9P71//8OCv/yAf//DAsAAAL/8f//DQz/8wP+8/70//8WDAAAA/70/vX//xoKAAAB//8WDAAAA/70/vX//w4K//IB//8MCwAAAv/7//8NDP/zA/7z/vT//xYMAAAD/vT+9f//FwoAFwH//xgK//AB//8=",
    "16": "FgwAAAP+8/70//wXCgAXAf//GAr/8AH//xYMAAAD/vL+8//5FwoAFwH//xgK//AB//8ZDQAABP9G//n//P//GAr/8AH//xcKABgB//8WDAAAA/7u/u///w4K//IB//8MCwAAAv/x//8NDP/zA/7t/u7//xYMAAAD/u7+7///GgoAAAH//xYMAAAD/u7+7///Dgr/8gH//wwLAAAC//v//w0M//MD/u3+7v//FgwAAAP+7v7v//8XCgAXAf//GAr/8AH//xYMAAAD/u3+7v/8FwoAFwH//xgK//AB//8WDAAAA/7s/u3/+RcKABcB//8YCv/wAf//GQ0AAAT/MP/5//z//xgK//AB//8XCgAYAf//FgwAAAP+6P7p//8OCv/yAf//DAsAAAL/8f//DQz/8wP+5/7o//8WDAAAA/7o/un//xoKAAAB//8WDAAAA/7o/un//w4K//IB//8MCwAAAv/7//8=",
    "17": "DQz/8wP+5/7o//8WDAAAA/7o/un//xcKABcB//8YCv/wAf//FgwAAAP+5/7o//wXCgAXAf//GAr/8AH//xYMAAAD/ub+5//5FwoAFwH//xgK//AB//8ZDQAABP8a//n//P//GAr/8AH//xcKABgB//8WDAAAA/7i/uP//w4K//IB//8MCwAAAv/x//8NDP/zA/7h/uL//xYMAAAD/uL+4///GgoAAAH//xYMAAAD/uL+4///Dgr/8gH//wwLAAAC//v//w0M//MD/uH+4v//FgwAAAP+4v7j//8XCgAXAf//GAr/8AH//xYMAAAD/uH+4v/8FwoAFwH//xgK//AB//8WDAAAA/7g/uH/+RcKABcB//8YCv/wAf//GQ0AAAT/BP/5//z//xgK//AB//8XCgAYAf//FgwAAAP+3P7d//8OCv/yAf//DAsAAAL/8f//DQz/8wP+2/7c//8WDAAAA/7c/t3//w==",
    "18": "FwoANwH//TcKADAB//8XCgA3Af/8NwoAMAH//xcKADcB//s3CgAwAf//EQoAFAH/+xEKABQB//wYCv/lAf//NQsAAAL//f//",
    "19": "Cgr/6QH//woK/+oB//8MDgAAAv/8//82CgAgAf//EQoAFAH//w4K/+cB//81CwAAAv/t//83CgAwAf//OAoAMQH//xcKABgB//8="
  },
  "rules": {
    "transition_rules": {
      "After 'aten.expand.default:node_args(1):kwargs()' -> 'aten._to_copy.default:node_args(1):kwargs('dtype',)' with connection 'in0=SOURCE'": {
        "probability": "0.92",
        "count": 11,
        "b64_repr": "EAoAEwARCgAUAQAA",
        "exceptions": [
          "-> 'aten.clone.default:node_args(1):kwargs()' with conn 'in0=SOURCE' (1 times)"
        ]
      },
      "After 'aten.lift_fresh_copy.default:node_args(1):kwargs()' -> 'aten.detach.default:node_args(1):kwargs()' with connection 'in0=SOURCE'": {
        "probability": "1.00",
        "count": 23,
        "b64_repr": "EgoAAAATCgAAAQAA"
      },
      "After 'aten.scaled_dot_product_attention.default:node_args(4):kwargs()' -> 'aten.transpose.int:node_args(1):kwargs()' with connection 'in0=SOURCE'": {
        "probability": "1.00",
        "count": 91,
        "b64_repr": "GQ0AAAAYCv/wAQAA"
      },
      "After 'aten.outer.default:node_args(2):kwargs()' -> '<PATTERN ID=10>' with connection 'in0=rel_-8,in1=rel_-4,in2=SOURCE'": {
        "probability": "1.00",
        "count": 30,
        "b64_repr": "KQsAAAAGCgAAAQAA"
      },
      "After 'aten.scaled_dot_product_attention.default:node_args(4):kwargs('scale',)' -> 'aten.transpose.int:node_args(1):kwargs()' with connection 'in0=SOURCE'": {
        "probability": "1.00",
        "count": 30,
        "b64_repr": "Mg0ADAAYCv/wAQAA"
      },
      "After 'aten.erf.default:node_args(1):kwargs()' -> 'aten.add.Tensor:node_args(1):kwargs()' with connection 'in0=SOURCE'": {
        "probability": "1.00",
        "count": 30,
        "b64_repr": "MwoAAAAgCgAMAQAA"
      },
      "After 'aten.softmax.int:node_args(1):kwargs()' -> 'aten.dropout.default:node_args(1):kwargs()' with connection 'in0=SOURCE'": {
        "probability": "1.00",
        "count": 24,
        "b64_repr": "NgoAIAAOCv/yAQAA"
      },
      "After 'aten.permute.default:node_args(1):kwargs()' -> 'aten.clone.default:node_args(1):kwargs('memory_format',)' with connection 'in0=SOURCE'": {
        "probability": "1.00",
        "count": 24,
        "b64_repr": "NwoAMAA4CgAxAQAA"
      },
      "After 'aten.clone.default:node_args(1):kwargs('memory_format',)' -> 'aten.view.default:node_args(1):kwargs()' with connection 'in0=SOURCE'": {
        "probability": "1.00",
        "count": 24,
        "b64_repr": "OAoAMQAXCgAyAQAA"
      },
      "After 'aten.slice_scatter.default:node_args(2):kwargs()' -> 'aten.slice.Tensor:node_args(1):kwargs()' with connection 'in0=SOURCE'": {
        "probability": "0.86",
        "count": 12,
        "b64_repr": "Pwv/3wAKCv/1AQAA",
        "exceptions": [
          "-> 'aten.slice_scatter.default:node_args(2):kwargs()' with conn 'in0=rel_-3,in1=SOURCE' (1 times)",
          "-> 'aten.slice_scatter.default:node_args(2):kwargs()' with conn 'in0=rel_-23,in1=SOURCE' (1 times)"
        ]
      },
      "After 'aten.where.self:node_args(3):kwargs()' -> '<PATTERN ID=19>' with connection 'in0=rel_-9,in1=SOURCE,in2=rel_-1'": {
        "probability": "1.00",
        "count": 12,
        "b64_repr": "QAwAAAAGEwAAAQAA"
      },
      "After 'aten.pow.Tensor_Scalar:node_args(1):kwargs()' -> 'aten.mul.Tensor:node_args(1):kwargs()' with connection 'in0=SOURCE'": {
        "probability": "1.00",
        "count": 12,
        "b64_repr": "QQoAEgAlCgA4AQAA"
      },
      "After 'aten._native_batch_norm_legit_no_training.default:node_args(5):kwargs()' -> '<built-in function getitem>:node_args(1):kwargs()' with connection 'in0=SOURCE'": {
        "probability": "1.00",
        "count": 20,
        "b64_repr": "Qw//2wAvCgAKAQAA"
      }
    },
    "composition_rules": {
      "Composition: Op='aten.slice.Tensor:node_args(1):kwargs()', Var=10, Const='g[10]'": {
        "count": 88
      },
      "Composition: Op='aten.embedding.default:node_args(2):kwargs()', Var=11, Const='None'": {
        "count": 22
      },
      "Composition: Op='aten.add.Tensor:node_args(2):kwargs()', Var=11, Const='None'": {
        "count": 324
      },
      "Composition: Op='aten.layer_norm.default:node_args(3):kwargs()', Var=12, Const='g[12]'": {
        "count": 76
      },
      "Composition: Op='aten.dropout.default:node_args(1):kwargs()', Var=10, Const='g[13]'": {
        "count": 196
      },
      "Composition: Op='aten._to_copy.default:node_args(1):kwargs('dtype',)', Var=10, Const='c[20]'": {
        "count": 45
      },
      "Composition: Op='aten.lift_fresh_copy.default:node_args(1):kwargs()', Var=10, Const='None'": {
        "count": 23
      },
      "Composition: Op='aten.detach.default:node_args(1):kwargs()', Var=10, Const='None'": {
        "count": 23
      },
      "Composition: Op='aten.linear.default:node_args(3):kwargs()', Var=12, Const='None'": {
        "count": 932
      },
      "Composition: Op='aten.view.default:node_args(1):kwargs()', Var=10, Const='c[23]'": {
        "count": 174
      },
      "Composition: Op='aten.transpose.int:node_args(1):kwargs()', Var=10, Const='g[15]'": {
        "count": 556
      },
      "Composition: Op='aten.scaled_dot_product_attention.default:node_args(4):kwargs()', Var=13, Const='None'": {
        "count": 91
      },
      "Composition: Op='aten.view.default:node_args(1):kwargs()', Var=10, Const='c[24]'": {
        "count": 52
      },
      "Composition: Op='aten.add.Tensor:node_args(2):kwargs()', Var=14, Const='None'": {
        "count": 89
      },
      "Composition: Op='aten.gelu.default:node_args(1):kwargs()', Var=10, Const='None'": {
        "count": 122
      },
      "Composition: Op='aten.type_as.default:node_args(2):kwargs()', Var=11, Const='None'": {
        "count": 33
      },
      "Composition: Op='aten.mul.Tensor:node_args(2):kwargs()', Var=14, Const='None'": {
        "count": 46
      },
      "Composition: Op='aten.add.Tensor:node_args(1):kwargs()', Var=10, Const='c[12]'": {
        "count": 45
      },
      "Composition: Op='aten.layer_norm.default:node_args(3):kwargs()', Var=12, Const='c[35]'": {
        "count": 61
      },
      "Composition: Op='aten.view.default:node_args(1):kwargs()', Var=10, Const='c[36]'": {
        "count": 90
      },
      "Composition: Op='aten.mul.Tensor:node_args(1):kwargs()', Var=10, Const='c[37]'": {
        "count": 30
      },
      "Composition: Op='aten.arange.default:node_args(0):kwargs('device', 'pin_memory')', Var=1, Const='g[19]'": {
        "count": 31
      },
      "Composition: Op='aten.outer.default:node_args(2):kwargs()', Var=11, Const='None'": {
        "count": 30
      },
      "Composition: Op='aten.slice.Tensor:node_args(1):kwargs()', Var=10, Const='g[22]'": {
        "count": 48
      },
      "Composition: Op='aten.slice.Tensor:node_args(1):kwargs()', Var=10, Const='g[21]'": {
        "count": 34
      },
      "Composition: Op='aten.scaled_dot_product_attention.default:node_args(4):kwargs('scale',)', Var=13, Const='c[12]'": {
        "count": 30
      },
      "Composition: Op='aten.view.default:node_args(1):kwargs()', Var=10, Const='c[41]'": {
        "count": 30
      },
      "Composition: Op='aten.dropout.default:node_args(1):kwargs()', Var=10, Const='g[24]'": {
        "count": 146
      },
      "Composition: Op='aten.mul.Tensor:node_args(1):kwargs()', Var=10, Const='c[42]'": {
        "count": 42
      },
      "Composition: Op='aten.div.Tensor:node_args(1):kwargs()', Var=10, Const='c[43]'": {
        "count": 30
      },
      "Composition: Op='aten.erf.default:node_args(1):kwargs()', Var=10, Const='None'": {
        "count": 30
      },
      "Composition: Op='aten.linear.default:node_args(2):kwargs()', Var=11, Const='None'": {
        "count": 39
      },
      "Composition: Op='aten.layer_norm.default:node_args(3):kwargs()', Var=12, Const='g[25]'": {
        "count": 112
      },
      "Composition: Op='aten.view.default:node_args(1):kwargs()', Var=10, Const='c[45]'": {
        "count": 162
      },
      "Composition: Op='aten.transpose.int:node_args(1):kwargs()', Var=10, Const='g[26]'": {
        "count": 24
      },
      "Composition: Op='aten.matmul.default:node_args(2):kwargs()', Var=11, Const='None'": {
        "count": 48
      },
      "Composition: Op='aten.div.Tensor:node_args(1):kwargs()', Var=10, Const='c[47]'": {
        "count": 24
      },
      "Composition: Op='aten.softmax.int:node_args(1):kwargs()', Var=10, Const='c[32]'": {
        "count": 24
      },
      "Composition: Op='aten.permute.default:node_args(1):kwargs()', Var=10, Const='c[48]'": {
        "count": 24
      },
      "Composition: Op='aten.clone.default:node_args(1):kwargs('memory_format',)', Var=10, Const='c[49]'": {
        "count": 24
      },
      "Composition: Op='aten.view.default:node_args(1):kwargs()', Var=10, Const='c[50]'": {
        "count": 54
      },
      "Composition: Op='aten.layer_norm.default:node_args(3):kwargs()', Var=12, Const='c[14]'": {
        "count": 75
      }
    },
    "structural_rules": {
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.embedding.default:node_args(2):kwargs()' (at rel -2), 'aten.embedding.default:node_args(2):kwargs()' (at rel -1)]": {
        "count": 11
      },
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.add.Tensor:node_args(2):kwargs()' (at rel -2), 'aten.embedding.default:node_args(2):kwargs()' (at rel -1)]": {
        "count": 11
      },
      "Node 'aten.sub.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten._to_copy.default:node_args(1):kwargs('dtype',)' (at rel -3), 'aten.detach.default:node_args(1):kwargs()' (at rel -1)]": {
        "count": 11
      },
      "Node 'aten.masked_fill.Scalar:node_args(2):kwargs()' is formed by inputs from ['aten._to_copy.default:node_args(1):kwargs('dtype',)' (at rel -1), 'aten.sub.Tensor:node_args(2):kwargs()' (at rel -2)]": {
        "count": 11
      },
      "Node 'aten.scaled_dot_product_attention.default:node_args(4):kwargs()' is formed by inputs from ['aten.masked_fill.Scalar:node_args(2):kwargs()' (at rel -10), 'aten.transpose.int:node_args(1):kwargs()' (at rel -7), 'aten.transpose.int:node_args(1):kwargs()' (at rel -4), 'aten.transpose.int:node_args(1):kwargs()' (at rel -1)]": {
        "count": 11
      },
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.dropout.default:node_args(1):kwargs()' (at rel -1), 'aten.layer_norm.default:node_args(3):kwargs()' (at rel -5)]": {
        "count": 87
      },
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.dropout.default:node_args(1):kwargs()' (at rel -1), 'aten.layer_norm.default:node_args(3):kwargs()' (at rel -15)]": {
        "count": 75
      },
      "Node '<PATTERN ID=10>' is formed by inputs from ['aten.mul.Tensor:node_args(1):kwargs()' (at rel -4), 'aten.outer.default:node_args(2):kwargs()' (at rel -1), 'aten.transpose.int:node_args(1):kwargs()' (at rel -8)]": {
        "count": 30
      },
      "Node 'aten.scaled_dot_product_attention.default:node_args(4):kwargs('scale',)' is formed by inputs from ['<PATTERN ID=10>' (at rel -6), 'aten._to_copy.default:node_args(1):kwargs('dtype',)' (at rel -4), 'aten.slice.Tensor:node_args(1):kwargs()' (at rel -1), 'aten.transpose.int:node_args(1):kwargs()' (at rel -11)]": {
        "count": 30
      },
      "Node 'aten.mul.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.add.Tensor:node_args(1):kwargs()' (at rel -1), 'aten.mul.Tensor:node_args(1):kwargs()' (at rel -4)]": {
        "count": 30
      },
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.add.Tensor:node_args(2):kwargs()' (at rel -10), 'aten.dropout.default:node_args(1):kwargs()' (at rel -1)]": {
        "count": 30
      },
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.add.Tensor:node_args(2):kwargs()' (at rel -26), 'aten.dropout.default:node_args(1):kwargs()' (at rel -1)]": {
        "count": 29
      },
      "Node 'aten.matmul.default:node_args(2):kwargs()' is formed by inputs from ['aten.transpose.int:node_args(1):kwargs()' (at rel -8), 'aten.transpose.int:node_args(1):kwargs()' (at rel -1)]": {
        "count": 24
      },
      "Node 'aten.matmul.default:node_args(2):kwargs()' is formed by inputs from ['aten.dropout.default:node_args(1):kwargs()' (at rel -1), 'aten.transpose.int:node_args(1):kwargs()' (at rel -7)]": {
        "count": 24
      },
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.add.Tensor:node_args(2):kwargs()' (at rel -6), 'aten.dropout.default:node_args(1):kwargs()' (at rel -1)]": {
        "count": 24
      },
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.add.Tensor:node_args(2):kwargs()' (at rel -23), 'aten.dropout.default:node_args(1):kwargs()' (at rel -1)]": {
        "count": 23
      },
      "Node '<PATTERN ID=18>' is formed by inputs from ['aten.linear.default:node_args(2):kwargs()' (at rel -3), 'aten.linear.default:node_args(2):kwargs()' (at rel -2), 'aten.linear.default:node_args(2):kwargs()' (at rel -1)]": {
        "count": 12
      },
      "Node 'aten.where.self:node_args(3):kwargs()' is formed by inputs from ['<PATTERN ID=18>' (at rel -7), 'aten.detach.default:node_args(1):kwargs()' (at rel -1), 'aten.slice.Tensor:node_args(1):kwargs()' (at rel -3)]": {
        "count": 12
      },
      "Node '<PATTERN ID=19>' is formed by inputs from ['<PATTERN ID=18>' (at rel -9), 'aten.slice.Tensor:node_args(1):kwargs()' (at rel -1), 'aten.where.self:node_args(3):kwargs()' (at rel -2)]": {
        "count": 12
      },
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.linear.default:node_args(3):kwargs()' (at rel -4), 'aten.mul.Tensor:node_args(1):kwargs()' (at rel -1)]": {
        "count": 12
      },
      "Node 'aten.mul.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.add.Tensor:node_args(1):kwargs()' (at rel -1), 'aten.mul.Tensor:node_args(1):kwargs()' (at rel -7)]": {
        "count": 12
      },
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.add.Tensor:node_args(2):kwargs()' (at rel -13), 'aten.dropout.default:node_args(1):kwargs()' (at rel -1)]": {
        "count": 12
      },
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.add.Tensor:node_args(2):kwargs()' (at rel -17), 'aten.dropout.default:node_args(1):kwargs()' (at rel -1)]": {
        "count": 11
      }
    }
  }
}