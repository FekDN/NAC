{
  "canonical_to_index": {
    "<NONE>": 0,
    "<PAD>": 1,
    "<DATA_INPUT>": 2,
    "<PARAM_INPUT>": 3,
    "<OUTPUT>": 4,
    "<CONST_REF>": 5,
    "<PATTERN_PREFIX>": 6,
    "<COPY_PREFIX>": 7,
    "<RESERVED>": 8,
    "aten.slice.Tensor:node_args(1):kwargs()": 10,
    "aten.expand.default:node_args(1):kwargs()": 10,
    "aten.embedding.default:node_args(2):kwargs()": 11,
    "aten.add.Tensor:node_args(2):kwargs()": 12,
    "aten.layer_norm.default:node_args(3):kwargs()": 13,
    "aten.dropout.default:node_args(1):kwargs()": 14,
    "aten.ones.default:node_args(0):kwargs('device', 'pin_memory')": 15,
    "aten.unsqueeze.default:node_args(1):kwargs()": 16,
    "aten._to_copy.default:node_args(1):kwargs('dtype',)": 17,
    "aten.lift_fresh_copy.default:node_args(1):kwargs()": 18,
    "aten.detach.default:node_args(1):kwargs()": 19,
    "aten.sub.Tensor:node_args(2):kwargs()": 20,
    "aten.masked_fill.Scalar:node_args(2):kwargs()": 21,
    "aten.linear.default:node_args(3):kwargs()": 22,
    "aten.view.default:node_args(1):kwargs()": 23,
    "aten.transpose.int:node_args(1):kwargs()": 24,
    "aten.scaled_dot_product_attention.default:node_args(4):kwargs()": 25,
    "aten.gelu.default:node_args(1):kwargs()": 26,
    "aten.select.int:node_args(1):kwargs()": 27,
    "aten.tanh.default:node_args(1):kwargs()": 28,
    "aten.ne.Scalar:node_args(1):kwargs()": 29,
    "aten.cumsum.default:node_args(1):kwargs()": 30,
    "aten.type_as.default:node_args(2):kwargs()": 31,
    "aten.add.Tensor:node_args(1):kwargs()": 32,
    "aten.mul.Tensor:node_args(2):kwargs()": 33,
    "aten.eq.Scalar:node_args(1):kwargs()": 34,
    "aten.sum.dim_IntList:node_args(1):kwargs()": 35,
    "aten.div.Tensor:node_args(1):kwargs()": 36,
    "aten.mul.Tensor:node_args(1):kwargs()": 37,
    "aten.rsub.Scalar:node_args(1):kwargs()": 38,
    "aten.div.Tensor:node_args(2):kwargs()": 39,
    "aten.arange.default:node_args(0):kwargs('device', 'pin_memory')": 40,
    "aten.outer.default:node_args(2):kwargs()": 41,
    "aten.cat.default:node_args(1):kwargs()": 42,
    "aten._to_copy.default:node_args(1):kwargs('device', 'dtype', 'layout')": 43,
    "aten.cos.default:node_args(1):kwargs()": 44,
    "aten.sin.default:node_args(1):kwargs()": 45,
    "aten.split.Tensor:node_args(1):kwargs()": 46,
    "<built-in function getitem>:node_args(1):kwargs()": 47,
    "aten.neg.default:node_args(1):kwargs()": 48,
    "aten.cat.default:node_args(2):kwargs()": 49,
    "aten.scaled_dot_product_attention.default:node_args(4):kwargs('scale',)": 50,
    "aten.erf.default:node_args(1):kwargs()": 51,
    "aten.linear.default:node_args(2):kwargs()": 52,
    "aten.zeros.default:node_args(0):kwargs('device', 'dtype', 'pin_memory')": 53,
    "aten.matmul.default:node_args(2):kwargs()": 54,
    "aten.softmax.int:node_args(1):kwargs()": 55,
    "aten.permute.default:node_args(1):kwargs()": 56,
    "aten.clone.default:node_args(1):kwargs('memory_format',)": 57,
    "aten.arange.start:node_args(0):kwargs('device', 'pin_memory')": 58,
    "aten.full.default:node_args(0):kwargs('device', 'dtype', 'pin_memory')": 59,
    "aten.triu.default:node_args(1):kwargs()": 60,
    "aten.gt.Tensor:node_args(2):kwargs()": 61,
    "aten.where.self:node_args(3):kwargs()": 62,
    "aten.pow.Tensor_Scalar:node_args(1):kwargs()": 63
  },
  "index_to_canonical": {
    "0": "<NONE>",
    "1": "<PAD>",
    "2": "<DATA_INPUT>",
    "3": "<PARAM_INPUT>",
    "4": "<OUTPUT>",
    "5": "<CONST_REF>",
    "6": "<PATTERN_PREFIX>",
    "7": "<COPY_PREFIX>",
    "8": "<RESERVED>",
    "10": "aten.expand.default:node_args(1):kwargs()",
    "11": "aten.embedding.default:node_args(2):kwargs()",
    "12": "aten.add.Tensor:node_args(2):kwargs()",
    "13": "aten.layer_norm.default:node_args(3):kwargs()",
    "14": "aten.dropout.default:node_args(1):kwargs()",
    "15": "aten.ones.default:node_args(0):kwargs('device', 'pin_memory')",
    "16": "aten.unsqueeze.default:node_args(1):kwargs()",
    "17": "aten._to_copy.default:node_args(1):kwargs('dtype',)",
    "18": "aten.lift_fresh_copy.default:node_args(1):kwargs()",
    "19": "aten.detach.default:node_args(1):kwargs()",
    "20": "aten.sub.Tensor:node_args(2):kwargs()",
    "21": "aten.masked_fill.Scalar:node_args(2):kwargs()",
    "22": "aten.linear.default:node_args(3):kwargs()",
    "23": "aten.view.default:node_args(1):kwargs()",
    "24": "aten.transpose.int:node_args(1):kwargs()",
    "25": "aten.scaled_dot_product_attention.default:node_args(4):kwargs()",
    "26": "aten.gelu.default:node_args(1):kwargs()",
    "27": "aten.select.int:node_args(1):kwargs()",
    "28": "aten.tanh.default:node_args(1):kwargs()",
    "29": "aten.ne.Scalar:node_args(1):kwargs()",
    "30": "aten.cumsum.default:node_args(1):kwargs()",
    "31": "aten.type_as.default:node_args(2):kwargs()",
    "32": "aten.add.Tensor:node_args(1):kwargs()",
    "33": "aten.mul.Tensor:node_args(2):kwargs()",
    "34": "aten.eq.Scalar:node_args(1):kwargs()",
    "35": "aten.sum.dim_IntList:node_args(1):kwargs()",
    "36": "aten.div.Tensor:node_args(1):kwargs()",
    "37": "aten.mul.Tensor:node_args(1):kwargs()",
    "38": "aten.rsub.Scalar:node_args(1):kwargs()",
    "39": "aten.div.Tensor:node_args(2):kwargs()",
    "40": "aten.arange.default:node_args(0):kwargs('device', 'pin_memory')",
    "41": "aten.outer.default:node_args(2):kwargs()",
    "42": "aten.cat.default:node_args(1):kwargs()",
    "43": "aten._to_copy.default:node_args(1):kwargs('device', 'dtype', 'layout')",
    "44": "aten.cos.default:node_args(1):kwargs()",
    "45": "aten.sin.default:node_args(1):kwargs()",
    "46": "aten.split.Tensor:node_args(1):kwargs()",
    "47": "<built-in function getitem>:node_args(1):kwargs()",
    "48": "aten.neg.default:node_args(1):kwargs()",
    "49": "aten.cat.default:node_args(2):kwargs()",
    "50": "aten.scaled_dot_product_attention.default:node_args(4):kwargs('scale',)",
    "51": "aten.erf.default:node_args(1):kwargs()",
    "52": "aten.linear.default:node_args(2):kwargs()",
    "53": "aten.zeros.default:node_args(0):kwargs('device', 'dtype', 'pin_memory')",
    "54": "aten.matmul.default:node_args(2):kwargs()",
    "55": "aten.softmax.int:node_args(1):kwargs()",
    "56": "aten.permute.default:node_args(1):kwargs()",
    "57": "aten.clone.default:node_args(1):kwargs('memory_format',)",
    "58": "aten.arange.start:node_args(0):kwargs('device', 'pin_memory')",
    "59": "aten.full.default:node_args(0):kwargs('device', 'dtype', 'pin_memory')",
    "60": "aten.triu.default:node_args(1):kwargs()",
    "61": "aten.gt.Tensor:node_args(2):kwargs()",
    "62": "aten.where.self:node_args(3):kwargs()",
    "63": "aten.pow.Tensor_Scalar:node_args(1):kwargs()"
  },
  "variation_to_index": {
    "in0": 10,
    "in0,in1": 11,
    "in0,in1,in2": 12,
    "in0,in1,in2,in3": 13,
    "in1,in0": 14
  },
  "constants": {
    "10": {
      "type": "int",
      "value": 0
    },
    "11": {
      "type": "int",
      "value": 9223372036854775807
    },
    "12": {
      "type": "int",
      "value": 1
    },
    "13": {
      "type": "int",
      "value": 64
    },
    "14": {
      "type": "immutable_list",
      "value": [
        1,
        64
      ]
    },
    "15": {
      "type": "immutable_list",
      "value": [
        768
      ]
    },
    "16": {
      "type": "float",
      "value": 1e-12
    },
    "17": {
      "type": "float",
      "value": 0.1
    },
    "18": {
      "type": "torch.device",
      "value": "cpu"
    },
    "19": {
      "type": "int",
      "value": 2
    },
    "20": {
      "type": "int",
      "value": 3
    },
    "21": {
      "type": "immutable_list",
      "value": [
        1,
        1,
        64,
        64
      ]
    },
    "22": {
      "type": "torch.dtype",
      "value": "torch.float32"
    },
    "23": {
      "type": "torch.dtype",
      "value": "torch.bool"
    },
    "24": {
      "type": "float",
      "value": -3.4028234663852886e+38
    },
    "25": {
      "type": "immutable_list",
      "value": [
        1,
        -1,
        12,
        64
      ]
    },
    "26": {
      "type": "immutable_list",
      "value": [
        1,
        64,
        768
      ]
    },
    "27": {
      "type": "torch.dtype",
      "value": "torch.int32"
    },
    "28": {
      "type": "torch.dtype",
      "value": "torch.int64"
    },
    "29": {
      "type": "immutable_list",
      "value": [
        384
      ]
    },
    "30": {
      "type": "float",
      "value": 0.144
    },
    "31": {
      "type": "immutable_list",
      "value": [
        1,
        -1,
        12,
        32
      ]
    },
    "32": {
      "type": "immutable_list",
      "value": [
        1,
        64,
        384
      ]
    },
    "33": {
      "type": "int",
      "value": 32
    },
    "34": {
      "type": "int",
      "value": -1
    },
    "35": {
      "type": "immutable_list",
      "value": [
        -1
      ]
    },
    "36": {
      "type": "float",
      "value": 0.88
    },
    "37": {
      "type": "immutable_list",
      "value": [
        640
      ]
    },
    "38": {
      "type": "immutable_list",
      "value": [
        1,
        64,
        -1,
        32
      ]
    },
    "39": {
      "type": "float",
      "value": 0.1767766952966369
    },
    "40": {
      "type": "torch.layout",
      "value": "torch.strided"
    },
    "41": {
      "type": "int",
      "value": 16
    },
    "42": {
      "type": "immutable_list",
      "value": [
        1,
        64,
        -1
      ]
    },
    "43": {
      "type": "float",
      "value": 0.5
    },
    "44": {
      "type": "float",
      "value": 1.4142135623730951
    },
    "45": {
      "type": "immutable_list",
      "value": [
        1024
      ]
    },
    "46": {
      "type": "immutable_list",
      "value": [
        1,
        -1,
        16,
        64
      ]
    },
    "47": {
      "type": "int",
      "value": -2
    },
    "48": {
      "type": "float",
      "value": 8.0
    },
    "49": {
      "type": "immutable_list",
      "value": [
        0,
        2,
        1,
        3
      ]
    },
    "50": {
      "type": "torch.memory_format",
      "value": "torch.contiguous_format"
    },
    "51": {
      "type": "immutable_list",
      "value": [
        1,
        64,
        1024
      ]
    },
    "52": {
      "type": "immutable_list",
      "value": [
        1,
        -1,
        768
      ]
    },
    "53": {
      "type": "immutable_list",
      "value": [
        64,
        65
      ]
    },
    "54": {
      "type": "int",
      "value": 65
    },
    "55": {
      "type": "immutable_list",
      "value": [
        -1,
        1
      ]
    },
    "56": {
      "type": "immutable_list",
      "value": [
        1,
        64,
        12,
        64
      ]
    },
    "57": {
      "type": "immutable_list",
      "value": [
        1,
        1,
        -1,
        -1
      ]
    },
    "58": {
      "type": "float",
      "value": 0.044715
    },
    "59": {
      "type": "float",
      "value": 0.7978845608028654
    },
    "60": {
      "type": "immutable_list",
      "value": [
        -1,
        64,
        768
      ]
    }
  },
  "index_to_constant": {
    "10": "0",
    "11": "9223372036854775807",
    "12": "1",
    "13": "64",
    "14": "[1, 64]",
    "15": "[768]",
    "16": "1e-12",
    "17": "0.1",
    "18": "cpu",
    "19": "2",
    "20": "3",
    "21": "[1, 1, 64, 64]",
    "22": "torch.float32",
    "23": "torch.bool",
    "24": "-3.4028234663852886e+38",
    "25": "[1, -1, 12, 64]",
    "26": "[1, 64, 768]",
    "27": "torch.int32",
    "28": "torch.int64",
    "29": "[384]",
    "30": "0.144",
    "31": "[1, -1, 12, 32]",
    "32": "[1, 64, 384]",
    "33": "32",
    "34": "-1",
    "35": "[-1]",
    "36": "0.88",
    "37": "[640]",
    "38": "[1, 64, -1, 32]",
    "39": "0.1767766952966369",
    "40": "torch.strided",
    "41": "16",
    "42": "[1, 64, -1]",
    "43": "0.5",
    "44": "1.4142135623730951",
    "45": "[1024]",
    "46": "[1, -1, 16, 64]",
    "47": "-2",
    "48": "8.0",
    "49": "[0, 2, 1, 3]",
    "50": "torch.contiguous_format",
    "51": "[1, 64, 1024]",
    "52": "[1, -1, 768]",
    "53": "[64, 65]",
    "54": "65",
    "55": "[-1, 1]",
    "56": "[1, 64, 12, 64]",
    "57": "[1, 1, -1, -1]",
    "58": "0.044715",
    "59": "0.7978845608028654",
    "60": "[-1, 64, 768]"
  },
  "constant_group_to_index": {
    "arg1=10;arg2=10;arg3=11": 10,
    "arg1=12;arg2=10;arg3=13": 11,
    "arg1=15;arg4=16": 12,
    "arg1=17;arg2=10": 13,
    "arg0=14;device=18;pin_memory=10": 14,
    "arg1=20;arg2=10;arg3=11": 15,
    "arg1=12;arg2=19": 16,
    "arg1=12;arg2=10": 17,
    "arg1=29;arg4=16": 18,
    "arg1=30;arg2=10": 19,
    "arg0=13;device=18;pin_memory=10": 20,
    "device=18;dtype=22;layout=40": 21,
    "arg1=19;arg2=10;arg3=11": 22,
    "arg1=12;arg2=10;arg3=11": 23,
    "arg1=41;arg2=34": 24,
    "arg1=10;arg2=10": 25,
    "arg0=14;device=18;dtype=28;pin_memory=10": 26,
    "arg1=45;arg4=16": 27,
    "arg1=34;arg2=47": 28,
    "arg0=10;arg1=13;device=18;pin_memory=10": 29,
    "arg0=53;arg1=24;device=18;dtype=22;pin_memory=10": 30,
    "arg0=54;device=18;pin_memory=10": 31,
    "arg1=19;arg2=10;arg3=13": 32,
    "arg1=20;arg2=10;arg3=13": 33
  },
  "index_to_constant_group": {
    "10": "arg1=10;arg2=10;arg3=11",
    "11": "arg1=12;arg2=10;arg3=13",
    "12": "arg1=15;arg4=16",
    "13": "arg1=17;arg2=10",
    "14": "arg0=14;device=18;pin_memory=10",
    "15": "arg1=20;arg2=10;arg3=11",
    "16": "arg1=12;arg2=19",
    "17": "arg1=12;arg2=10",
    "18": "arg1=29;arg4=16",
    "19": "arg1=30;arg2=10",
    "20": "arg0=13;device=18;pin_memory=10",
    "21": "device=18;dtype=22;layout=40",
    "22": "arg1=19;arg2=10;arg3=11",
    "23": "arg1=12;arg2=10;arg3=11",
    "24": "arg1=41;arg2=34",
    "25": "arg1=10;arg2=10",
    "26": "arg0=14;device=18;dtype=28;pin_memory=10",
    "27": "arg1=45;arg4=16",
    "28": "arg1=34;arg2=47",
    "29": "arg0=10;arg1=13;device=18;pin_memory=10",
    "30": "arg0=53;arg1=24;device=18;dtype=22;pin_memory=10",
    "31": "arg0=54;device=18;pin_memory=10",
    "32": "arg1=19;arg2=10;arg3=13",
    "33": "arg1=20;arg2=10;arg3=13"
  },
  "param_name_to_index": {
    "p_embeddings_position_embeddings_weight": 10,
    "p_embeddings_layernorm_weight": 11,
    "p_embeddings_layernorm_bias": 12,
    "p_encoder_layer_0_attention_self_query_weight": 13,
    "p_encoder_layer_0_attention_self_query_bias": 14,
    "p_encoder_layer_0_attention_self_key_weight": 15,
    "p_encoder_layer_0_attention_self_key_bias": 16,
    "p_encoder_layer_0_attention_self_value_weight": 17,
    "p_encoder_layer_0_attention_self_value_bias": 18,
    "p_encoder_layer_0_attention_output_dense_weight": 19,
    "p_encoder_layer_0_attention_output_dense_bias": 20,
    "p_encoder_layer_0_attention_output_layernorm_weight": 21,
    "p_encoder_layer_0_attention_output_layernorm_bias": 22,
    "p_encoder_layer_0_intermediate_dense_weight": 23,
    "p_encoder_layer_0_intermediate_dense_bias": 24,
    "p_encoder_layer_0_output_dense_weight": 25,
    "p_encoder_layer_0_output_dense_bias": 26,
    "p_encoder_layer_0_output_layernorm_weight": 27,
    "p_encoder_layer_0_output_layernorm_bias": 28,
    "p_encoder_layer_1_attention_self_query_weight": 29,
    "p_encoder_layer_1_attention_self_query_bias": 30,
    "p_encoder_layer_1_attention_self_key_weight": 31,
    "p_encoder_layer_1_attention_self_key_bias": 32,
    "p_encoder_layer_1_attention_self_value_weight": 33,
    "p_encoder_layer_1_attention_self_value_bias": 34,
    "p_encoder_layer_1_attention_output_dense_weight": 35,
    "p_encoder_layer_1_attention_output_dense_bias": 36,
    "p_encoder_layer_1_attention_output_layernorm_weight": 37,
    "p_encoder_layer_1_attention_output_layernorm_bias": 38,
    "p_encoder_layer_1_intermediate_dense_weight": 39,
    "p_encoder_layer_1_intermediate_dense_bias": 40,
    "p_encoder_layer_1_output_dense_weight": 41,
    "p_encoder_layer_1_output_dense_bias": 42,
    "p_encoder_layer_1_output_layernorm_weight": 43,
    "p_encoder_layer_1_output_layernorm_bias": 44,
    "p_encoder_layer_2_attention_self_query_weight": 45,
    "p_encoder_layer_2_attention_self_query_bias": 46,
    "p_encoder_layer_2_attention_self_key_weight": 47,
    "p_encoder_layer_2_attention_self_key_bias": 48,
    "p_encoder_layer_2_attention_self_value_weight": 49,
    "p_encoder_layer_2_attention_self_value_bias": 50,
    "p_encoder_layer_2_attention_output_dense_weight": 51,
    "p_encoder_layer_2_attention_output_dense_bias": 52,
    "p_encoder_layer_2_attention_output_layernorm_weight": 53,
    "p_encoder_layer_2_attention_output_layernorm_bias": 54,
    "p_encoder_layer_2_intermediate_dense_weight": 55,
    "p_encoder_layer_2_intermediate_dense_bias": 56,
    "p_encoder_layer_2_output_dense_weight": 57,
    "p_encoder_layer_2_output_dense_bias": 58,
    "p_encoder_layer_2_output_layernorm_weight": 59,
    "p_encoder_layer_2_output_layernorm_bias": 60,
    "p_encoder_layer_3_attention_self_query_weight": 61,
    "p_encoder_layer_3_attention_self_query_bias": 62,
    "p_encoder_layer_3_attention_self_key_weight": 63,
    "p_encoder_layer_3_attention_self_key_bias": 64,
    "p_encoder_layer_3_attention_self_value_weight": 65,
    "p_encoder_layer_3_attention_self_value_bias": 66,
    "p_encoder_layer_3_attention_output_dense_weight": 67,
    "p_encoder_layer_3_attention_output_dense_bias": 68,
    "p_encoder_layer_3_attention_output_layernorm_weight": 69,
    "p_encoder_layer_3_attention_output_layernorm_bias": 70,
    "p_encoder_layer_3_intermediate_dense_weight": 71,
    "p_encoder_layer_3_intermediate_dense_bias": 72,
    "p_encoder_layer_3_output_dense_weight": 73,
    "p_encoder_layer_3_output_dense_bias": 74,
    "p_encoder_layer_3_output_layernorm_weight": 75,
    "p_encoder_layer_3_output_layernorm_bias": 76,
    "p_encoder_layer_4_attention_self_query_weight": 77,
    "p_encoder_layer_4_attention_self_query_bias": 78,
    "p_encoder_layer_4_attention_self_key_weight": 79,
    "p_encoder_layer_4_attention_self_key_bias": 80,
    "p_encoder_layer_4_attention_self_value_weight": 81,
    "p_encoder_layer_4_attention_self_value_bias": 82,
    "p_encoder_layer_4_attention_output_dense_weight": 83,
    "p_encoder_layer_4_attention_output_dense_bias": 84,
    "p_encoder_layer_4_attention_output_layernorm_weight": 85,
    "p_encoder_layer_4_attention_output_layernorm_bias": 86,
    "p_encoder_layer_4_intermediate_dense_weight": 87,
    "p_encoder_layer_4_intermediate_dense_bias": 88,
    "p_encoder_layer_4_output_dense_weight": 89,
    "p_encoder_layer_4_output_dense_bias": 90,
    "p_encoder_layer_4_output_layernorm_weight": 91,
    "p_encoder_layer_4_output_layernorm_bias": 92,
    "p_encoder_layer_5_attention_self_query_weight": 93,
    "p_encoder_layer_5_attention_self_query_bias": 94,
    "p_encoder_layer_5_attention_self_key_weight": 95,
    "p_encoder_layer_5_attention_self_key_bias": 96,
    "p_encoder_layer_5_attention_self_value_weight": 97,
    "p_encoder_layer_5_attention_self_value_bias": 98,
    "p_encoder_layer_5_attention_output_dense_weight": 99,
    "p_encoder_layer_5_attention_output_dense_bias": 100,
    "p_encoder_layer_5_attention_output_layernorm_weight": 101,
    "p_encoder_layer_5_attention_output_layernorm_bias": 102,
    "p_encoder_layer_5_intermediate_dense_weight": 103,
    "p_encoder_layer_5_intermediate_dense_bias": 104,
    "p_encoder_layer_5_output_dense_weight": 105,
    "p_encoder_layer_5_output_dense_bias": 106,
    "p_encoder_layer_5_output_layernorm_weight": 107,
    "p_encoder_layer_5_output_layernorm_bias": 108,
    "p_encoder_layer_6_attention_self_query_weight": 109,
    "p_encoder_layer_6_attention_self_query_bias": 110,
    "p_encoder_layer_6_attention_self_key_weight": 111,
    "p_encoder_layer_6_attention_self_key_bias": 112,
    "p_encoder_layer_6_attention_self_value_weight": 113,
    "p_encoder_layer_6_attention_self_value_bias": 114,
    "p_encoder_layer_6_attention_output_dense_weight": 115,
    "p_encoder_layer_6_attention_output_dense_bias": 116,
    "p_encoder_layer_6_attention_output_layernorm_weight": 117,
    "p_encoder_layer_6_attention_output_layernorm_bias": 118,
    "p_encoder_layer_6_intermediate_dense_weight": 119,
    "p_encoder_layer_6_intermediate_dense_bias": 120,
    "p_encoder_layer_6_output_dense_weight": 121,
    "p_encoder_layer_6_output_dense_bias": 122,
    "p_encoder_layer_6_output_layernorm_weight": 123,
    "p_encoder_layer_6_output_layernorm_bias": 124,
    "p_encoder_layer_7_attention_self_query_weight": 125,
    "p_encoder_layer_7_attention_self_query_bias": 126,
    "p_encoder_layer_7_attention_self_key_weight": 127,
    "p_encoder_layer_7_attention_self_key_bias": 128,
    "p_encoder_layer_7_attention_self_value_weight": 129,
    "p_encoder_layer_7_attention_self_value_bias": 130,
    "p_encoder_layer_7_attention_output_dense_weight": 131,
    "p_encoder_layer_7_attention_output_dense_bias": 132,
    "p_encoder_layer_7_attention_output_layernorm_weight": 133,
    "p_encoder_layer_7_attention_output_layernorm_bias": 134,
    "p_encoder_layer_7_intermediate_dense_weight": 135,
    "p_encoder_layer_7_intermediate_dense_bias": 136,
    "p_encoder_layer_7_output_dense_weight": 137,
    "p_encoder_layer_7_output_dense_bias": 138,
    "p_encoder_layer_7_output_layernorm_weight": 139,
    "p_encoder_layer_7_output_layernorm_bias": 140,
    "p_encoder_layer_8_attention_self_query_weight": 141,
    "p_encoder_layer_8_attention_self_query_bias": 142,
    "p_encoder_layer_8_attention_self_key_weight": 143,
    "p_encoder_layer_8_attention_self_key_bias": 144,
    "p_encoder_layer_8_attention_self_value_weight": 145,
    "p_encoder_layer_8_attention_self_value_bias": 146,
    "p_encoder_layer_8_attention_output_dense_weight": 147,
    "p_encoder_layer_8_attention_output_dense_bias": 148,
    "p_encoder_layer_8_attention_output_layernorm_weight": 149,
    "p_encoder_layer_8_attention_output_layernorm_bias": 150,
    "p_encoder_layer_8_intermediate_dense_weight": 151,
    "p_encoder_layer_8_intermediate_dense_bias": 152,
    "p_encoder_layer_8_output_dense_weight": 153,
    "p_encoder_layer_8_output_dense_bias": 154,
    "p_encoder_layer_8_output_layernorm_weight": 155,
    "p_encoder_layer_8_output_layernorm_bias": 156,
    "p_encoder_layer_9_attention_self_query_weight": 157,
    "p_encoder_layer_9_attention_self_query_bias": 158,
    "p_encoder_layer_9_attention_self_key_weight": 159,
    "p_encoder_layer_9_attention_self_key_bias": 160,
    "p_encoder_layer_9_attention_self_value_weight": 161,
    "p_encoder_layer_9_attention_self_value_bias": 162,
    "p_encoder_layer_9_attention_output_dense_weight": 163,
    "p_encoder_layer_9_attention_output_dense_bias": 164,
    "p_encoder_layer_9_attention_output_layernorm_weight": 165,
    "p_encoder_layer_9_attention_output_layernorm_bias": 166,
    "p_encoder_layer_9_intermediate_dense_weight": 167,
    "p_encoder_layer_9_intermediate_dense_bias": 168,
    "p_encoder_layer_9_output_dense_weight": 169,
    "p_encoder_layer_9_output_dense_bias": 170,
    "p_encoder_layer_9_output_layernorm_weight": 171,
    "p_encoder_layer_9_output_layernorm_bias": 172,
    "p_encoder_layer_10_attention_self_query_weight": 173,
    "p_encoder_layer_10_attention_self_query_bias": 174,
    "p_encoder_layer_10_attention_self_key_weight": 175,
    "p_encoder_layer_10_attention_self_key_bias": 176,
    "p_encoder_layer_10_attention_self_value_weight": 177,
    "p_encoder_layer_10_attention_self_value_bias": 178,
    "p_encoder_layer_10_attention_output_dense_weight": 179,
    "p_encoder_layer_10_attention_output_dense_bias": 180,
    "p_encoder_layer_10_attention_output_layernorm_weight": 181,
    "p_encoder_layer_10_attention_output_layernorm_bias": 182,
    "p_encoder_layer_10_intermediate_dense_weight": 183,
    "p_encoder_layer_10_intermediate_dense_bias": 184,
    "p_encoder_layer_10_output_dense_weight": 185,
    "p_encoder_layer_10_output_dense_bias": 186,
    "p_encoder_layer_10_output_layernorm_weight": 187,
    "p_encoder_layer_10_output_layernorm_bias": 188,
    "p_encoder_layer_11_attention_self_query_weight": 189,
    "p_encoder_layer_11_attention_self_query_bias": 190,
    "p_encoder_layer_11_attention_self_key_weight": 191,
    "p_encoder_layer_11_attention_self_key_bias": 192,
    "p_encoder_layer_11_attention_self_value_weight": 193,
    "p_encoder_layer_11_attention_self_value_bias": 194,
    "p_encoder_layer_11_attention_output_dense_weight": 195,
    "p_encoder_layer_11_attention_output_dense_bias": 196,
    "p_encoder_layer_11_attention_output_layernorm_weight": 197,
    "p_encoder_layer_11_attention_output_layernorm_bias": 198,
    "p_encoder_layer_11_intermediate_dense_weight": 199,
    "p_encoder_layer_11_intermediate_dense_bias": 200,
    "p_encoder_layer_11_output_dense_weight": 201,
    "p_encoder_layer_11_output_dense_bias": 202,
    "p_encoder_layer_11_output_layernorm_weight": 203,
    "p_encoder_layer_11_output_layernorm_bias": 204,
    "p_pooler_dense_weight": 205,
    "p_pooler_dense_bias": 206,
    "b_embeddings_token_type_ids": 207,
    "b_embeddings_position_ids": 208,
    "use_cache": 209,
    "c_lifted_tensor_0": 210,
    "input_ids": 211,
    "p_fn_bias": 212,
    "input": 213,
    "p_predictions_transform_dense_bias": 214,
    "p_predictions_transform_layernorm_weight": 215,
    "p_predictions_transform_layernorm_bias": 216,
    "p_predictions_decoder_weight": 217,
    "p_predictions_decoder_bias": 218,
    "sequence_output": 219,
    "p_encoder_layer_0_attention_layernorm_bias": 220,
    "p_encoder_layer_0_layernorm_weight": 221,
    "p_encoder_layer_0_layernorm_bias": 222,
    "p_encoder_layer_1_attention_layernorm_weight": 223,
    "p_encoder_layer_1_attention_layernorm_bias": 224,
    "p_encoder_layer_1_layernorm_weight": 225,
    "p_encoder_layer_1_layernorm_bias": 226,
    "p_encoder_layer_2_attention_layernorm_weight": 227,
    "p_encoder_layer_2_attention_layernorm_bias": 228,
    "p_encoder_layer_2_layernorm_weight": 229,
    "p_encoder_layer_2_layernorm_bias": 230,
    "p_encoder_layer_3_attention_layernorm_weight": 231,
    "p_encoder_layer_3_attention_layernorm_bias": 232,
    "p_encoder_layer_3_layernorm_weight": 233,
    "p_encoder_layer_3_layernorm_bias": 234,
    "p_encoder_layer_4_attention_layernorm_weight": 235,
    "p_encoder_layer_4_attention_layernorm_bias": 236,
    "p_encoder_layer_4_layernorm_weight": 237,
    "p_encoder_layer_4_layernorm_bias": 238,
    "p_encoder_layer_5_attention_layernorm_weight": 239,
    "p_encoder_layer_5_attention_layernorm_bias": 240,
    "p_encoder_layer_5_layernorm_weight": 241,
    "p_encoder_layer_5_layernorm_bias": 242,
    "p_encoder_layer_6_attention_layernorm_weight": 243,
    "p_encoder_layer_6_attention_layernorm_bias": 244,
    "p_encoder_layer_6_layernorm_weight": 245,
    "p_encoder_layer_6_layernorm_bias": 246,
    "p_encoder_layer_7_attention_layernorm_weight": 247,
    "p_encoder_layer_7_attention_layernorm_bias": 248,
    "p_encoder_layer_7_layernorm_weight": 249,
    "p_encoder_layer_7_layernorm_bias": 250,
    "p_encoder_layer_8_attention_layernorm_weight": 251,
    "p_encoder_layer_8_attention_layernorm_bias": 252,
    "p_encoder_layer_8_layernorm_weight": 253,
    "p_encoder_layer_8_layernorm_bias": 254,
    "p_encoder_layer_9_attention_layernorm_weight": 255,
    "p_encoder_layer_9_attention_layernorm_bias": 256,
    "p_encoder_layer_9_layernorm_weight": 257,
    "p_encoder_layer_9_layernorm_bias": 258,
    "p_encoder_layer_10_attention_layernorm_weight": 259,
    "p_encoder_layer_10_attention_layernorm_bias": 260,
    "p_encoder_layer_10_layernorm_weight": 261,
    "p_encoder_layer_10_layernorm_bias": 262,
    "p_encoder_layer_11_attention_layernorm_weight": 263,
    "p_encoder_layer_11_attention_layernorm_bias": 264,
    "p_encoder_layer_11_layernorm_weight": 265,
    "p_encoder_layer_11_layernorm_bias": 266,
    "p_encoder_layer_12_attention_layernorm_weight": 267,
    "p_encoder_layer_12_attention_layernorm_bias": 268,
    "p_encoder_layer_12_attention_self_query_weight": 269,
    "p_encoder_layer_12_attention_self_query_bias": 270,
    "p_encoder_layer_12_attention_self_key_weight": 271,
    "p_encoder_layer_12_attention_self_key_bias": 272,
    "p_encoder_layer_12_attention_self_value_weight": 273,
    "p_encoder_layer_12_attention_self_value_bias": 274,
    "p_encoder_layer_12_attention_output_dense_weight": 275,
    "p_encoder_layer_12_attention_output_dense_bias": 276,
    "p_encoder_layer_12_layernorm_weight": 277,
    "p_encoder_layer_12_layernorm_bias": 278,
    "p_encoder_layer_12_intermediate_dense_weight": 279,
    "p_encoder_layer_12_intermediate_dense_bias": 280,
    "p_encoder_layer_12_output_dense_weight": 281,
    "p_encoder_layer_12_output_dense_bias": 282,
    "p_encoder_layer_13_attention_layernorm_weight": 283,
    "p_encoder_layer_13_attention_layernorm_bias": 284,
    "p_encoder_layer_13_attention_self_query_weight": 285,
    "p_encoder_layer_13_attention_self_query_bias": 286,
    "p_encoder_layer_13_attention_self_key_weight": 287,
    "p_encoder_layer_13_attention_self_key_bias": 288,
    "p_encoder_layer_13_attention_self_value_weight": 289,
    "p_encoder_layer_13_attention_self_value_bias": 290,
    "p_encoder_layer_13_attention_output_dense_weight": 291,
    "p_encoder_layer_13_attention_output_dense_bias": 292,
    "p_encoder_layer_13_layernorm_weight": 293,
    "p_encoder_layer_13_layernorm_bias": 294,
    "p_encoder_layer_13_intermediate_dense_weight": 295,
    "p_encoder_layer_13_intermediate_dense_bias": 296,
    "p_encoder_layer_13_output_dense_weight": 297,
    "p_encoder_layer_13_output_dense_bias": 298,
    "p_encoder_layer_14_attention_layernorm_weight": 299,
    "p_encoder_layer_14_attention_layernorm_bias": 300,
    "p_encoder_layer_14_attention_self_query_weight": 301,
    "p_encoder_layer_14_attention_self_query_bias": 302,
    "p_encoder_layer_14_attention_self_key_weight": 303,
    "p_encoder_layer_14_attention_self_key_bias": 304,
    "p_encoder_layer_14_attention_self_value_weight": 305,
    "p_encoder_layer_14_attention_self_value_bias": 306,
    "p_encoder_layer_14_attention_output_dense_weight": 307,
    "p_encoder_layer_14_attention_output_dense_bias": 308,
    "p_encoder_layer_14_layernorm_weight": 309,
    "p_encoder_layer_14_layernorm_bias": 310,
    "p_encoder_layer_14_intermediate_dense_weight": 311,
    "p_encoder_layer_14_intermediate_dense_bias": 312,
    "p_encoder_layer_14_output_dense_weight": 313,
    "p_encoder_layer_14_output_dense_bias": 314,
    "p_encoder_layer_15_attention_layernorm_weight": 315,
    "p_encoder_layer_15_attention_layernorm_bias": 316,
    "p_encoder_layer_15_attention_self_query_weight": 317,
    "p_encoder_layer_15_attention_self_query_bias": 318,
    "p_encoder_layer_15_attention_self_key_weight": 319,
    "p_encoder_layer_15_attention_self_key_bias": 320,
    "p_encoder_layer_15_attention_self_value_weight": 321,
    "p_encoder_layer_15_attention_self_value_bias": 322,
    "p_encoder_layer_15_attention_output_dense_weight": 323,
    "p_encoder_layer_15_attention_output_dense_bias": 324,
    "p_encoder_layer_15_layernorm_weight": 325,
    "p_encoder_layer_15_layernorm_bias": 326,
    "p_encoder_layer_15_intermediate_dense_weight": 327,
    "p_encoder_layer_15_intermediate_dense_bias": 328,
    "p_encoder_layer_15_output_dense_weight": 329,
    "p_encoder_layer_15_output_dense_bias": 330,
    "p_encoder_layer_16_attention_layernorm_weight": 331,
    "p_encoder_layer_16_attention_layernorm_bias": 332,
    "p_encoder_layer_16_attention_self_query_weight": 333,
    "p_encoder_layer_16_attention_self_query_bias": 334,
    "p_encoder_layer_16_attention_self_key_weight": 335,
    "p_encoder_layer_16_attention_self_key_bias": 336,
    "p_encoder_layer_16_attention_self_value_weight": 337,
    "p_encoder_layer_16_attention_self_value_bias": 338,
    "p_encoder_layer_16_attention_output_dense_weight": 339,
    "p_encoder_layer_16_attention_output_dense_bias": 340,
    "p_encoder_layer_16_layernorm_weight": 341,
    "p_encoder_layer_16_layernorm_bias": 342,
    "p_encoder_layer_16_intermediate_dense_weight": 343,
    "p_encoder_layer_16_intermediate_dense_bias": 344,
    "p_encoder_layer_16_output_dense_weight": 345,
    "p_encoder_layer_16_output_dense_bias": 346,
    "p_encoder_layer_17_attention_layernorm_weight": 347,
    "p_encoder_layer_17_attention_layernorm_bias": 348,
    "p_encoder_layer_17_attention_self_query_weight": 349,
    "p_encoder_layer_17_attention_self_query_bias": 350,
    "p_encoder_layer_17_attention_self_key_weight": 351,
    "p_encoder_layer_17_attention_self_key_bias": 352,
    "p_encoder_layer_17_attention_self_value_weight": 353,
    "p_encoder_layer_17_attention_self_value_bias": 354,
    "p_encoder_layer_17_attention_output_dense_weight": 355,
    "p_encoder_layer_17_attention_output_dense_bias": 356,
    "p_encoder_layer_17_layernorm_weight": 357,
    "p_encoder_layer_17_layernorm_bias": 358,
    "p_encoder_layer_17_intermediate_dense_weight": 359,
    "p_encoder_layer_17_intermediate_dense_bias": 360,
    "p_encoder_layer_17_output_dense_weight": 361,
    "p_encoder_layer_17_output_dense_bias": 362,
    "p_encoder_layer_18_attention_layernorm_weight": 363,
    "p_encoder_layer_18_attention_layernorm_bias": 364,
    "p_encoder_layer_18_attention_self_query_weight": 365,
    "p_encoder_layer_18_attention_self_query_bias": 366,
    "p_encoder_layer_18_attention_self_key_weight": 367,
    "p_encoder_layer_18_attention_self_key_bias": 368,
    "p_encoder_layer_18_attention_self_value_weight": 369,
    "p_encoder_layer_18_attention_self_value_bias": 370,
    "p_encoder_layer_18_attention_output_dense_weight": 371,
    "p_encoder_layer_18_attention_output_dense_bias": 372,
    "p_encoder_layer_18_layernorm_weight": 373,
    "p_encoder_layer_18_layernorm_bias": 374,
    "p_encoder_layer_18_intermediate_dense_weight": 375,
    "p_encoder_layer_18_intermediate_dense_bias": 376,
    "p_encoder_layer_18_output_dense_weight": 377,
    "p_encoder_layer_18_output_dense_bias": 378,
    "p_encoder_layer_19_attention_layernorm_weight": 379,
    "p_encoder_layer_19_attention_layernorm_bias": 380,
    "p_encoder_layer_19_attention_self_query_weight": 381,
    "p_encoder_layer_19_attention_self_query_bias": 382,
    "p_encoder_layer_19_attention_self_key_weight": 383,
    "p_encoder_layer_19_attention_self_key_bias": 384,
    "p_encoder_layer_19_attention_self_value_weight": 385,
    "p_encoder_layer_19_attention_self_value_bias": 386,
    "p_encoder_layer_19_attention_output_dense_weight": 387,
    "p_encoder_layer_19_attention_output_dense_bias": 388,
    "p_encoder_layer_19_layernorm_weight": 389,
    "p_encoder_layer_19_layernorm_bias": 390,
    "p_encoder_layer_19_intermediate_dense_weight": 391,
    "p_encoder_layer_19_intermediate_dense_bias": 392,
    "p_encoder_layer_19_output_dense_weight": 393,
    "p_encoder_layer_19_output_dense_bias": 394,
    "p_encoder_layer_20_attention_layernorm_weight": 395,
    "p_encoder_layer_20_attention_layernorm_bias": 396,
    "p_encoder_layer_20_attention_self_query_weight": 397,
    "p_encoder_layer_20_attention_self_query_bias": 398,
    "p_encoder_layer_20_attention_self_key_weight": 399,
    "p_encoder_layer_20_attention_self_key_bias": 400,
    "p_encoder_layer_20_attention_self_value_weight": 401,
    "p_encoder_layer_20_attention_self_value_bias": 402,
    "p_encoder_layer_20_attention_output_dense_weight": 403,
    "p_encoder_layer_20_attention_output_dense_bias": 404,
    "p_encoder_layer_20_layernorm_weight": 405,
    "p_encoder_layer_20_layernorm_bias": 406,
    "p_encoder_layer_20_intermediate_dense_weight": 407,
    "p_encoder_layer_20_intermediate_dense_bias": 408,
    "p_encoder_layer_20_output_dense_weight": 409,
    "p_encoder_layer_20_output_dense_bias": 410,
    "p_encoder_layer_21_attention_layernorm_weight": 411,
    "p_encoder_layer_21_attention_layernorm_bias": 412,
    "p_encoder_layer_21_attention_self_query_weight": 413,
    "p_encoder_layer_21_attention_self_query_bias": 414,
    "p_encoder_layer_21_attention_self_key_weight": 415,
    "p_encoder_layer_21_attention_self_key_bias": 416,
    "p_encoder_layer_21_attention_self_value_weight": 417,
    "p_encoder_layer_21_attention_self_value_bias": 418,
    "p_encoder_layer_21_attention_output_dense_weight": 419,
    "p_encoder_layer_21_attention_output_dense_bias": 420,
    "p_encoder_layer_21_layernorm_weight": 421,
    "p_encoder_layer_21_layernorm_bias": 422,
    "p_encoder_layer_21_intermediate_dense_weight": 423,
    "p_encoder_layer_21_intermediate_dense_bias": 424,
    "p_encoder_layer_21_output_dense_weight": 425,
    "p_encoder_layer_21_output_dense_bias": 426,
    "p_encoder_layer_22_attention_layernorm_weight": 427,
    "p_encoder_layer_22_attention_layernorm_bias": 428,
    "p_encoder_layer_22_attention_self_query_weight": 429,
    "p_encoder_layer_22_attention_self_query_bias": 430,
    "p_encoder_layer_22_attention_self_key_weight": 431,
    "p_encoder_layer_22_attention_self_key_bias": 432,
    "p_encoder_layer_22_attention_self_value_weight": 433,
    "p_encoder_layer_22_attention_self_value_bias": 434,
    "p_encoder_layer_22_attention_output_dense_weight": 435,
    "p_encoder_layer_22_attention_output_dense_bias": 436,
    "p_encoder_layer_22_layernorm_weight": 437,
    "p_encoder_layer_22_layernorm_bias": 438,
    "p_encoder_layer_22_intermediate_dense_weight": 439,
    "p_encoder_layer_22_intermediate_dense_bias": 440,
    "p_encoder_layer_22_output_dense_weight": 441,
    "p_encoder_layer_22_output_dense_bias": 442,
    "p_encoder_layer_23_attention_layernorm_weight": 443,
    "p_encoder_layer_23_attention_layernorm_bias": 444,
    "p_encoder_layer_23_attention_self_query_weight": 445,
    "p_encoder_layer_23_attention_self_query_bias": 446,
    "p_encoder_layer_23_attention_self_key_weight": 447,
    "p_encoder_layer_23_attention_self_key_bias": 448,
    "p_encoder_layer_23_attention_self_value_weight": 449,
    "p_encoder_layer_23_attention_self_value_bias": 450,
    "p_encoder_layer_23_attention_output_dense_weight": 451,
    "p_encoder_layer_23_attention_output_dense_bias": 452,
    "p_encoder_layer_23_layernorm_weight": 453,
    "p_encoder_layer_23_layernorm_bias": 454,
    "p_encoder_layer_23_intermediate_dense_weight": 455,
    "p_encoder_layer_23_intermediate_dense_bias": 456,
    "p_encoder_layer_23_output_dense_weight": 457,
    "p_encoder_layer_23_output_dense_bias": 458,
    "p_encoder_layer_24_attention_layernorm_weight": 459,
    "p_encoder_layer_24_attention_layernorm_bias": 460,
    "p_encoder_layer_24_attention_self_query_weight": 461,
    "p_encoder_layer_24_attention_self_query_bias": 462,
    "p_encoder_layer_24_attention_self_key_weight": 463,
    "p_encoder_layer_24_attention_self_key_bias": 464,
    "p_encoder_layer_24_attention_self_value_weight": 465,
    "p_encoder_layer_24_attention_self_value_bias": 466,
    "p_encoder_layer_24_attention_output_dense_weight": 467,
    "p_encoder_layer_24_attention_output_dense_bias": 468,
    "p_encoder_layer_24_layernorm_weight": 469,
    "p_encoder_layer_24_layernorm_bias": 470,
    "p_encoder_layer_24_intermediate_dense_weight": 471,
    "p_encoder_layer_24_intermediate_dense_bias": 472,
    "p_encoder_layer_24_output_dense_weight": 473,
    "p_encoder_layer_24_output_dense_bias": 474,
    "p_encoder_layer_25_attention_layernorm_weight": 475,
    "p_encoder_layer_25_attention_layernorm_bias": 476,
    "p_encoder_layer_25_attention_self_query_weight": 477,
    "p_encoder_layer_25_attention_self_query_bias": 478,
    "p_encoder_layer_25_attention_self_key_weight": 479,
    "p_encoder_layer_25_attention_self_key_bias": 480,
    "p_encoder_layer_25_attention_self_value_weight": 481,
    "p_encoder_layer_25_attention_self_value_bias": 482,
    "p_encoder_layer_25_attention_output_dense_weight": 483,
    "p_encoder_layer_25_attention_output_dense_bias": 484,
    "p_encoder_layer_25_layernorm_weight": 485,
    "p_encoder_layer_25_layernorm_bias": 486,
    "p_encoder_layer_25_intermediate_dense_weight": 487,
    "p_encoder_layer_25_intermediate_dense_bias": 488,
    "p_encoder_layer_25_output_dense_weight": 489,
    "p_encoder_layer_25_output_dense_bias": 490,
    "p_encoder_layer_26_attention_layernorm_weight": 491,
    "p_encoder_layer_26_attention_layernorm_bias": 492,
    "p_encoder_layer_26_attention_self_query_weight": 493,
    "p_encoder_layer_26_attention_self_query_bias": 494,
    "p_encoder_layer_26_attention_self_key_weight": 495,
    "p_encoder_layer_26_attention_self_key_bias": 496,
    "p_encoder_layer_26_attention_self_value_weight": 497,
    "p_encoder_layer_26_attention_self_value_bias": 498,
    "p_encoder_layer_26_attention_output_dense_weight": 499,
    "p_encoder_layer_26_attention_output_dense_bias": 500,
    "p_encoder_layer_26_layernorm_weight": 501,
    "p_encoder_layer_26_layernorm_bias": 502,
    "p_encoder_layer_26_intermediate_dense_weight": 503,
    "p_encoder_layer_26_intermediate_dense_bias": 504,
    "p_encoder_layer_26_output_dense_weight": 505,
    "p_encoder_layer_26_output_dense_bias": 506,
    "p_encoder_layer_27_attention_layernorm_weight": 507,
    "p_encoder_layer_27_attention_layernorm_bias": 508,
    "p_encoder_layer_27_attention_self_query_weight": 509,
    "p_encoder_layer_27_attention_self_query_bias": 510,
    "p_encoder_layer_27_attention_self_key_weight": 511,
    "p_encoder_layer_27_attention_self_key_bias": 512,
    "p_encoder_layer_27_attention_self_value_weight": 513,
    "p_encoder_layer_27_attention_self_value_bias": 514,
    "p_encoder_layer_27_attention_output_dense_weight": 515,
    "p_encoder_layer_27_attention_output_dense_bias": 516,
    "p_encoder_layer_27_layernorm_weight": 517,
    "p_encoder_layer_27_layernorm_bias": 518,
    "p_encoder_layer_27_intermediate_dense_weight": 519,
    "p_encoder_layer_27_intermediate_dense_bias": 520,
    "p_encoder_layer_27_output_dense_weight": 521,
    "p_encoder_layer_27_output_dense_bias": 522,
    "p_encoder_layer_28_attention_layernorm_weight": 523,
    "p_encoder_layer_28_attention_layernorm_bias": 524,
    "p_encoder_layer_28_attention_self_query_weight": 525,
    "p_encoder_layer_28_attention_self_query_bias": 526,
    "p_encoder_layer_28_attention_self_key_weight": 527,
    "p_encoder_layer_28_attention_self_key_bias": 528,
    "p_encoder_layer_28_attention_self_value_weight": 529,
    "p_encoder_layer_28_attention_self_value_bias": 530,
    "p_encoder_layer_28_attention_output_dense_weight": 531,
    "p_encoder_layer_28_attention_output_dense_bias": 532,
    "p_encoder_layer_28_layernorm_weight": 533,
    "p_encoder_layer_28_layernorm_bias": 534,
    "p_encoder_layer_28_intermediate_dense_weight": 535,
    "p_encoder_layer_28_intermediate_dense_bias": 536,
    "p_encoder_layer_28_output_dense_weight": 537,
    "p_encoder_layer_28_output_dense_bias": 538,
    "p_encoder_layer_29_attention_layernorm_weight": 539,
    "p_encoder_layer_29_attention_layernorm_bias": 540,
    "p_encoder_layer_29_attention_self_query_weight": 541,
    "p_encoder_layer_29_attention_self_query_bias": 542,
    "p_encoder_layer_29_attention_self_key_weight": 543,
    "p_encoder_layer_29_attention_self_key_bias": 544,
    "p_encoder_layer_29_attention_self_value_weight": 545,
    "p_encoder_layer_29_attention_self_value_bias": 546,
    "p_encoder_layer_29_attention_output_dense_weight": 547,
    "p_encoder_layer_29_attention_output_dense_bias": 548,
    "p_encoder_layer_29_layernorm_weight": 549,
    "p_encoder_layer_29_layernorm_bias": 550,
    "p_encoder_layer_29_intermediate_dense_weight": 551,
    "p_encoder_layer_29_intermediate_dense_bias": 552,
    "p_encoder_layer_29_output_dense_weight": 553,
    "p_encoder_layer_29_output_dense_bias": 554,
    "p_encoder_emb_layer_norm_after_weight": 555,
    "p_encoder_emb_layer_norm_after_bias": 556,
    "b___encoder_layer_0_attention_self_rotary_embeddings__buffers__inv_freq": 557,
    "b___encoder_layer_1_attention_self_rotary_embeddings__buffers__inv_freq": 558,
    "b___encoder_layer_2_attention_self_rotary_embeddings__buffers__inv_freq": 559,
    "b___encoder_layer_3_attention_self_rotary_embeddings__buffers__inv_freq": 560,
    "b___encoder_layer_4_attention_self_rotary_embeddings__buffers__inv_freq": 561,
    "b___encoder_layer_5_attention_self_rotary_embeddings__buffers__inv_freq": 562,
    "b___encoder_layer_6_attention_self_rotary_embeddings__buffers__inv_freq": 563,
    "b___encoder_layer_7_attention_self_rotary_embeddings__buffers__inv_freq": 564,
    "b___encoder_layer_8_attention_self_rotary_embeddings__buffers__inv_freq": 565,
    "b___encoder_layer_9_attention_self_rotary_embeddings__buffers__inv_freq": 566,
    "b___encoder_layer_10_attention_self_rotary_embeddings__buffers__inv_freq": 567,
    "b___encoder_layer_11_attention_self_rotary_embeddings__buffers__inv_freq": 568,
    "b___encoder_layer_12_attention_self_rotary_embeddings__buffers__inv_freq": 569,
    "b___encoder_layer_13_attention_self_rotary_embeddings__buffers__inv_freq": 570,
    "b___encoder_layer_14_attention_self_rotary_embeddings__buffers__inv_freq": 571,
    "b___encoder_layer_15_attention_self_rotary_embeddings__buffers__inv_freq": 572,
    "b___encoder_layer_16_attention_self_rotary_embeddings__buffers__inv_freq": 573,
    "b___encoder_layer_17_attention_self_rotary_embeddings__buffers__inv_freq": 574,
    "b___encoder_layer_18_attention_self_rotary_embeddings__buffers__inv_freq": 575,
    "b___encoder_layer_19_attention_self_rotary_embeddings__buffers__inv_freq": 576,
    "b___encoder_layer_20_attention_self_rotary_embeddings__buffers__inv_freq": 577,
    "b___encoder_layer_21_attention_self_rotary_embeddings__buffers__inv_freq": 578,
    "b___encoder_layer_22_attention_self_rotary_embeddings__buffers__inv_freq": 579,
    "b___encoder_layer_23_attention_self_rotary_embeddings__buffers__inv_freq": 580,
    "b___encoder_layer_24_attention_self_rotary_embeddings__buffers__inv_freq": 581,
    "b___encoder_layer_25_attention_self_rotary_embeddings__buffers__inv_freq": 582,
    "b___encoder_layer_26_attention_self_rotary_embeddings__buffers__inv_freq": 583,
    "b___encoder_layer_27_attention_self_rotary_embeddings__buffers__inv_freq": 584,
    "b___encoder_layer_28_attention_self_rotary_embeddings__buffers__inv_freq": 585,
    "b___encoder_layer_29_attention_self_rotary_embeddings__buffers__inv_freq": 586,
    "p_encoder_layer_0_attention_ln_weight": 587,
    "p_encoder_layer_0_attention_ln_bias": 588,
    "p_encoder_layer_0_ln_weight": 589,
    "p_encoder_layer_0_ln_bias": 590,
    "p_encoder_layer_1_attention_ln_weight": 591,
    "p_encoder_layer_1_attention_ln_bias": 592,
    "p_encoder_layer_1_ln_weight": 593,
    "p_encoder_layer_1_ln_bias": 594,
    "p_encoder_layer_2_attention_ln_weight": 595,
    "p_encoder_layer_2_attention_ln_bias": 596,
    "p_encoder_layer_2_ln_weight": 597,
    "p_encoder_layer_2_ln_bias": 598,
    "p_encoder_layer_3_attention_ln_weight": 599,
    "p_encoder_layer_3_attention_ln_bias": 600,
    "p_encoder_layer_3_ln_weight": 601,
    "p_encoder_layer_3_ln_bias": 602,
    "p_encoder_layer_4_attention_ln_weight": 603,
    "p_encoder_layer_4_attention_ln_bias": 604,
    "p_encoder_layer_4_ln_weight": 605,
    "p_encoder_layer_4_ln_bias": 606,
    "p_encoder_layer_5_attention_ln_weight": 607,
    "p_encoder_layer_5_attention_ln_bias": 608,
    "p_encoder_layer_5_ln_weight": 609,
    "p_encoder_layer_5_ln_bias": 610,
    "p_encoder_layer_6_attention_ln_weight": 611,
    "p_encoder_layer_6_attention_ln_bias": 612,
    "p_encoder_layer_6_ln_weight": 613,
    "p_encoder_layer_6_ln_bias": 614,
    "p_encoder_layer_7_attention_ln_weight": 615,
    "p_encoder_layer_7_attention_ln_bias": 616,
    "p_encoder_layer_7_ln_weight": 617,
    "p_encoder_layer_7_ln_bias": 618,
    "p_encoder_layer_8_attention_ln_weight": 619,
    "p_encoder_layer_8_attention_ln_bias": 620,
    "p_encoder_layer_8_ln_weight": 621,
    "p_encoder_layer_8_ln_bias": 622,
    "p_encoder_layer_9_attention_ln_weight": 623,
    "p_encoder_layer_9_attention_ln_bias": 624,
    "p_encoder_layer_9_ln_weight": 625,
    "p_encoder_layer_9_ln_bias": 626,
    "p_encoder_layer_10_attention_ln_weight": 627,
    "p_encoder_layer_10_attention_ln_bias": 628,
    "p_encoder_layer_10_ln_weight": 629,
    "p_encoder_layer_10_ln_bias": 630,
    "p_encoder_layer_11_attention_ln_weight": 631,
    "p_encoder_layer_11_attention_ln_bias": 632,
    "p_encoder_layer_11_ln_weight": 633,
    "p_encoder_layer_11_ln_bias": 634,
    "p_encoder_layer_12_attention_ln_weight": 635,
    "p_encoder_layer_12_attention_ln_bias": 636,
    "p_encoder_layer_12_ln_weight": 637,
    "p_encoder_layer_12_ln_bias": 638,
    "p_encoder_layer_13_attention_ln_weight": 639,
    "p_encoder_layer_13_attention_ln_bias": 640,
    "p_encoder_layer_13_ln_weight": 641,
    "p_encoder_layer_13_ln_bias": 642,
    "p_encoder_layer_14_attention_ln_weight": 643,
    "p_encoder_layer_14_attention_ln_bias": 644,
    "p_encoder_layer_14_ln_weight": 645,
    "p_encoder_layer_14_ln_bias": 646,
    "p_encoder_layer_15_attention_ln_weight": 647,
    "p_encoder_layer_15_attention_ln_bias": 648,
    "p_encoder_layer_15_ln_weight": 649,
    "p_encoder_layer_15_ln_bias": 650,
    "p_encoder_layer_16_attention_ln_weight": 651,
    "p_encoder_layer_16_attention_ln_bias": 652,
    "p_encoder_layer_16_ln_weight": 653,
    "p_encoder_layer_16_ln_bias": 654,
    "p_encoder_layer_17_attention_ln_weight": 655,
    "p_encoder_layer_17_attention_ln_bias": 656,
    "p_encoder_layer_17_ln_weight": 657,
    "p_encoder_layer_17_ln_bias": 658,
    "p_encoder_layer_18_attention_ln_weight": 659,
    "p_encoder_layer_18_attention_ln_bias": 660,
    "p_encoder_layer_18_ln_weight": 661,
    "p_encoder_layer_18_ln_bias": 662,
    "p_encoder_layer_19_attention_ln_weight": 663,
    "p_encoder_layer_19_attention_ln_bias": 664,
    "p_encoder_layer_19_ln_weight": 665,
    "p_encoder_layer_19_ln_bias": 666,
    "p_encoder_layer_20_attention_ln_weight": 667,
    "p_encoder_layer_20_attention_ln_bias": 668,
    "p_encoder_layer_20_ln_weight": 669,
    "p_encoder_layer_20_ln_bias": 670,
    "p_encoder_layer_21_attention_ln_weight": 671,
    "p_encoder_layer_21_attention_ln_bias": 672,
    "p_encoder_layer_21_ln_weight": 673,
    "p_encoder_layer_21_ln_bias": 674,
    "p_encoder_layer_22_attention_ln_weight": 675,
    "p_encoder_layer_22_attention_ln_bias": 676,
    "p_encoder_layer_22_ln_weight": 677,
    "p_encoder_layer_22_ln_bias": 678,
    "p_encoder_layer_23_attention_ln_weight": 679,
    "p_encoder_layer_23_attention_ln_bias": 680,
    "p_encoder_layer_23_ln_weight": 681,
    "p_encoder_layer_23_ln_bias": 682,
    "p_encoder_ln_weight": 683,
    "p_encoder_ln_bias": 684,
    "p_transformer_layer_0_attention_q_lin_weight": 685,
    "p_transformer_layer_0_attention_q_lin_bias": 686,
    "p_transformer_layer_0_attention_k_lin_weight": 687,
    "p_transformer_layer_0_attention_k_lin_bias": 688,
    "p_transformer_layer_0_attention_v_lin_weight": 689,
    "p_transformer_layer_0_attention_v_lin_bias": 690,
    "p_transformer_layer_0_attention_out_lin_weight": 691,
    "p_transformer_layer_0_attention_out_lin_bias": 692,
    "p_transformer_layer_0_sa_layer_norm_weight": 693,
    "p_transformer_layer_0_sa_layer_norm_bias": 694,
    "p_transformer_layer_0_ffn_lin1_weight": 695,
    "p_transformer_layer_0_ffn_lin1_bias": 696,
    "p_transformer_layer_0_ffn_lin2_weight": 697,
    "p_transformer_layer_0_ffn_lin2_bias": 698,
    "p_transformer_layer_0_output_layer_norm_weight": 699,
    "p_transformer_layer_0_output_layer_norm_bias": 700,
    "p_transformer_layer_1_attention_q_lin_weight": 701,
    "p_transformer_layer_1_attention_q_lin_bias": 702,
    "p_transformer_layer_1_attention_k_lin_weight": 703,
    "p_transformer_layer_1_attention_k_lin_bias": 704,
    "p_transformer_layer_1_attention_v_lin_weight": 705,
    "p_transformer_layer_1_attention_v_lin_bias": 706,
    "p_transformer_layer_1_attention_out_lin_weight": 707,
    "p_transformer_layer_1_attention_out_lin_bias": 708,
    "p_transformer_layer_1_sa_layer_norm_weight": 709,
    "p_transformer_layer_1_sa_layer_norm_bias": 710,
    "p_transformer_layer_1_ffn_lin1_weight": 711,
    "p_transformer_layer_1_ffn_lin1_bias": 712,
    "p_transformer_layer_1_ffn_lin2_weight": 713,
    "p_transformer_layer_1_ffn_lin2_bias": 714,
    "p_transformer_layer_1_output_layer_norm_weight": 715,
    "p_transformer_layer_1_output_layer_norm_bias": 716,
    "p_transformer_layer_2_attention_q_lin_weight": 717,
    "p_transformer_layer_2_attention_q_lin_bias": 718,
    "p_transformer_layer_2_attention_k_lin_weight": 719,
    "p_transformer_layer_2_attention_k_lin_bias": 720,
    "p_transformer_layer_2_attention_v_lin_weight": 721,
    "p_transformer_layer_2_attention_v_lin_bias": 722,
    "p_transformer_layer_2_attention_out_lin_weight": 723,
    "p_transformer_layer_2_attention_out_lin_bias": 724,
    "p_transformer_layer_2_sa_layer_norm_weight": 725,
    "p_transformer_layer_2_sa_layer_norm_bias": 726,
    "p_transformer_layer_2_ffn_lin1_weight": 727,
    "p_transformer_layer_2_ffn_lin1_bias": 728,
    "p_transformer_layer_2_ffn_lin2_weight": 729,
    "p_transformer_layer_2_ffn_lin2_bias": 730,
    "p_transformer_layer_2_output_layer_norm_weight": 731,
    "p_transformer_layer_2_output_layer_norm_bias": 732,
    "p_transformer_layer_3_attention_q_lin_weight": 733,
    "p_transformer_layer_3_attention_q_lin_bias": 734,
    "p_transformer_layer_3_attention_k_lin_weight": 735,
    "p_transformer_layer_3_attention_k_lin_bias": 736,
    "p_transformer_layer_3_attention_v_lin_weight": 737,
    "p_transformer_layer_3_attention_v_lin_bias": 738,
    "p_transformer_layer_3_attention_out_lin_weight": 739,
    "p_transformer_layer_3_attention_out_lin_bias": 740,
    "p_transformer_layer_3_sa_layer_norm_weight": 741,
    "p_transformer_layer_3_sa_layer_norm_bias": 742,
    "p_transformer_layer_3_ffn_lin1_weight": 743,
    "p_transformer_layer_3_ffn_lin1_bias": 744,
    "p_transformer_layer_3_ffn_lin2_weight": 745,
    "p_transformer_layer_3_ffn_lin2_bias": 746,
    "p_transformer_layer_3_output_layer_norm_weight": 747,
    "p_transformer_layer_3_output_layer_norm_bias": 748,
    "p_transformer_layer_4_attention_q_lin_weight": 749,
    "p_transformer_layer_4_attention_q_lin_bias": 750,
    "p_transformer_layer_4_attention_k_lin_weight": 751,
    "p_transformer_layer_4_attention_k_lin_bias": 752,
    "p_transformer_layer_4_attention_v_lin_weight": 753,
    "p_transformer_layer_4_attention_v_lin_bias": 754,
    "p_transformer_layer_4_attention_out_lin_weight": 755,
    "p_transformer_layer_4_attention_out_lin_bias": 756,
    "p_transformer_layer_4_sa_layer_norm_weight": 757,
    "p_transformer_layer_4_sa_layer_norm_bias": 758,
    "p_transformer_layer_4_ffn_lin1_weight": 759,
    "p_transformer_layer_4_ffn_lin1_bias": 760,
    "p_transformer_layer_4_ffn_lin2_weight": 761,
    "p_transformer_layer_4_ffn_lin2_bias": 762,
    "p_transformer_layer_4_output_layer_norm_weight": 763,
    "p_transformer_layer_4_output_layer_norm_bias": 764,
    "p_transformer_layer_5_attention_q_lin_weight": 765,
    "p_transformer_layer_5_attention_q_lin_bias": 766,
    "p_transformer_layer_5_attention_k_lin_weight": 767,
    "p_transformer_layer_5_attention_k_lin_bias": 768,
    "p_transformer_layer_5_attention_v_lin_weight": 769,
    "p_transformer_layer_5_attention_v_lin_bias": 770,
    "p_transformer_layer_5_attention_out_lin_weight": 771,
    "p_transformer_layer_5_attention_out_lin_bias": 772,
    "p_transformer_layer_5_sa_layer_norm_weight": 773,
    "p_transformer_layer_5_sa_layer_norm_bias": 774,
    "p_transformer_layer_5_ffn_lin1_weight": 775,
    "p_transformer_layer_5_ffn_lin1_bias": 776,
    "p_transformer_layer_5_ffn_lin2_weight": 777,
    "p_transformer_layer_5_ffn_lin2_bias": 778,
    "p_transformer_layer_5_output_layer_norm_weight": 779,
    "p_transformer_layer_5_output_layer_norm_bias": 780,
    "p_dense_bias": 781,
    "p_out_proj_weight": 782,
    "p_out_proj_bias": 783,
    "features": 784,
    "p_h_0_ln_1_weight": 785,
    "p_h_0_ln_1_bias": 786,
    "p_h_0_attn_attention_q_proj_weight": 787,
    "p_h_0_attn_attention_k_proj_weight": 788,
    "p_h_0_attn_attention_v_proj_weight": 789,
    "p_h_0_attn_attention_out_proj_weight": 790,
    "p_h_0_attn_attention_out_proj_bias": 791,
    "p_h_0_ln_2_weight": 792,
    "p_h_0_ln_2_bias": 793,
    "p_h_0_mlp_c_fc_weight": 794,
    "p_h_0_mlp_c_fc_bias": 795,
    "p_h_0_mlp_c_proj_weight": 796,
    "p_h_0_mlp_c_proj_bias": 797,
    "p_h_1_ln_1_weight": 798,
    "p_h_1_ln_1_bias": 799,
    "p_h_1_attn_attention_q_proj_weight": 800,
    "p_h_1_attn_attention_k_proj_weight": 801,
    "p_h_1_attn_attention_v_proj_weight": 802,
    "p_h_1_attn_attention_out_proj_weight": 803,
    "p_h_1_attn_attention_out_proj_bias": 804,
    "p_h_1_ln_2_weight": 805,
    "p_h_1_ln_2_bias": 806,
    "p_h_1_mlp_c_fc_weight": 807,
    "p_h_1_mlp_c_fc_bias": 808,
    "p_h_1_mlp_c_proj_weight": 809,
    "p_h_1_mlp_c_proj_bias": 810,
    "p_h_2_ln_1_weight": 811,
    "p_h_2_ln_1_bias": 812,
    "p_h_2_attn_attention_q_proj_weight": 813,
    "p_h_2_attn_attention_k_proj_weight": 814,
    "p_h_2_attn_attention_v_proj_weight": 815,
    "p_h_2_attn_attention_out_proj_weight": 816,
    "p_h_2_attn_attention_out_proj_bias": 817,
    "p_h_2_ln_2_weight": 818,
    "p_h_2_ln_2_bias": 819,
    "p_h_2_mlp_c_fc_weight": 820,
    "p_h_2_mlp_c_fc_bias": 821,
    "p_h_2_mlp_c_proj_weight": 822,
    "p_h_2_mlp_c_proj_bias": 823,
    "p_h_3_ln_1_weight": 824,
    "p_h_3_ln_1_bias": 825,
    "p_h_3_attn_attention_q_proj_weight": 826,
    "p_h_3_attn_attention_k_proj_weight": 827,
    "p_h_3_attn_attention_v_proj_weight": 828,
    "p_h_3_attn_attention_out_proj_weight": 829,
    "p_h_3_attn_attention_out_proj_bias": 830,
    "p_h_3_ln_2_weight": 831,
    "p_h_3_ln_2_bias": 832,
    "p_h_3_mlp_c_fc_weight": 833,
    "p_h_3_mlp_c_fc_bias": 834,
    "p_h_3_mlp_c_proj_weight": 835,
    "p_h_3_mlp_c_proj_bias": 836,
    "p_h_4_ln_1_weight": 837,
    "p_h_4_ln_1_bias": 838,
    "p_h_4_attn_attention_q_proj_weight": 839,
    "p_h_4_attn_attention_k_proj_weight": 840,
    "p_h_4_attn_attention_v_proj_weight": 841,
    "p_h_4_attn_attention_out_proj_weight": 842,
    "p_h_4_attn_attention_out_proj_bias": 843,
    "p_h_4_ln_2_weight": 844,
    "p_h_4_ln_2_bias": 845,
    "p_h_4_mlp_c_fc_weight": 846,
    "p_h_4_mlp_c_fc_bias": 847,
    "p_h_4_mlp_c_proj_weight": 848,
    "p_h_4_mlp_c_proj_bias": 849,
    "p_h_5_ln_1_weight": 850,
    "p_h_5_ln_1_bias": 851,
    "p_h_5_attn_attention_q_proj_weight": 852,
    "p_h_5_attn_attention_k_proj_weight": 853,
    "p_h_5_attn_attention_v_proj_weight": 854,
    "p_h_5_attn_attention_out_proj_weight": 855,
    "p_h_5_attn_attention_out_proj_bias": 856,
    "p_h_5_ln_2_weight": 857,
    "p_h_5_ln_2_bias": 858,
    "p_h_5_mlp_c_fc_weight": 859,
    "p_h_5_mlp_c_fc_bias": 860,
    "p_h_5_mlp_c_proj_weight": 861,
    "p_h_5_mlp_c_proj_bias": 862,
    "p_h_6_ln_1_weight": 863,
    "p_h_6_ln_1_bias": 864,
    "p_h_6_attn_attention_q_proj_weight": 865,
    "p_h_6_attn_attention_k_proj_weight": 866,
    "p_h_6_attn_attention_v_proj_weight": 867,
    "p_h_6_attn_attention_out_proj_weight": 868,
    "p_h_6_attn_attention_out_proj_bias": 869,
    "p_h_6_ln_2_weight": 870,
    "p_h_6_ln_2_bias": 871,
    "p_h_6_mlp_c_fc_weight": 872,
    "p_h_6_mlp_c_fc_bias": 873,
    "p_h_6_mlp_c_proj_weight": 874,
    "p_h_6_mlp_c_proj_bias": 875,
    "p_h_7_ln_1_weight": 876,
    "p_h_7_ln_1_bias": 877,
    "p_h_7_attn_attention_q_proj_weight": 878,
    "p_h_7_attn_attention_k_proj_weight": 879,
    "p_h_7_attn_attention_v_proj_weight": 880,
    "p_h_7_attn_attention_out_proj_weight": 881,
    "p_h_7_attn_attention_out_proj_bias": 882,
    "p_h_7_ln_2_weight": 883,
    "p_h_7_ln_2_bias": 884,
    "p_h_7_mlp_c_fc_weight": 885,
    "p_h_7_mlp_c_fc_bias": 886,
    "p_h_7_mlp_c_proj_weight": 887,
    "p_h_7_mlp_c_proj_bias": 888,
    "p_h_8_ln_1_weight": 889,
    "p_h_8_ln_1_bias": 890,
    "p_h_8_attn_attention_q_proj_weight": 891,
    "p_h_8_attn_attention_k_proj_weight": 892,
    "p_h_8_attn_attention_v_proj_weight": 893,
    "p_h_8_attn_attention_out_proj_weight": 894,
    "p_h_8_attn_attention_out_proj_bias": 895,
    "p_h_8_ln_2_weight": 896,
    "p_h_8_ln_2_bias": 897,
    "p_h_8_mlp_c_fc_weight": 898,
    "p_h_8_mlp_c_fc_bias": 899,
    "p_h_8_mlp_c_proj_weight": 900,
    "p_h_8_mlp_c_proj_bias": 901,
    "p_h_9_ln_1_weight": 902,
    "p_h_9_ln_1_bias": 903,
    "p_h_9_attn_attention_q_proj_weight": 904,
    "p_h_9_attn_attention_k_proj_weight": 905,
    "p_h_9_attn_attention_v_proj_weight": 906,
    "p_h_9_attn_attention_out_proj_weight": 907,
    "p_h_9_attn_attention_out_proj_bias": 908,
    "p_h_9_ln_2_weight": 909,
    "p_h_9_ln_2_bias": 910,
    "p_h_9_mlp_c_fc_weight": 911,
    "p_h_9_mlp_c_fc_bias": 912,
    "p_h_9_mlp_c_proj_weight": 913,
    "p_h_9_mlp_c_proj_bias": 914,
    "p_h_10_ln_1_weight": 915,
    "p_h_10_ln_1_bias": 916,
    "p_h_10_attn_attention_q_proj_weight": 917,
    "p_h_10_attn_attention_k_proj_weight": 918,
    "p_h_10_attn_attention_v_proj_weight": 919,
    "p_h_10_attn_attention_out_proj_weight": 920,
    "p_h_10_attn_attention_out_proj_bias": 921,
    "p_h_10_ln_2_weight": 922,
    "p_h_10_ln_2_bias": 923,
    "p_h_10_mlp_c_fc_weight": 924,
    "p_h_10_mlp_c_fc_bias": 925,
    "p_h_10_mlp_c_proj_weight": 926,
    "p_h_10_mlp_c_proj_bias": 927,
    "p_h_11_ln_1_weight": 928,
    "p_h_11_ln_1_bias": 929,
    "p_h_11_attn_attention_q_proj_weight": 930,
    "p_h_11_attn_attention_k_proj_weight": 931,
    "p_h_11_attn_attention_v_proj_weight": 932,
    "p_h_11_attn_attention_out_proj_weight": 933,
    "p_h_11_attn_attention_out_proj_bias": 934,
    "p_h_11_ln_2_weight": 935,
    "p_h_11_ln_2_bias": 936,
    "p_h_11_mlp_c_fc_weight": 937,
    "p_h_11_mlp_c_fc_bias": 938,
    "p_h_11_mlp_c_proj_weight": 939,
    "p_h_11_mlp_c_proj_bias": 940,
    "p_ln_f_weight": 941,
    "p_ln_f_bias": 942,
    "b_h_0_attn_attention_bias": 943,
    "b_h_1_attn_attention_bias": 944,
    "b_h_2_attn_attention_bias": 945,
    "b_h_3_attn_attention_bias": 946,
    "b_h_4_attn_attention_bias": 947,
    "b_h_5_attn_attention_bias": 948,
    "b_h_6_attn_attention_bias": 949,
    "b_h_7_attn_attention_bias": 950,
    "b_h_8_attn_attention_bias": 951,
    "b_h_9_attn_attention_bias": 952,
    "b_h_10_attn_attention_bias": 953,
    "b_h_11_attn_attention_bias": 954,
    "c_h_0_attn_attention_lifted_tensor_0": 955,
    "c_h_1_attn_attention_lifted_tensor_1": 956,
    "c_h_2_attn_attention_lifted_tensor_2": 957,
    "c_h_3_attn_attention_lifted_tensor_3": 958,
    "c_h_4_attn_attention_lifted_tensor_4": 959,
    "c_h_5_attn_attention_lifted_tensor_5": 960,
    "c_h_6_attn_attention_lifted_tensor_6": 961,
    "c_h_7_attn_attention_lifted_tensor_7": 962,
    "c_h_8_attn_attention_lifted_tensor_8": 963,
    "c_h_9_attn_attention_lifted_tensor_9": 964,
    "c_h_10_attn_attention_lifted_tensor_10": 965,
    "c_h_11_attn_attention_lifted_tensor_11": 966,
    "p_encoder_layer_12_attention_output_layernorm_weight": 967,
    "p_encoder_layer_12_attention_output_layernorm_bias": 968,
    "p_encoder_layer_12_output_layernorm_weight": 969,
    "p_encoder_layer_12_output_layernorm_bias": 970,
    "p_encoder_layer_13_attention_output_layernorm_weight": 971,
    "p_encoder_layer_13_attention_output_layernorm_bias": 972,
    "p_encoder_layer_13_output_layernorm_weight": 973,
    "p_encoder_layer_13_output_layernorm_bias": 974,
    "p_encoder_layer_14_attention_output_layernorm_weight": 975,
    "p_encoder_layer_14_attention_output_layernorm_bias": 976,
    "p_encoder_layer_14_output_layernorm_weight": 977,
    "p_encoder_layer_14_output_layernorm_bias": 978,
    "p_encoder_layer_15_attention_output_layernorm_weight": 979,
    "p_encoder_layer_15_attention_output_layernorm_bias": 980,
    "p_encoder_layer_15_output_layernorm_weight": 981,
    "p_encoder_layer_15_output_layernorm_bias": 982,
    "p_encoder_layer_16_attention_output_layernorm_weight": 983,
    "p_encoder_layer_16_attention_output_layernorm_bias": 984,
    "p_encoder_layer_16_output_layernorm_weight": 985,
    "p_encoder_layer_16_output_layernorm_bias": 986,
    "p_encoder_layer_17_attention_output_layernorm_weight": 987,
    "p_encoder_layer_17_attention_output_layernorm_bias": 988,
    "p_encoder_layer_17_output_layernorm_weight": 989,
    "p_encoder_layer_17_output_layernorm_bias": 990,
    "p_encoder_layer_18_attention_output_layernorm_weight": 991,
    "p_encoder_layer_18_attention_output_layernorm_bias": 992,
    "p_encoder_layer_18_output_layernorm_weight": 993,
    "p_encoder_layer_18_output_layernorm_bias": 994,
    "p_encoder_layer_19_attention_output_layernorm_weight": 995,
    "p_encoder_layer_19_attention_output_layernorm_bias": 996,
    "p_encoder_layer_19_output_layernorm_weight": 997,
    "p_encoder_layer_19_output_layernorm_bias": 998,
    "p_encoder_layer_20_attention_output_layernorm_weight": 999,
    "p_encoder_layer_20_attention_output_layernorm_bias": 1000,
    "p_encoder_layer_20_output_layernorm_weight": 1001,
    "p_encoder_layer_20_output_layernorm_bias": 1002,
    "p_encoder_layer_21_attention_output_layernorm_weight": 1003,
    "p_encoder_layer_21_attention_output_layernorm_bias": 1004,
    "p_encoder_layer_21_output_layernorm_weight": 1005,
    "p_encoder_layer_21_output_layernorm_bias": 1006,
    "p_encoder_layer_22_attention_output_layernorm_weight": 1007,
    "p_encoder_layer_22_attention_output_layernorm_bias": 1008,
    "p_encoder_layer_22_output_layernorm_weight": 1009,
    "p_encoder_layer_22_output_layernorm_bias": 1010,
    "p_encoder_layer_23_attention_output_layernorm_weight": 1011,
    "p_encoder_layer_23_attention_output_layernorm_bias": 1012,
    "p_encoder_layer_23_output_layernorm_weight": 1013,
    "p_encoder_layer_23_output_layernorm_bias": 1014,
    "p_encoder_layer_24_attention_output_layernorm_weight": 1015,
    "p_encoder_layer_24_attention_output_layernorm_bias": 1016,
    "p_encoder_layer_24_output_layernorm_weight": 1017,
    "p_encoder_layer_24_output_layernorm_bias": 1018,
    "p_encoder_layer_25_attention_output_layernorm_weight": 1019,
    "p_encoder_layer_25_attention_output_layernorm_bias": 1020,
    "p_encoder_layer_25_output_layernorm_weight": 1021,
    "p_encoder_layer_25_output_layernorm_bias": 1022,
    "p_encoder_layer_26_attention_output_layernorm_weight": 1023,
    "p_encoder_layer_26_attention_output_layernorm_bias": 1024,
    "p_encoder_layer_26_output_layernorm_weight": 1025,
    "p_encoder_layer_26_output_layernorm_bias": 1026,
    "p_encoder_layer_27_attention_output_layernorm_weight": 1027,
    "p_encoder_layer_27_attention_output_layernorm_bias": 1028,
    "p_encoder_layer_27_output_layernorm_weight": 1029,
    "p_encoder_layer_27_output_layernorm_bias": 1030,
    "p_encoder_layer_28_attention_output_layernorm_weight": 1031,
    "p_encoder_layer_28_attention_output_layernorm_bias": 1032,
    "p_encoder_layer_28_output_layernorm_weight": 1033,
    "p_encoder_layer_28_output_layernorm_bias": 1034,
    "p_encoder_layer_29_attention_output_layernorm_weight": 1035,
    "p_encoder_layer_29_attention_output_layernorm_bias": 1036,
    "p_encoder_layer_29_output_layernorm_weight": 1037,
    "p_encoder_layer_29_output_layernorm_bias": 1038
  },
  "index_to_param_name": {
    "10": "p_embeddings_position_embeddings_weight",
    "11": "p_embeddings_layernorm_weight",
    "12": "p_embeddings_layernorm_bias",
    "13": "p_encoder_layer_0_attention_self_query_weight",
    "14": "p_encoder_layer_0_attention_self_query_bias",
    "15": "p_encoder_layer_0_attention_self_key_weight",
    "16": "p_encoder_layer_0_attention_self_key_bias",
    "17": "p_encoder_layer_0_attention_self_value_weight",
    "18": "p_encoder_layer_0_attention_self_value_bias",
    "19": "p_encoder_layer_0_attention_output_dense_weight",
    "20": "p_encoder_layer_0_attention_output_dense_bias",
    "21": "p_encoder_layer_0_attention_output_layernorm_weight",
    "22": "p_encoder_layer_0_attention_output_layernorm_bias",
    "23": "p_encoder_layer_0_intermediate_dense_weight",
    "24": "p_encoder_layer_0_intermediate_dense_bias",
    "25": "p_encoder_layer_0_output_dense_weight",
    "26": "p_encoder_layer_0_output_dense_bias",
    "27": "p_encoder_layer_0_output_layernorm_weight",
    "28": "p_encoder_layer_0_output_layernorm_bias",
    "29": "p_encoder_layer_1_attention_self_query_weight",
    "30": "p_encoder_layer_1_attention_self_query_bias",
    "31": "p_encoder_layer_1_attention_self_key_weight",
    "32": "p_encoder_layer_1_attention_self_key_bias",
    "33": "p_encoder_layer_1_attention_self_value_weight",
    "34": "p_encoder_layer_1_attention_self_value_bias",
    "35": "p_encoder_layer_1_attention_output_dense_weight",
    "36": "p_encoder_layer_1_attention_output_dense_bias",
    "37": "p_encoder_layer_1_attention_output_layernorm_weight",
    "38": "p_encoder_layer_1_attention_output_layernorm_bias",
    "39": "p_encoder_layer_1_intermediate_dense_weight",
    "40": "p_encoder_layer_1_intermediate_dense_bias",
    "41": "p_encoder_layer_1_output_dense_weight",
    "42": "p_encoder_layer_1_output_dense_bias",
    "43": "p_encoder_layer_1_output_layernorm_weight",
    "44": "p_encoder_layer_1_output_layernorm_bias",
    "45": "p_encoder_layer_2_attention_self_query_weight",
    "46": "p_encoder_layer_2_attention_self_query_bias",
    "47": "p_encoder_layer_2_attention_self_key_weight",
    "48": "p_encoder_layer_2_attention_self_key_bias",
    "49": "p_encoder_layer_2_attention_self_value_weight",
    "50": "p_encoder_layer_2_attention_self_value_bias",
    "51": "p_encoder_layer_2_attention_output_dense_weight",
    "52": "p_encoder_layer_2_attention_output_dense_bias",
    "53": "p_encoder_layer_2_attention_output_layernorm_weight",
    "54": "p_encoder_layer_2_attention_output_layernorm_bias",
    "55": "p_encoder_layer_2_intermediate_dense_weight",
    "56": "p_encoder_layer_2_intermediate_dense_bias",
    "57": "p_encoder_layer_2_output_dense_weight",
    "58": "p_encoder_layer_2_output_dense_bias",
    "59": "p_encoder_layer_2_output_layernorm_weight",
    "60": "p_encoder_layer_2_output_layernorm_bias",
    "61": "p_encoder_layer_3_attention_self_query_weight",
    "62": "p_encoder_layer_3_attention_self_query_bias",
    "63": "p_encoder_layer_3_attention_self_key_weight",
    "64": "p_encoder_layer_3_attention_self_key_bias",
    "65": "p_encoder_layer_3_attention_self_value_weight",
    "66": "p_encoder_layer_3_attention_self_value_bias",
    "67": "p_encoder_layer_3_attention_output_dense_weight",
    "68": "p_encoder_layer_3_attention_output_dense_bias",
    "69": "p_encoder_layer_3_attention_output_layernorm_weight",
    "70": "p_encoder_layer_3_attention_output_layernorm_bias",
    "71": "p_encoder_layer_3_intermediate_dense_weight",
    "72": "p_encoder_layer_3_intermediate_dense_bias",
    "73": "p_encoder_layer_3_output_dense_weight",
    "74": "p_encoder_layer_3_output_dense_bias",
    "75": "p_encoder_layer_3_output_layernorm_weight",
    "76": "p_encoder_layer_3_output_layernorm_bias",
    "77": "p_encoder_layer_4_attention_self_query_weight",
    "78": "p_encoder_layer_4_attention_self_query_bias",
    "79": "p_encoder_layer_4_attention_self_key_weight",
    "80": "p_encoder_layer_4_attention_self_key_bias",
    "81": "p_encoder_layer_4_attention_self_value_weight",
    "82": "p_encoder_layer_4_attention_self_value_bias",
    "83": "p_encoder_layer_4_attention_output_dense_weight",
    "84": "p_encoder_layer_4_attention_output_dense_bias",
    "85": "p_encoder_layer_4_attention_output_layernorm_weight",
    "86": "p_encoder_layer_4_attention_output_layernorm_bias",
    "87": "p_encoder_layer_4_intermediate_dense_weight",
    "88": "p_encoder_layer_4_intermediate_dense_bias",
    "89": "p_encoder_layer_4_output_dense_weight",
    "90": "p_encoder_layer_4_output_dense_bias",
    "91": "p_encoder_layer_4_output_layernorm_weight",
    "92": "p_encoder_layer_4_output_layernorm_bias",
    "93": "p_encoder_layer_5_attention_self_query_weight",
    "94": "p_encoder_layer_5_attention_self_query_bias",
    "95": "p_encoder_layer_5_attention_self_key_weight",
    "96": "p_encoder_layer_5_attention_self_key_bias",
    "97": "p_encoder_layer_5_attention_self_value_weight",
    "98": "p_encoder_layer_5_attention_self_value_bias",
    "99": "p_encoder_layer_5_attention_output_dense_weight",
    "100": "p_encoder_layer_5_attention_output_dense_bias",
    "101": "p_encoder_layer_5_attention_output_layernorm_weight",
    "102": "p_encoder_layer_5_attention_output_layernorm_bias",
    "103": "p_encoder_layer_5_intermediate_dense_weight",
    "104": "p_encoder_layer_5_intermediate_dense_bias",
    "105": "p_encoder_layer_5_output_dense_weight",
    "106": "p_encoder_layer_5_output_dense_bias",
    "107": "p_encoder_layer_5_output_layernorm_weight",
    "108": "p_encoder_layer_5_output_layernorm_bias",
    "109": "p_encoder_layer_6_attention_self_query_weight",
    "110": "p_encoder_layer_6_attention_self_query_bias",
    "111": "p_encoder_layer_6_attention_self_key_weight",
    "112": "p_encoder_layer_6_attention_self_key_bias",
    "113": "p_encoder_layer_6_attention_self_value_weight",
    "114": "p_encoder_layer_6_attention_self_value_bias",
    "115": "p_encoder_layer_6_attention_output_dense_weight",
    "116": "p_encoder_layer_6_attention_output_dense_bias",
    "117": "p_encoder_layer_6_attention_output_layernorm_weight",
    "118": "p_encoder_layer_6_attention_output_layernorm_bias",
    "119": "p_encoder_layer_6_intermediate_dense_weight",
    "120": "p_encoder_layer_6_intermediate_dense_bias",
    "121": "p_encoder_layer_6_output_dense_weight",
    "122": "p_encoder_layer_6_output_dense_bias",
    "123": "p_encoder_layer_6_output_layernorm_weight",
    "124": "p_encoder_layer_6_output_layernorm_bias",
    "125": "p_encoder_layer_7_attention_self_query_weight",
    "126": "p_encoder_layer_7_attention_self_query_bias",
    "127": "p_encoder_layer_7_attention_self_key_weight",
    "128": "p_encoder_layer_7_attention_self_key_bias",
    "129": "p_encoder_layer_7_attention_self_value_weight",
    "130": "p_encoder_layer_7_attention_self_value_bias",
    "131": "p_encoder_layer_7_attention_output_dense_weight",
    "132": "p_encoder_layer_7_attention_output_dense_bias",
    "133": "p_encoder_layer_7_attention_output_layernorm_weight",
    "134": "p_encoder_layer_7_attention_output_layernorm_bias",
    "135": "p_encoder_layer_7_intermediate_dense_weight",
    "136": "p_encoder_layer_7_intermediate_dense_bias",
    "137": "p_encoder_layer_7_output_dense_weight",
    "138": "p_encoder_layer_7_output_dense_bias",
    "139": "p_encoder_layer_7_output_layernorm_weight",
    "140": "p_encoder_layer_7_output_layernorm_bias",
    "141": "p_encoder_layer_8_attention_self_query_weight",
    "142": "p_encoder_layer_8_attention_self_query_bias",
    "143": "p_encoder_layer_8_attention_self_key_weight",
    "144": "p_encoder_layer_8_attention_self_key_bias",
    "145": "p_encoder_layer_8_attention_self_value_weight",
    "146": "p_encoder_layer_8_attention_self_value_bias",
    "147": "p_encoder_layer_8_attention_output_dense_weight",
    "148": "p_encoder_layer_8_attention_output_dense_bias",
    "149": "p_encoder_layer_8_attention_output_layernorm_weight",
    "150": "p_encoder_layer_8_attention_output_layernorm_bias",
    "151": "p_encoder_layer_8_intermediate_dense_weight",
    "152": "p_encoder_layer_8_intermediate_dense_bias",
    "153": "p_encoder_layer_8_output_dense_weight",
    "154": "p_encoder_layer_8_output_dense_bias",
    "155": "p_encoder_layer_8_output_layernorm_weight",
    "156": "p_encoder_layer_8_output_layernorm_bias",
    "157": "p_encoder_layer_9_attention_self_query_weight",
    "158": "p_encoder_layer_9_attention_self_query_bias",
    "159": "p_encoder_layer_9_attention_self_key_weight",
    "160": "p_encoder_layer_9_attention_self_key_bias",
    "161": "p_encoder_layer_9_attention_self_value_weight",
    "162": "p_encoder_layer_9_attention_self_value_bias",
    "163": "p_encoder_layer_9_attention_output_dense_weight",
    "164": "p_encoder_layer_9_attention_output_dense_bias",
    "165": "p_encoder_layer_9_attention_output_layernorm_weight",
    "166": "p_encoder_layer_9_attention_output_layernorm_bias",
    "167": "p_encoder_layer_9_intermediate_dense_weight",
    "168": "p_encoder_layer_9_intermediate_dense_bias",
    "169": "p_encoder_layer_9_output_dense_weight",
    "170": "p_encoder_layer_9_output_dense_bias",
    "171": "p_encoder_layer_9_output_layernorm_weight",
    "172": "p_encoder_layer_9_output_layernorm_bias",
    "173": "p_encoder_layer_10_attention_self_query_weight",
    "174": "p_encoder_layer_10_attention_self_query_bias",
    "175": "p_encoder_layer_10_attention_self_key_weight",
    "176": "p_encoder_layer_10_attention_self_key_bias",
    "177": "p_encoder_layer_10_attention_self_value_weight",
    "178": "p_encoder_layer_10_attention_self_value_bias",
    "179": "p_encoder_layer_10_attention_output_dense_weight",
    "180": "p_encoder_layer_10_attention_output_dense_bias",
    "181": "p_encoder_layer_10_attention_output_layernorm_weight",
    "182": "p_encoder_layer_10_attention_output_layernorm_bias",
    "183": "p_encoder_layer_10_intermediate_dense_weight",
    "184": "p_encoder_layer_10_intermediate_dense_bias",
    "185": "p_encoder_layer_10_output_dense_weight",
    "186": "p_encoder_layer_10_output_dense_bias",
    "187": "p_encoder_layer_10_output_layernorm_weight",
    "188": "p_encoder_layer_10_output_layernorm_bias",
    "189": "p_encoder_layer_11_attention_self_query_weight",
    "190": "p_encoder_layer_11_attention_self_query_bias",
    "191": "p_encoder_layer_11_attention_self_key_weight",
    "192": "p_encoder_layer_11_attention_self_key_bias",
    "193": "p_encoder_layer_11_attention_self_value_weight",
    "194": "p_encoder_layer_11_attention_self_value_bias",
    "195": "p_encoder_layer_11_attention_output_dense_weight",
    "196": "p_encoder_layer_11_attention_output_dense_bias",
    "197": "p_encoder_layer_11_attention_output_layernorm_weight",
    "198": "p_encoder_layer_11_attention_output_layernorm_bias",
    "199": "p_encoder_layer_11_intermediate_dense_weight",
    "200": "p_encoder_layer_11_intermediate_dense_bias",
    "201": "p_encoder_layer_11_output_dense_weight",
    "202": "p_encoder_layer_11_output_dense_bias",
    "203": "p_encoder_layer_11_output_layernorm_weight",
    "204": "p_encoder_layer_11_output_layernorm_bias",
    "205": "p_pooler_dense_weight",
    "206": "p_pooler_dense_bias",
    "207": "b_embeddings_token_type_ids",
    "208": "b_embeddings_position_ids",
    "209": "use_cache",
    "210": "c_lifted_tensor_0",
    "211": "input_ids",
    "212": "p_fn_bias",
    "213": "input",
    "214": "p_predictions_transform_dense_bias",
    "215": "p_predictions_transform_layernorm_weight",
    "216": "p_predictions_transform_layernorm_bias",
    "217": "p_predictions_decoder_weight",
    "218": "p_predictions_decoder_bias",
    "219": "sequence_output",
    "220": "p_encoder_layer_0_attention_layernorm_bias",
    "221": "p_encoder_layer_0_layernorm_weight",
    "222": "p_encoder_layer_0_layernorm_bias",
    "223": "p_encoder_layer_1_attention_layernorm_weight",
    "224": "p_encoder_layer_1_attention_layernorm_bias",
    "225": "p_encoder_layer_1_layernorm_weight",
    "226": "p_encoder_layer_1_layernorm_bias",
    "227": "p_encoder_layer_2_attention_layernorm_weight",
    "228": "p_encoder_layer_2_attention_layernorm_bias",
    "229": "p_encoder_layer_2_layernorm_weight",
    "230": "p_encoder_layer_2_layernorm_bias",
    "231": "p_encoder_layer_3_attention_layernorm_weight",
    "232": "p_encoder_layer_3_attention_layernorm_bias",
    "233": "p_encoder_layer_3_layernorm_weight",
    "234": "p_encoder_layer_3_layernorm_bias",
    "235": "p_encoder_layer_4_attention_layernorm_weight",
    "236": "p_encoder_layer_4_attention_layernorm_bias",
    "237": "p_encoder_layer_4_layernorm_weight",
    "238": "p_encoder_layer_4_layernorm_bias",
    "239": "p_encoder_layer_5_attention_layernorm_weight",
    "240": "p_encoder_layer_5_attention_layernorm_bias",
    "241": "p_encoder_layer_5_layernorm_weight",
    "242": "p_encoder_layer_5_layernorm_bias",
    "243": "p_encoder_layer_6_attention_layernorm_weight",
    "244": "p_encoder_layer_6_attention_layernorm_bias",
    "245": "p_encoder_layer_6_layernorm_weight",
    "246": "p_encoder_layer_6_layernorm_bias",
    "247": "p_encoder_layer_7_attention_layernorm_weight",
    "248": "p_encoder_layer_7_attention_layernorm_bias",
    "249": "p_encoder_layer_7_layernorm_weight",
    "250": "p_encoder_layer_7_layernorm_bias",
    "251": "p_encoder_layer_8_attention_layernorm_weight",
    "252": "p_encoder_layer_8_attention_layernorm_bias",
    "253": "p_encoder_layer_8_layernorm_weight",
    "254": "p_encoder_layer_8_layernorm_bias",
    "255": "p_encoder_layer_9_attention_layernorm_weight",
    "256": "p_encoder_layer_9_attention_layernorm_bias",
    "257": "p_encoder_layer_9_layernorm_weight",
    "258": "p_encoder_layer_9_layernorm_bias",
    "259": "p_encoder_layer_10_attention_layernorm_weight",
    "260": "p_encoder_layer_10_attention_layernorm_bias",
    "261": "p_encoder_layer_10_layernorm_weight",
    "262": "p_encoder_layer_10_layernorm_bias",
    "263": "p_encoder_layer_11_attention_layernorm_weight",
    "264": "p_encoder_layer_11_attention_layernorm_bias",
    "265": "p_encoder_layer_11_layernorm_weight",
    "266": "p_encoder_layer_11_layernorm_bias",
    "267": "p_encoder_layer_12_attention_layernorm_weight",
    "268": "p_encoder_layer_12_attention_layernorm_bias",
    "269": "p_encoder_layer_12_attention_self_query_weight",
    "270": "p_encoder_layer_12_attention_self_query_bias",
    "271": "p_encoder_layer_12_attention_self_key_weight",
    "272": "p_encoder_layer_12_attention_self_key_bias",
    "273": "p_encoder_layer_12_attention_self_value_weight",
    "274": "p_encoder_layer_12_attention_self_value_bias",
    "275": "p_encoder_layer_12_attention_output_dense_weight",
    "276": "p_encoder_layer_12_attention_output_dense_bias",
    "277": "p_encoder_layer_12_layernorm_weight",
    "278": "p_encoder_layer_12_layernorm_bias",
    "279": "p_encoder_layer_12_intermediate_dense_weight",
    "280": "p_encoder_layer_12_intermediate_dense_bias",
    "281": "p_encoder_layer_12_output_dense_weight",
    "282": "p_encoder_layer_12_output_dense_bias",
    "283": "p_encoder_layer_13_attention_layernorm_weight",
    "284": "p_encoder_layer_13_attention_layernorm_bias",
    "285": "p_encoder_layer_13_attention_self_query_weight",
    "286": "p_encoder_layer_13_attention_self_query_bias",
    "287": "p_encoder_layer_13_attention_self_key_weight",
    "288": "p_encoder_layer_13_attention_self_key_bias",
    "289": "p_encoder_layer_13_attention_self_value_weight",
    "290": "p_encoder_layer_13_attention_self_value_bias",
    "291": "p_encoder_layer_13_attention_output_dense_weight",
    "292": "p_encoder_layer_13_attention_output_dense_bias",
    "293": "p_encoder_layer_13_layernorm_weight",
    "294": "p_encoder_layer_13_layernorm_bias",
    "295": "p_encoder_layer_13_intermediate_dense_weight",
    "296": "p_encoder_layer_13_intermediate_dense_bias",
    "297": "p_encoder_layer_13_output_dense_weight",
    "298": "p_encoder_layer_13_output_dense_bias",
    "299": "p_encoder_layer_14_attention_layernorm_weight",
    "300": "p_encoder_layer_14_attention_layernorm_bias",
    "301": "p_encoder_layer_14_attention_self_query_weight",
    "302": "p_encoder_layer_14_attention_self_query_bias",
    "303": "p_encoder_layer_14_attention_self_key_weight",
    "304": "p_encoder_layer_14_attention_self_key_bias",
    "305": "p_encoder_layer_14_attention_self_value_weight",
    "306": "p_encoder_layer_14_attention_self_value_bias",
    "307": "p_encoder_layer_14_attention_output_dense_weight",
    "308": "p_encoder_layer_14_attention_output_dense_bias",
    "309": "p_encoder_layer_14_layernorm_weight",
    "310": "p_encoder_layer_14_layernorm_bias",
    "311": "p_encoder_layer_14_intermediate_dense_weight",
    "312": "p_encoder_layer_14_intermediate_dense_bias",
    "313": "p_encoder_layer_14_output_dense_weight",
    "314": "p_encoder_layer_14_output_dense_bias",
    "315": "p_encoder_layer_15_attention_layernorm_weight",
    "316": "p_encoder_layer_15_attention_layernorm_bias",
    "317": "p_encoder_layer_15_attention_self_query_weight",
    "318": "p_encoder_layer_15_attention_self_query_bias",
    "319": "p_encoder_layer_15_attention_self_key_weight",
    "320": "p_encoder_layer_15_attention_self_key_bias",
    "321": "p_encoder_layer_15_attention_self_value_weight",
    "322": "p_encoder_layer_15_attention_self_value_bias",
    "323": "p_encoder_layer_15_attention_output_dense_weight",
    "324": "p_encoder_layer_15_attention_output_dense_bias",
    "325": "p_encoder_layer_15_layernorm_weight",
    "326": "p_encoder_layer_15_layernorm_bias",
    "327": "p_encoder_layer_15_intermediate_dense_weight",
    "328": "p_encoder_layer_15_intermediate_dense_bias",
    "329": "p_encoder_layer_15_output_dense_weight",
    "330": "p_encoder_layer_15_output_dense_bias",
    "331": "p_encoder_layer_16_attention_layernorm_weight",
    "332": "p_encoder_layer_16_attention_layernorm_bias",
    "333": "p_encoder_layer_16_attention_self_query_weight",
    "334": "p_encoder_layer_16_attention_self_query_bias",
    "335": "p_encoder_layer_16_attention_self_key_weight",
    "336": "p_encoder_layer_16_attention_self_key_bias",
    "337": "p_encoder_layer_16_attention_self_value_weight",
    "338": "p_encoder_layer_16_attention_self_value_bias",
    "339": "p_encoder_layer_16_attention_output_dense_weight",
    "340": "p_encoder_layer_16_attention_output_dense_bias",
    "341": "p_encoder_layer_16_layernorm_weight",
    "342": "p_encoder_layer_16_layernorm_bias",
    "343": "p_encoder_layer_16_intermediate_dense_weight",
    "344": "p_encoder_layer_16_intermediate_dense_bias",
    "345": "p_encoder_layer_16_output_dense_weight",
    "346": "p_encoder_layer_16_output_dense_bias",
    "347": "p_encoder_layer_17_attention_layernorm_weight",
    "348": "p_encoder_layer_17_attention_layernorm_bias",
    "349": "p_encoder_layer_17_attention_self_query_weight",
    "350": "p_encoder_layer_17_attention_self_query_bias",
    "351": "p_encoder_layer_17_attention_self_key_weight",
    "352": "p_encoder_layer_17_attention_self_key_bias",
    "353": "p_encoder_layer_17_attention_self_value_weight",
    "354": "p_encoder_layer_17_attention_self_value_bias",
    "355": "p_encoder_layer_17_attention_output_dense_weight",
    "356": "p_encoder_layer_17_attention_output_dense_bias",
    "357": "p_encoder_layer_17_layernorm_weight",
    "358": "p_encoder_layer_17_layernorm_bias",
    "359": "p_encoder_layer_17_intermediate_dense_weight",
    "360": "p_encoder_layer_17_intermediate_dense_bias",
    "361": "p_encoder_layer_17_output_dense_weight",
    "362": "p_encoder_layer_17_output_dense_bias",
    "363": "p_encoder_layer_18_attention_layernorm_weight",
    "364": "p_encoder_layer_18_attention_layernorm_bias",
    "365": "p_encoder_layer_18_attention_self_query_weight",
    "366": "p_encoder_layer_18_attention_self_query_bias",
    "367": "p_encoder_layer_18_attention_self_key_weight",
    "368": "p_encoder_layer_18_attention_self_key_bias",
    "369": "p_encoder_layer_18_attention_self_value_weight",
    "370": "p_encoder_layer_18_attention_self_value_bias",
    "371": "p_encoder_layer_18_attention_output_dense_weight",
    "372": "p_encoder_layer_18_attention_output_dense_bias",
    "373": "p_encoder_layer_18_layernorm_weight",
    "374": "p_encoder_layer_18_layernorm_bias",
    "375": "p_encoder_layer_18_intermediate_dense_weight",
    "376": "p_encoder_layer_18_intermediate_dense_bias",
    "377": "p_encoder_layer_18_output_dense_weight",
    "378": "p_encoder_layer_18_output_dense_bias",
    "379": "p_encoder_layer_19_attention_layernorm_weight",
    "380": "p_encoder_layer_19_attention_layernorm_bias",
    "381": "p_encoder_layer_19_attention_self_query_weight",
    "382": "p_encoder_layer_19_attention_self_query_bias",
    "383": "p_encoder_layer_19_attention_self_key_weight",
    "384": "p_encoder_layer_19_attention_self_key_bias",
    "385": "p_encoder_layer_19_attention_self_value_weight",
    "386": "p_encoder_layer_19_attention_self_value_bias",
    "387": "p_encoder_layer_19_attention_output_dense_weight",
    "388": "p_encoder_layer_19_attention_output_dense_bias",
    "389": "p_encoder_layer_19_layernorm_weight",
    "390": "p_encoder_layer_19_layernorm_bias",
    "391": "p_encoder_layer_19_intermediate_dense_weight",
    "392": "p_encoder_layer_19_intermediate_dense_bias",
    "393": "p_encoder_layer_19_output_dense_weight",
    "394": "p_encoder_layer_19_output_dense_bias",
    "395": "p_encoder_layer_20_attention_layernorm_weight",
    "396": "p_encoder_layer_20_attention_layernorm_bias",
    "397": "p_encoder_layer_20_attention_self_query_weight",
    "398": "p_encoder_layer_20_attention_self_query_bias",
    "399": "p_encoder_layer_20_attention_self_key_weight",
    "400": "p_encoder_layer_20_attention_self_key_bias",
    "401": "p_encoder_layer_20_attention_self_value_weight",
    "402": "p_encoder_layer_20_attention_self_value_bias",
    "403": "p_encoder_layer_20_attention_output_dense_weight",
    "404": "p_encoder_layer_20_attention_output_dense_bias",
    "405": "p_encoder_layer_20_layernorm_weight",
    "406": "p_encoder_layer_20_layernorm_bias",
    "407": "p_encoder_layer_20_intermediate_dense_weight",
    "408": "p_encoder_layer_20_intermediate_dense_bias",
    "409": "p_encoder_layer_20_output_dense_weight",
    "410": "p_encoder_layer_20_output_dense_bias",
    "411": "p_encoder_layer_21_attention_layernorm_weight",
    "412": "p_encoder_layer_21_attention_layernorm_bias",
    "413": "p_encoder_layer_21_attention_self_query_weight",
    "414": "p_encoder_layer_21_attention_self_query_bias",
    "415": "p_encoder_layer_21_attention_self_key_weight",
    "416": "p_encoder_layer_21_attention_self_key_bias",
    "417": "p_encoder_layer_21_attention_self_value_weight",
    "418": "p_encoder_layer_21_attention_self_value_bias",
    "419": "p_encoder_layer_21_attention_output_dense_weight",
    "420": "p_encoder_layer_21_attention_output_dense_bias",
    "421": "p_encoder_layer_21_layernorm_weight",
    "422": "p_encoder_layer_21_layernorm_bias",
    "423": "p_encoder_layer_21_intermediate_dense_weight",
    "424": "p_encoder_layer_21_intermediate_dense_bias",
    "425": "p_encoder_layer_21_output_dense_weight",
    "426": "p_encoder_layer_21_output_dense_bias",
    "427": "p_encoder_layer_22_attention_layernorm_weight",
    "428": "p_encoder_layer_22_attention_layernorm_bias",
    "429": "p_encoder_layer_22_attention_self_query_weight",
    "430": "p_encoder_layer_22_attention_self_query_bias",
    "431": "p_encoder_layer_22_attention_self_key_weight",
    "432": "p_encoder_layer_22_attention_self_key_bias",
    "433": "p_encoder_layer_22_attention_self_value_weight",
    "434": "p_encoder_layer_22_attention_self_value_bias",
    "435": "p_encoder_layer_22_attention_output_dense_weight",
    "436": "p_encoder_layer_22_attention_output_dense_bias",
    "437": "p_encoder_layer_22_layernorm_weight",
    "438": "p_encoder_layer_22_layernorm_bias",
    "439": "p_encoder_layer_22_intermediate_dense_weight",
    "440": "p_encoder_layer_22_intermediate_dense_bias",
    "441": "p_encoder_layer_22_output_dense_weight",
    "442": "p_encoder_layer_22_output_dense_bias",
    "443": "p_encoder_layer_23_attention_layernorm_weight",
    "444": "p_encoder_layer_23_attention_layernorm_bias",
    "445": "p_encoder_layer_23_attention_self_query_weight",
    "446": "p_encoder_layer_23_attention_self_query_bias",
    "447": "p_encoder_layer_23_attention_self_key_weight",
    "448": "p_encoder_layer_23_attention_self_key_bias",
    "449": "p_encoder_layer_23_attention_self_value_weight",
    "450": "p_encoder_layer_23_attention_self_value_bias",
    "451": "p_encoder_layer_23_attention_output_dense_weight",
    "452": "p_encoder_layer_23_attention_output_dense_bias",
    "453": "p_encoder_layer_23_layernorm_weight",
    "454": "p_encoder_layer_23_layernorm_bias",
    "455": "p_encoder_layer_23_intermediate_dense_weight",
    "456": "p_encoder_layer_23_intermediate_dense_bias",
    "457": "p_encoder_layer_23_output_dense_weight",
    "458": "p_encoder_layer_23_output_dense_bias",
    "459": "p_encoder_layer_24_attention_layernorm_weight",
    "460": "p_encoder_layer_24_attention_layernorm_bias",
    "461": "p_encoder_layer_24_attention_self_query_weight",
    "462": "p_encoder_layer_24_attention_self_query_bias",
    "463": "p_encoder_layer_24_attention_self_key_weight",
    "464": "p_encoder_layer_24_attention_self_key_bias",
    "465": "p_encoder_layer_24_attention_self_value_weight",
    "466": "p_encoder_layer_24_attention_self_value_bias",
    "467": "p_encoder_layer_24_attention_output_dense_weight",
    "468": "p_encoder_layer_24_attention_output_dense_bias",
    "469": "p_encoder_layer_24_layernorm_weight",
    "470": "p_encoder_layer_24_layernorm_bias",
    "471": "p_encoder_layer_24_intermediate_dense_weight",
    "472": "p_encoder_layer_24_intermediate_dense_bias",
    "473": "p_encoder_layer_24_output_dense_weight",
    "474": "p_encoder_layer_24_output_dense_bias",
    "475": "p_encoder_layer_25_attention_layernorm_weight",
    "476": "p_encoder_layer_25_attention_layernorm_bias",
    "477": "p_encoder_layer_25_attention_self_query_weight",
    "478": "p_encoder_layer_25_attention_self_query_bias",
    "479": "p_encoder_layer_25_attention_self_key_weight",
    "480": "p_encoder_layer_25_attention_self_key_bias",
    "481": "p_encoder_layer_25_attention_self_value_weight",
    "482": "p_encoder_layer_25_attention_self_value_bias",
    "483": "p_encoder_layer_25_attention_output_dense_weight",
    "484": "p_encoder_layer_25_attention_output_dense_bias",
    "485": "p_encoder_layer_25_layernorm_weight",
    "486": "p_encoder_layer_25_layernorm_bias",
    "487": "p_encoder_layer_25_intermediate_dense_weight",
    "488": "p_encoder_layer_25_intermediate_dense_bias",
    "489": "p_encoder_layer_25_output_dense_weight",
    "490": "p_encoder_layer_25_output_dense_bias",
    "491": "p_encoder_layer_26_attention_layernorm_weight",
    "492": "p_encoder_layer_26_attention_layernorm_bias",
    "493": "p_encoder_layer_26_attention_self_query_weight",
    "494": "p_encoder_layer_26_attention_self_query_bias",
    "495": "p_encoder_layer_26_attention_self_key_weight",
    "496": "p_encoder_layer_26_attention_self_key_bias",
    "497": "p_encoder_layer_26_attention_self_value_weight",
    "498": "p_encoder_layer_26_attention_self_value_bias",
    "499": "p_encoder_layer_26_attention_output_dense_weight",
    "500": "p_encoder_layer_26_attention_output_dense_bias",
    "501": "p_encoder_layer_26_layernorm_weight",
    "502": "p_encoder_layer_26_layernorm_bias",
    "503": "p_encoder_layer_26_intermediate_dense_weight",
    "504": "p_encoder_layer_26_intermediate_dense_bias",
    "505": "p_encoder_layer_26_output_dense_weight",
    "506": "p_encoder_layer_26_output_dense_bias",
    "507": "p_encoder_layer_27_attention_layernorm_weight",
    "508": "p_encoder_layer_27_attention_layernorm_bias",
    "509": "p_encoder_layer_27_attention_self_query_weight",
    "510": "p_encoder_layer_27_attention_self_query_bias",
    "511": "p_encoder_layer_27_attention_self_key_weight",
    "512": "p_encoder_layer_27_attention_self_key_bias",
    "513": "p_encoder_layer_27_attention_self_value_weight",
    "514": "p_encoder_layer_27_attention_self_value_bias",
    "515": "p_encoder_layer_27_attention_output_dense_weight",
    "516": "p_encoder_layer_27_attention_output_dense_bias",
    "517": "p_encoder_layer_27_layernorm_weight",
    "518": "p_encoder_layer_27_layernorm_bias",
    "519": "p_encoder_layer_27_intermediate_dense_weight",
    "520": "p_encoder_layer_27_intermediate_dense_bias",
    "521": "p_encoder_layer_27_output_dense_weight",
    "522": "p_encoder_layer_27_output_dense_bias",
    "523": "p_encoder_layer_28_attention_layernorm_weight",
    "524": "p_encoder_layer_28_attention_layernorm_bias",
    "525": "p_encoder_layer_28_attention_self_query_weight",
    "526": "p_encoder_layer_28_attention_self_query_bias",
    "527": "p_encoder_layer_28_attention_self_key_weight",
    "528": "p_encoder_layer_28_attention_self_key_bias",
    "529": "p_encoder_layer_28_attention_self_value_weight",
    "530": "p_encoder_layer_28_attention_self_value_bias",
    "531": "p_encoder_layer_28_attention_output_dense_weight",
    "532": "p_encoder_layer_28_attention_output_dense_bias",
    "533": "p_encoder_layer_28_layernorm_weight",
    "534": "p_encoder_layer_28_layernorm_bias",
    "535": "p_encoder_layer_28_intermediate_dense_weight",
    "536": "p_encoder_layer_28_intermediate_dense_bias",
    "537": "p_encoder_layer_28_output_dense_weight",
    "538": "p_encoder_layer_28_output_dense_bias",
    "539": "p_encoder_layer_29_attention_layernorm_weight",
    "540": "p_encoder_layer_29_attention_layernorm_bias",
    "541": "p_encoder_layer_29_attention_self_query_weight",
    "542": "p_encoder_layer_29_attention_self_query_bias",
    "543": "p_encoder_layer_29_attention_self_key_weight",
    "544": "p_encoder_layer_29_attention_self_key_bias",
    "545": "p_encoder_layer_29_attention_self_value_weight",
    "546": "p_encoder_layer_29_attention_self_value_bias",
    "547": "p_encoder_layer_29_attention_output_dense_weight",
    "548": "p_encoder_layer_29_attention_output_dense_bias",
    "549": "p_encoder_layer_29_layernorm_weight",
    "550": "p_encoder_layer_29_layernorm_bias",
    "551": "p_encoder_layer_29_intermediate_dense_weight",
    "552": "p_encoder_layer_29_intermediate_dense_bias",
    "553": "p_encoder_layer_29_output_dense_weight",
    "554": "p_encoder_layer_29_output_dense_bias",
    "555": "p_encoder_emb_layer_norm_after_weight",
    "556": "p_encoder_emb_layer_norm_after_bias",
    "557": "b___encoder_layer_0_attention_self_rotary_embeddings__buffers__inv_freq",
    "558": "b___encoder_layer_1_attention_self_rotary_embeddings__buffers__inv_freq",
    "559": "b___encoder_layer_2_attention_self_rotary_embeddings__buffers__inv_freq",
    "560": "b___encoder_layer_3_attention_self_rotary_embeddings__buffers__inv_freq",
    "561": "b___encoder_layer_4_attention_self_rotary_embeddings__buffers__inv_freq",
    "562": "b___encoder_layer_5_attention_self_rotary_embeddings__buffers__inv_freq",
    "563": "b___encoder_layer_6_attention_self_rotary_embeddings__buffers__inv_freq",
    "564": "b___encoder_layer_7_attention_self_rotary_embeddings__buffers__inv_freq",
    "565": "b___encoder_layer_8_attention_self_rotary_embeddings__buffers__inv_freq",
    "566": "b___encoder_layer_9_attention_self_rotary_embeddings__buffers__inv_freq",
    "567": "b___encoder_layer_10_attention_self_rotary_embeddings__buffers__inv_freq",
    "568": "b___encoder_layer_11_attention_self_rotary_embeddings__buffers__inv_freq",
    "569": "b___encoder_layer_12_attention_self_rotary_embeddings__buffers__inv_freq",
    "570": "b___encoder_layer_13_attention_self_rotary_embeddings__buffers__inv_freq",
    "571": "b___encoder_layer_14_attention_self_rotary_embeddings__buffers__inv_freq",
    "572": "b___encoder_layer_15_attention_self_rotary_embeddings__buffers__inv_freq",
    "573": "b___encoder_layer_16_attention_self_rotary_embeddings__buffers__inv_freq",
    "574": "b___encoder_layer_17_attention_self_rotary_embeddings__buffers__inv_freq",
    "575": "b___encoder_layer_18_attention_self_rotary_embeddings__buffers__inv_freq",
    "576": "b___encoder_layer_19_attention_self_rotary_embeddings__buffers__inv_freq",
    "577": "b___encoder_layer_20_attention_self_rotary_embeddings__buffers__inv_freq",
    "578": "b___encoder_layer_21_attention_self_rotary_embeddings__buffers__inv_freq",
    "579": "b___encoder_layer_22_attention_self_rotary_embeddings__buffers__inv_freq",
    "580": "b___encoder_layer_23_attention_self_rotary_embeddings__buffers__inv_freq",
    "581": "b___encoder_layer_24_attention_self_rotary_embeddings__buffers__inv_freq",
    "582": "b___encoder_layer_25_attention_self_rotary_embeddings__buffers__inv_freq",
    "583": "b___encoder_layer_26_attention_self_rotary_embeddings__buffers__inv_freq",
    "584": "b___encoder_layer_27_attention_self_rotary_embeddings__buffers__inv_freq",
    "585": "b___encoder_layer_28_attention_self_rotary_embeddings__buffers__inv_freq",
    "586": "b___encoder_layer_29_attention_self_rotary_embeddings__buffers__inv_freq",
    "587": "p_encoder_layer_0_attention_ln_weight",
    "588": "p_encoder_layer_0_attention_ln_bias",
    "589": "p_encoder_layer_0_ln_weight",
    "590": "p_encoder_layer_0_ln_bias",
    "591": "p_encoder_layer_1_attention_ln_weight",
    "592": "p_encoder_layer_1_attention_ln_bias",
    "593": "p_encoder_layer_1_ln_weight",
    "594": "p_encoder_layer_1_ln_bias",
    "595": "p_encoder_layer_2_attention_ln_weight",
    "596": "p_encoder_layer_2_attention_ln_bias",
    "597": "p_encoder_layer_2_ln_weight",
    "598": "p_encoder_layer_2_ln_bias",
    "599": "p_encoder_layer_3_attention_ln_weight",
    "600": "p_encoder_layer_3_attention_ln_bias",
    "601": "p_encoder_layer_3_ln_weight",
    "602": "p_encoder_layer_3_ln_bias",
    "603": "p_encoder_layer_4_attention_ln_weight",
    "604": "p_encoder_layer_4_attention_ln_bias",
    "605": "p_encoder_layer_4_ln_weight",
    "606": "p_encoder_layer_4_ln_bias",
    "607": "p_encoder_layer_5_attention_ln_weight",
    "608": "p_encoder_layer_5_attention_ln_bias",
    "609": "p_encoder_layer_5_ln_weight",
    "610": "p_encoder_layer_5_ln_bias",
    "611": "p_encoder_layer_6_attention_ln_weight",
    "612": "p_encoder_layer_6_attention_ln_bias",
    "613": "p_encoder_layer_6_ln_weight",
    "614": "p_encoder_layer_6_ln_bias",
    "615": "p_encoder_layer_7_attention_ln_weight",
    "616": "p_encoder_layer_7_attention_ln_bias",
    "617": "p_encoder_layer_7_ln_weight",
    "618": "p_encoder_layer_7_ln_bias",
    "619": "p_encoder_layer_8_attention_ln_weight",
    "620": "p_encoder_layer_8_attention_ln_bias",
    "621": "p_encoder_layer_8_ln_weight",
    "622": "p_encoder_layer_8_ln_bias",
    "623": "p_encoder_layer_9_attention_ln_weight",
    "624": "p_encoder_layer_9_attention_ln_bias",
    "625": "p_encoder_layer_9_ln_weight",
    "626": "p_encoder_layer_9_ln_bias",
    "627": "p_encoder_layer_10_attention_ln_weight",
    "628": "p_encoder_layer_10_attention_ln_bias",
    "629": "p_encoder_layer_10_ln_weight",
    "630": "p_encoder_layer_10_ln_bias",
    "631": "p_encoder_layer_11_attention_ln_weight",
    "632": "p_encoder_layer_11_attention_ln_bias",
    "633": "p_encoder_layer_11_ln_weight",
    "634": "p_encoder_layer_11_ln_bias",
    "635": "p_encoder_layer_12_attention_ln_weight",
    "636": "p_encoder_layer_12_attention_ln_bias",
    "637": "p_encoder_layer_12_ln_weight",
    "638": "p_encoder_layer_12_ln_bias",
    "639": "p_encoder_layer_13_attention_ln_weight",
    "640": "p_encoder_layer_13_attention_ln_bias",
    "641": "p_encoder_layer_13_ln_weight",
    "642": "p_encoder_layer_13_ln_bias",
    "643": "p_encoder_layer_14_attention_ln_weight",
    "644": "p_encoder_layer_14_attention_ln_bias",
    "645": "p_encoder_layer_14_ln_weight",
    "646": "p_encoder_layer_14_ln_bias",
    "647": "p_encoder_layer_15_attention_ln_weight",
    "648": "p_encoder_layer_15_attention_ln_bias",
    "649": "p_encoder_layer_15_ln_weight",
    "650": "p_encoder_layer_15_ln_bias",
    "651": "p_encoder_layer_16_attention_ln_weight",
    "652": "p_encoder_layer_16_attention_ln_bias",
    "653": "p_encoder_layer_16_ln_weight",
    "654": "p_encoder_layer_16_ln_bias",
    "655": "p_encoder_layer_17_attention_ln_weight",
    "656": "p_encoder_layer_17_attention_ln_bias",
    "657": "p_encoder_layer_17_ln_weight",
    "658": "p_encoder_layer_17_ln_bias",
    "659": "p_encoder_layer_18_attention_ln_weight",
    "660": "p_encoder_layer_18_attention_ln_bias",
    "661": "p_encoder_layer_18_ln_weight",
    "662": "p_encoder_layer_18_ln_bias",
    "663": "p_encoder_layer_19_attention_ln_weight",
    "664": "p_encoder_layer_19_attention_ln_bias",
    "665": "p_encoder_layer_19_ln_weight",
    "666": "p_encoder_layer_19_ln_bias",
    "667": "p_encoder_layer_20_attention_ln_weight",
    "668": "p_encoder_layer_20_attention_ln_bias",
    "669": "p_encoder_layer_20_ln_weight",
    "670": "p_encoder_layer_20_ln_bias",
    "671": "p_encoder_layer_21_attention_ln_weight",
    "672": "p_encoder_layer_21_attention_ln_bias",
    "673": "p_encoder_layer_21_ln_weight",
    "674": "p_encoder_layer_21_ln_bias",
    "675": "p_encoder_layer_22_attention_ln_weight",
    "676": "p_encoder_layer_22_attention_ln_bias",
    "677": "p_encoder_layer_22_ln_weight",
    "678": "p_encoder_layer_22_ln_bias",
    "679": "p_encoder_layer_23_attention_ln_weight",
    "680": "p_encoder_layer_23_attention_ln_bias",
    "681": "p_encoder_layer_23_ln_weight",
    "682": "p_encoder_layer_23_ln_bias",
    "683": "p_encoder_ln_weight",
    "684": "p_encoder_ln_bias",
    "685": "p_transformer_layer_0_attention_q_lin_weight",
    "686": "p_transformer_layer_0_attention_q_lin_bias",
    "687": "p_transformer_layer_0_attention_k_lin_weight",
    "688": "p_transformer_layer_0_attention_k_lin_bias",
    "689": "p_transformer_layer_0_attention_v_lin_weight",
    "690": "p_transformer_layer_0_attention_v_lin_bias",
    "691": "p_transformer_layer_0_attention_out_lin_weight",
    "692": "p_transformer_layer_0_attention_out_lin_bias",
    "693": "p_transformer_layer_0_sa_layer_norm_weight",
    "694": "p_transformer_layer_0_sa_layer_norm_bias",
    "695": "p_transformer_layer_0_ffn_lin1_weight",
    "696": "p_transformer_layer_0_ffn_lin1_bias",
    "697": "p_transformer_layer_0_ffn_lin2_weight",
    "698": "p_transformer_layer_0_ffn_lin2_bias",
    "699": "p_transformer_layer_0_output_layer_norm_weight",
    "700": "p_transformer_layer_0_output_layer_norm_bias",
    "701": "p_transformer_layer_1_attention_q_lin_weight",
    "702": "p_transformer_layer_1_attention_q_lin_bias",
    "703": "p_transformer_layer_1_attention_k_lin_weight",
    "704": "p_transformer_layer_1_attention_k_lin_bias",
    "705": "p_transformer_layer_1_attention_v_lin_weight",
    "706": "p_transformer_layer_1_attention_v_lin_bias",
    "707": "p_transformer_layer_1_attention_out_lin_weight",
    "708": "p_transformer_layer_1_attention_out_lin_bias",
    "709": "p_transformer_layer_1_sa_layer_norm_weight",
    "710": "p_transformer_layer_1_sa_layer_norm_bias",
    "711": "p_transformer_layer_1_ffn_lin1_weight",
    "712": "p_transformer_layer_1_ffn_lin1_bias",
    "713": "p_transformer_layer_1_ffn_lin2_weight",
    "714": "p_transformer_layer_1_ffn_lin2_bias",
    "715": "p_transformer_layer_1_output_layer_norm_weight",
    "716": "p_transformer_layer_1_output_layer_norm_bias",
    "717": "p_transformer_layer_2_attention_q_lin_weight",
    "718": "p_transformer_layer_2_attention_q_lin_bias",
    "719": "p_transformer_layer_2_attention_k_lin_weight",
    "720": "p_transformer_layer_2_attention_k_lin_bias",
    "721": "p_transformer_layer_2_attention_v_lin_weight",
    "722": "p_transformer_layer_2_attention_v_lin_bias",
    "723": "p_transformer_layer_2_attention_out_lin_weight",
    "724": "p_transformer_layer_2_attention_out_lin_bias",
    "725": "p_transformer_layer_2_sa_layer_norm_weight",
    "726": "p_transformer_layer_2_sa_layer_norm_bias",
    "727": "p_transformer_layer_2_ffn_lin1_weight",
    "728": "p_transformer_layer_2_ffn_lin1_bias",
    "729": "p_transformer_layer_2_ffn_lin2_weight",
    "730": "p_transformer_layer_2_ffn_lin2_bias",
    "731": "p_transformer_layer_2_output_layer_norm_weight",
    "732": "p_transformer_layer_2_output_layer_norm_bias",
    "733": "p_transformer_layer_3_attention_q_lin_weight",
    "734": "p_transformer_layer_3_attention_q_lin_bias",
    "735": "p_transformer_layer_3_attention_k_lin_weight",
    "736": "p_transformer_layer_3_attention_k_lin_bias",
    "737": "p_transformer_layer_3_attention_v_lin_weight",
    "738": "p_transformer_layer_3_attention_v_lin_bias",
    "739": "p_transformer_layer_3_attention_out_lin_weight",
    "740": "p_transformer_layer_3_attention_out_lin_bias",
    "741": "p_transformer_layer_3_sa_layer_norm_weight",
    "742": "p_transformer_layer_3_sa_layer_norm_bias",
    "743": "p_transformer_layer_3_ffn_lin1_weight",
    "744": "p_transformer_layer_3_ffn_lin1_bias",
    "745": "p_transformer_layer_3_ffn_lin2_weight",
    "746": "p_transformer_layer_3_ffn_lin2_bias",
    "747": "p_transformer_layer_3_output_layer_norm_weight",
    "748": "p_transformer_layer_3_output_layer_norm_bias",
    "749": "p_transformer_layer_4_attention_q_lin_weight",
    "750": "p_transformer_layer_4_attention_q_lin_bias",
    "751": "p_transformer_layer_4_attention_k_lin_weight",
    "752": "p_transformer_layer_4_attention_k_lin_bias",
    "753": "p_transformer_layer_4_attention_v_lin_weight",
    "754": "p_transformer_layer_4_attention_v_lin_bias",
    "755": "p_transformer_layer_4_attention_out_lin_weight",
    "756": "p_transformer_layer_4_attention_out_lin_bias",
    "757": "p_transformer_layer_4_sa_layer_norm_weight",
    "758": "p_transformer_layer_4_sa_layer_norm_bias",
    "759": "p_transformer_layer_4_ffn_lin1_weight",
    "760": "p_transformer_layer_4_ffn_lin1_bias",
    "761": "p_transformer_layer_4_ffn_lin2_weight",
    "762": "p_transformer_layer_4_ffn_lin2_bias",
    "763": "p_transformer_layer_4_output_layer_norm_weight",
    "764": "p_transformer_layer_4_output_layer_norm_bias",
    "765": "p_transformer_layer_5_attention_q_lin_weight",
    "766": "p_transformer_layer_5_attention_q_lin_bias",
    "767": "p_transformer_layer_5_attention_k_lin_weight",
    "768": "p_transformer_layer_5_attention_k_lin_bias",
    "769": "p_transformer_layer_5_attention_v_lin_weight",
    "770": "p_transformer_layer_5_attention_v_lin_bias",
    "771": "p_transformer_layer_5_attention_out_lin_weight",
    "772": "p_transformer_layer_5_attention_out_lin_bias",
    "773": "p_transformer_layer_5_sa_layer_norm_weight",
    "774": "p_transformer_layer_5_sa_layer_norm_bias",
    "775": "p_transformer_layer_5_ffn_lin1_weight",
    "776": "p_transformer_layer_5_ffn_lin1_bias",
    "777": "p_transformer_layer_5_ffn_lin2_weight",
    "778": "p_transformer_layer_5_ffn_lin2_bias",
    "779": "p_transformer_layer_5_output_layer_norm_weight",
    "780": "p_transformer_layer_5_output_layer_norm_bias",
    "781": "p_dense_bias",
    "782": "p_out_proj_weight",
    "783": "p_out_proj_bias",
    "784": "features",
    "785": "p_h_0_ln_1_weight",
    "786": "p_h_0_ln_1_bias",
    "787": "p_h_0_attn_attention_q_proj_weight",
    "788": "p_h_0_attn_attention_k_proj_weight",
    "789": "p_h_0_attn_attention_v_proj_weight",
    "790": "p_h_0_attn_attention_out_proj_weight",
    "791": "p_h_0_attn_attention_out_proj_bias",
    "792": "p_h_0_ln_2_weight",
    "793": "p_h_0_ln_2_bias",
    "794": "p_h_0_mlp_c_fc_weight",
    "795": "p_h_0_mlp_c_fc_bias",
    "796": "p_h_0_mlp_c_proj_weight",
    "797": "p_h_0_mlp_c_proj_bias",
    "798": "p_h_1_ln_1_weight",
    "799": "p_h_1_ln_1_bias",
    "800": "p_h_1_attn_attention_q_proj_weight",
    "801": "p_h_1_attn_attention_k_proj_weight",
    "802": "p_h_1_attn_attention_v_proj_weight",
    "803": "p_h_1_attn_attention_out_proj_weight",
    "804": "p_h_1_attn_attention_out_proj_bias",
    "805": "p_h_1_ln_2_weight",
    "806": "p_h_1_ln_2_bias",
    "807": "p_h_1_mlp_c_fc_weight",
    "808": "p_h_1_mlp_c_fc_bias",
    "809": "p_h_1_mlp_c_proj_weight",
    "810": "p_h_1_mlp_c_proj_bias",
    "811": "p_h_2_ln_1_weight",
    "812": "p_h_2_ln_1_bias",
    "813": "p_h_2_attn_attention_q_proj_weight",
    "814": "p_h_2_attn_attention_k_proj_weight",
    "815": "p_h_2_attn_attention_v_proj_weight",
    "816": "p_h_2_attn_attention_out_proj_weight",
    "817": "p_h_2_attn_attention_out_proj_bias",
    "818": "p_h_2_ln_2_weight",
    "819": "p_h_2_ln_2_bias",
    "820": "p_h_2_mlp_c_fc_weight",
    "821": "p_h_2_mlp_c_fc_bias",
    "822": "p_h_2_mlp_c_proj_weight",
    "823": "p_h_2_mlp_c_proj_bias",
    "824": "p_h_3_ln_1_weight",
    "825": "p_h_3_ln_1_bias",
    "826": "p_h_3_attn_attention_q_proj_weight",
    "827": "p_h_3_attn_attention_k_proj_weight",
    "828": "p_h_3_attn_attention_v_proj_weight",
    "829": "p_h_3_attn_attention_out_proj_weight",
    "830": "p_h_3_attn_attention_out_proj_bias",
    "831": "p_h_3_ln_2_weight",
    "832": "p_h_3_ln_2_bias",
    "833": "p_h_3_mlp_c_fc_weight",
    "834": "p_h_3_mlp_c_fc_bias",
    "835": "p_h_3_mlp_c_proj_weight",
    "836": "p_h_3_mlp_c_proj_bias",
    "837": "p_h_4_ln_1_weight",
    "838": "p_h_4_ln_1_bias",
    "839": "p_h_4_attn_attention_q_proj_weight",
    "840": "p_h_4_attn_attention_k_proj_weight",
    "841": "p_h_4_attn_attention_v_proj_weight",
    "842": "p_h_4_attn_attention_out_proj_weight",
    "843": "p_h_4_attn_attention_out_proj_bias",
    "844": "p_h_4_ln_2_weight",
    "845": "p_h_4_ln_2_bias",
    "846": "p_h_4_mlp_c_fc_weight",
    "847": "p_h_4_mlp_c_fc_bias",
    "848": "p_h_4_mlp_c_proj_weight",
    "849": "p_h_4_mlp_c_proj_bias",
    "850": "p_h_5_ln_1_weight",
    "851": "p_h_5_ln_1_bias",
    "852": "p_h_5_attn_attention_q_proj_weight",
    "853": "p_h_5_attn_attention_k_proj_weight",
    "854": "p_h_5_attn_attention_v_proj_weight",
    "855": "p_h_5_attn_attention_out_proj_weight",
    "856": "p_h_5_attn_attention_out_proj_bias",
    "857": "p_h_5_ln_2_weight",
    "858": "p_h_5_ln_2_bias",
    "859": "p_h_5_mlp_c_fc_weight",
    "860": "p_h_5_mlp_c_fc_bias",
    "861": "p_h_5_mlp_c_proj_weight",
    "862": "p_h_5_mlp_c_proj_bias",
    "863": "p_h_6_ln_1_weight",
    "864": "p_h_6_ln_1_bias",
    "865": "p_h_6_attn_attention_q_proj_weight",
    "866": "p_h_6_attn_attention_k_proj_weight",
    "867": "p_h_6_attn_attention_v_proj_weight",
    "868": "p_h_6_attn_attention_out_proj_weight",
    "869": "p_h_6_attn_attention_out_proj_bias",
    "870": "p_h_6_ln_2_weight",
    "871": "p_h_6_ln_2_bias",
    "872": "p_h_6_mlp_c_fc_weight",
    "873": "p_h_6_mlp_c_fc_bias",
    "874": "p_h_6_mlp_c_proj_weight",
    "875": "p_h_6_mlp_c_proj_bias",
    "876": "p_h_7_ln_1_weight",
    "877": "p_h_7_ln_1_bias",
    "878": "p_h_7_attn_attention_q_proj_weight",
    "879": "p_h_7_attn_attention_k_proj_weight",
    "880": "p_h_7_attn_attention_v_proj_weight",
    "881": "p_h_7_attn_attention_out_proj_weight",
    "882": "p_h_7_attn_attention_out_proj_bias",
    "883": "p_h_7_ln_2_weight",
    "884": "p_h_7_ln_2_bias",
    "885": "p_h_7_mlp_c_fc_weight",
    "886": "p_h_7_mlp_c_fc_bias",
    "887": "p_h_7_mlp_c_proj_weight",
    "888": "p_h_7_mlp_c_proj_bias",
    "889": "p_h_8_ln_1_weight",
    "890": "p_h_8_ln_1_bias",
    "891": "p_h_8_attn_attention_q_proj_weight",
    "892": "p_h_8_attn_attention_k_proj_weight",
    "893": "p_h_8_attn_attention_v_proj_weight",
    "894": "p_h_8_attn_attention_out_proj_weight",
    "895": "p_h_8_attn_attention_out_proj_bias",
    "896": "p_h_8_ln_2_weight",
    "897": "p_h_8_ln_2_bias",
    "898": "p_h_8_mlp_c_fc_weight",
    "899": "p_h_8_mlp_c_fc_bias",
    "900": "p_h_8_mlp_c_proj_weight",
    "901": "p_h_8_mlp_c_proj_bias",
    "902": "p_h_9_ln_1_weight",
    "903": "p_h_9_ln_1_bias",
    "904": "p_h_9_attn_attention_q_proj_weight",
    "905": "p_h_9_attn_attention_k_proj_weight",
    "906": "p_h_9_attn_attention_v_proj_weight",
    "907": "p_h_9_attn_attention_out_proj_weight",
    "908": "p_h_9_attn_attention_out_proj_bias",
    "909": "p_h_9_ln_2_weight",
    "910": "p_h_9_ln_2_bias",
    "911": "p_h_9_mlp_c_fc_weight",
    "912": "p_h_9_mlp_c_fc_bias",
    "913": "p_h_9_mlp_c_proj_weight",
    "914": "p_h_9_mlp_c_proj_bias",
    "915": "p_h_10_ln_1_weight",
    "916": "p_h_10_ln_1_bias",
    "917": "p_h_10_attn_attention_q_proj_weight",
    "918": "p_h_10_attn_attention_k_proj_weight",
    "919": "p_h_10_attn_attention_v_proj_weight",
    "920": "p_h_10_attn_attention_out_proj_weight",
    "921": "p_h_10_attn_attention_out_proj_bias",
    "922": "p_h_10_ln_2_weight",
    "923": "p_h_10_ln_2_bias",
    "924": "p_h_10_mlp_c_fc_weight",
    "925": "p_h_10_mlp_c_fc_bias",
    "926": "p_h_10_mlp_c_proj_weight",
    "927": "p_h_10_mlp_c_proj_bias",
    "928": "p_h_11_ln_1_weight",
    "929": "p_h_11_ln_1_bias",
    "930": "p_h_11_attn_attention_q_proj_weight",
    "931": "p_h_11_attn_attention_k_proj_weight",
    "932": "p_h_11_attn_attention_v_proj_weight",
    "933": "p_h_11_attn_attention_out_proj_weight",
    "934": "p_h_11_attn_attention_out_proj_bias",
    "935": "p_h_11_ln_2_weight",
    "936": "p_h_11_ln_2_bias",
    "937": "p_h_11_mlp_c_fc_weight",
    "938": "p_h_11_mlp_c_fc_bias",
    "939": "p_h_11_mlp_c_proj_weight",
    "940": "p_h_11_mlp_c_proj_bias",
    "941": "p_ln_f_weight",
    "942": "p_ln_f_bias",
    "943": "b_h_0_attn_attention_bias",
    "944": "b_h_1_attn_attention_bias",
    "945": "b_h_2_attn_attention_bias",
    "946": "b_h_3_attn_attention_bias",
    "947": "b_h_4_attn_attention_bias",
    "948": "b_h_5_attn_attention_bias",
    "949": "b_h_6_attn_attention_bias",
    "950": "b_h_7_attn_attention_bias",
    "951": "b_h_8_attn_attention_bias",
    "952": "b_h_9_attn_attention_bias",
    "953": "b_h_10_attn_attention_bias",
    "954": "b_h_11_attn_attention_bias",
    "955": "c_h_0_attn_attention_lifted_tensor_0",
    "956": "c_h_1_attn_attention_lifted_tensor_1",
    "957": "c_h_2_attn_attention_lifted_tensor_2",
    "958": "c_h_3_attn_attention_lifted_tensor_3",
    "959": "c_h_4_attn_attention_lifted_tensor_4",
    "960": "c_h_5_attn_attention_lifted_tensor_5",
    "961": "c_h_6_attn_attention_lifted_tensor_6",
    "962": "c_h_7_attn_attention_lifted_tensor_7",
    "963": "c_h_8_attn_attention_lifted_tensor_8",
    "964": "c_h_9_attn_attention_lifted_tensor_9",
    "965": "c_h_10_attn_attention_lifted_tensor_10",
    "966": "c_h_11_attn_attention_lifted_tensor_11",
    "967": "p_encoder_layer_12_attention_output_layernorm_weight",
    "968": "p_encoder_layer_12_attention_output_layernorm_bias",
    "969": "p_encoder_layer_12_output_layernorm_weight",
    "970": "p_encoder_layer_12_output_layernorm_bias",
    "971": "p_encoder_layer_13_attention_output_layernorm_weight",
    "972": "p_encoder_layer_13_attention_output_layernorm_bias",
    "973": "p_encoder_layer_13_output_layernorm_weight",
    "974": "p_encoder_layer_13_output_layernorm_bias",
    "975": "p_encoder_layer_14_attention_output_layernorm_weight",
    "976": "p_encoder_layer_14_attention_output_layernorm_bias",
    "977": "p_encoder_layer_14_output_layernorm_weight",
    "978": "p_encoder_layer_14_output_layernorm_bias",
    "979": "p_encoder_layer_15_attention_output_layernorm_weight",
    "980": "p_encoder_layer_15_attention_output_layernorm_bias",
    "981": "p_encoder_layer_15_output_layernorm_weight",
    "982": "p_encoder_layer_15_output_layernorm_bias",
    "983": "p_encoder_layer_16_attention_output_layernorm_weight",
    "984": "p_encoder_layer_16_attention_output_layernorm_bias",
    "985": "p_encoder_layer_16_output_layernorm_weight",
    "986": "p_encoder_layer_16_output_layernorm_bias",
    "987": "p_encoder_layer_17_attention_output_layernorm_weight",
    "988": "p_encoder_layer_17_attention_output_layernorm_bias",
    "989": "p_encoder_layer_17_output_layernorm_weight",
    "990": "p_encoder_layer_17_output_layernorm_bias",
    "991": "p_encoder_layer_18_attention_output_layernorm_weight",
    "992": "p_encoder_layer_18_attention_output_layernorm_bias",
    "993": "p_encoder_layer_18_output_layernorm_weight",
    "994": "p_encoder_layer_18_output_layernorm_bias",
    "995": "p_encoder_layer_19_attention_output_layernorm_weight",
    "996": "p_encoder_layer_19_attention_output_layernorm_bias",
    "997": "p_encoder_layer_19_output_layernorm_weight",
    "998": "p_encoder_layer_19_output_layernorm_bias",
    "999": "p_encoder_layer_20_attention_output_layernorm_weight",
    "1000": "p_encoder_layer_20_attention_output_layernorm_bias",
    "1001": "p_encoder_layer_20_output_layernorm_weight",
    "1002": "p_encoder_layer_20_output_layernorm_bias",
    "1003": "p_encoder_layer_21_attention_output_layernorm_weight",
    "1004": "p_encoder_layer_21_attention_output_layernorm_bias",
    "1005": "p_encoder_layer_21_output_layernorm_weight",
    "1006": "p_encoder_layer_21_output_layernorm_bias",
    "1007": "p_encoder_layer_22_attention_output_layernorm_weight",
    "1008": "p_encoder_layer_22_attention_output_layernorm_bias",
    "1009": "p_encoder_layer_22_output_layernorm_weight",
    "1010": "p_encoder_layer_22_output_layernorm_bias",
    "1011": "p_encoder_layer_23_attention_output_layernorm_weight",
    "1012": "p_encoder_layer_23_attention_output_layernorm_bias",
    "1013": "p_encoder_layer_23_output_layernorm_weight",
    "1014": "p_encoder_layer_23_output_layernorm_bias",
    "1015": "p_encoder_layer_24_attention_output_layernorm_weight",
    "1016": "p_encoder_layer_24_attention_output_layernorm_bias",
    "1017": "p_encoder_layer_24_output_layernorm_weight",
    "1018": "p_encoder_layer_24_output_layernorm_bias",
    "1019": "p_encoder_layer_25_attention_output_layernorm_weight",
    "1020": "p_encoder_layer_25_attention_output_layernorm_bias",
    "1021": "p_encoder_layer_25_output_layernorm_weight",
    "1022": "p_encoder_layer_25_output_layernorm_bias",
    "1023": "p_encoder_layer_26_attention_output_layernorm_weight",
    "1024": "p_encoder_layer_26_attention_output_layernorm_bias",
    "1025": "p_encoder_layer_26_output_layernorm_weight",
    "1026": "p_encoder_layer_26_output_layernorm_bias",
    "1027": "p_encoder_layer_27_attention_output_layernorm_weight",
    "1028": "p_encoder_layer_27_attention_output_layernorm_bias",
    "1029": "p_encoder_layer_27_output_layernorm_weight",
    "1030": "p_encoder_layer_27_output_layernorm_bias",
    "1031": "p_encoder_layer_28_attention_output_layernorm_weight",
    "1032": "p_encoder_layer_28_attention_output_layernorm_bias",
    "1033": "p_encoder_layer_28_output_layernorm_weight",
    "1034": "p_encoder_layer_28_output_layernorm_bias",
    "1035": "p_encoder_layer_29_attention_output_layernorm_weight",
    "1036": "p_encoder_layer_29_attention_output_layernorm_bias",
    "1037": "p_encoder_layer_29_output_layernorm_weight",
    "1038": "p_encoder_layer_29_output_layernorm_bias"
  },
  "patterns": {
    "10": "KgEAIgH//ysK/+oB//8sCgAAAf//EAoACgH//xAKAAwB//8KCv/pAf//Cgr/8AH//y0KAAAB//oQCgAKAf//EAoADAH//woK/+kB//8KCv/wAf//Cgr/9QH/+goK/+gB//8KCv/wAf//Cgr/9QH//AoK/+gB//8KCv/wAf//IQsAAAL/6v/8Lgr/5wH/6S8KAAoB//8vCgAMAf/+MAoAAAH//zEBACIC/////SELAAAC////+QwLAAAC//n//xEKABYB//8KCv/1Af/rCgr/6AH//woK//AB//8KCv/1Af/tCgr/6AH//woK//AB//8hDgAAAv/X//wuCv/nAf/WLwoACgH//y8KAAwB//4wCgAAAf//MQEAIgL////9IQsAAAL////5",
    "11": "EAoADAH//woK/+kB//8KCv/wAf//CgoAOQH//woK//UB//8KCv/oAf//Cgr/6QH//woK/94B//8MDgAAAv/2//83CgAiAf//EQoAFgH//w4K/+YB//82CwAAAv///+c4CgAxAf//OQoAMgH//xcKABoB//8=",
    "12": "Cgr/9QH/+woK//QB//8KCgAOAf//Cgr/9QH/+QoK//QB//8LCwAKAv8v//oLCwAAAv8v//wMCwAAAv/+//8LCwAAAv8u//wMCwAAAv/+//8NDP/zA////y3/Lg4K//IB//8PAf/xAAoK//UB//8QCgAMAf//EAoAEwH//woK//AB//8KCgAVAf//EQoAFgH//xIKAAAB/+sTCgAAAf//FAsAAAL////9EQoAFwH//xULABgC//7//xYMAAAD//P/If8iFwoAGQH//xgK/+8B//8WDAAAA//w/yD/IRcKABkB//8YCv/vAf//FgwAAAP/7f8f/yAXCgAZAf//GAr/7wH//xkNAAAE//n//P////YYCv/vAf//FwoAGgH//xYMAAAD////G/8cDgr/8gH//wwOAAAC////5Q0M//MD////Gv8b",
    "13": "FgwAAAP///8b/xwaCgAAAf//FgwAAAP///8b/xwOCv/yAf//DAsAAAL////7DQz/8wP///8a/xsWDAAAA////xv/HBcKABkB//8YCv/vAf//FgwAAAP//P8a/xsXCgAZAf//GAr/7wH//xYMAAAD//n/Gf8aFwoAGQH//xgK/+8B//8ZDQAABP/5//z////gGAr/7wH//xcKABoB//8WDAAAA////xX/Fg4K//IB//8MCwAAAv////ENDP/zA////xT/FRYMAAAD////Ff8WGgoAAAH//xYMAAAD////Ff8WDgr/8gH//wwLAAAC////+w0M//MD////FP8VFgwAAAP///8V/xYXCgAZAf//GAr/7wH//xYMAAAD//z/FP8VFwoAGQH//xgK/+8B//8WDAAAA//5/xP/FBcKABkB//8YCv/vAf//GQ0AAAT/+f/8////yhgK/+8B//8XCgAaAf//",
    "14": "FgwAAAP///8P/xAOCv/yAf//DAsAAAL////xDQz/8wP///8O/w8WDAAAA////w//EBoKAAAB//8WDAAAA////w//EA4K//IB//8MCwAAAv////sNDP/zA////w7/DxYMAAAD////D/8QFwoAGQH//xgK/+8B//8WDAAAA//8/w7/DxcKABkB//8YCv/vAf//FgwAAAP/+f8N/w4XCgAZAf//GAr/7wH//xkNAAAE//n//P///7QYCv/vAf//FwoAGgH//xYMAAAD////Cf8KDgr/8gH//wwLAAAC////8Q0M//MD////CP8JFgwAAAP///8J/woaCgAAAf//FgwAAAP///8J/woOCv/yAf//DAsAAAL////7DQz/8wP///8I/wkWDAAAA////wn/ChcKABkB//8YCv/vAf//FgwAAAP//P8I/wkXCgAZAf//GAr/7wH//xYMAAAD//n/B/8IFwoAGQH//w==",
    "15": "GAr/7wH//xkNAAAE//n//P///54YCv/vAf//FwoAGgH//xYMAAAD////A/8EDgr/8gH//wwLAAAC////8Q0M//MD////Av8DFgwAAAP///8D/wQaCgAAAf//FgwAAAP///8D/wQOCv/yAf//DAsAAAL////7DQz/8wP///8C/wMWDAAAA////wP/BBcKABkB//8YCv/vAf//FgwAAAP//P8C/wMXCgAZAf//GAr/7wH//xYMAAAD//n/Af8CFwoAGQH//xgK/+8B//8ZDQAABP/5//z///+IGAr/7wH//xcKABoB//8WDAAAA////v3+/g4K//IB//8MCwAAAv////ENDP/zA////vz+/RYMAAAD///+/f7+GgoAAAH//xYMAAAD///+/f7+Dgr/8gH//wwLAAAC////+w0M//MD///+/P79FgwAAAP///79/v4XCgAZAf//GAr/7wH//xYMAAAD//z+/P79",
    "16": "FwoAGQH//xgK/+8B//8WDAAAA//5/vv+/BcKABkB//8YCv/vAf//GQ0AAAT/+f/8////chgK/+8B//8XCgAaAf//FgwAAAP///73/vgOCv/yAf//DAsAAAL////xDQz/8wP///72/vcWDAAAA////vf++BoKAAAB//8WDAAAA////vf++A4K//IB//8MCwAAAv////sNDP/zA////vb+9xYMAAAD///+9/74FwoAGQH//xgK/+8B//8WDAAAA//8/vb+9xcKABkB//8YCv/vAf//FgwAAAP/+f71/vYXCgAZAf//GAr/7wH//xkNAAAE//n//P///1wYCv/vAf//FwoAGgH//xYMAAAD///+8f7yDgr/8gH//wwLAAAC////8Q0M//MD///+8P7xFgwAAAP///7x/vIaCgAAAf//FgwAAAP///7x/vIOCv/yAf//DAsAAAL////7DQz/8wP///7w/vE=",
    "17": "FgwAAAP///7x/vIXCgAZAf//GAr/7wH//xYMAAAD//z+8P7xFwoAGQH//xgK/+8B//8WDAAAA//5/u/+8BcKABkB//8YCv/vAf//GQ0AAAT/+f/8////RhgK/+8B//8XCgAaAf//FgwAAAP///7r/uwOCv/yAf//DAsAAAL////xDQz/8wP///7q/usWDAAAA////uv+7BoKAAAB//8WDAAAA////uv+7A4K//IB//8MCwAAAv////sNDP/zA////ur+6xYMAAAD///+6/7sFwoAGQH//xgK/+8B//8WDAAAA//8/ur+6xcKABkB//8YCv/vAf//FgwAAAP/+f7p/uoXCgAZAf//GAr/7wH//xkNAAAE//n//P///zAYCv/vAf//FwoAGgH//xYMAAAD///+5f7mDgr/8gH//wwLAAAC////8Q0M//MD///+5P7lFgwAAAP///7l/uYaCgAAAf//",
    "18": "FgwAAAP///7l/uYOCv/yAf//DAsAAAL////7DQz/8wP///7k/uUWDAAAA////uX+5hcKABkB//8YCv/vAf//FgwAAAP//P7k/uUXCgAZAf//GAr/7wH//xYMAAAD//n+4/7kFwoAGQH//xgK/+8B//8ZDQAABP/5//z///8aGAr/7wH//xcKABoB//8WDAAAA////t/+4A4K//IB//8MCwAAAv////ENDP/zA////t7+3xYMAAAD///+3/7gGgoAAAH//xYMAAAD///+3/7gDgr/8gH//wwLAAAC////+w0M//MD///+3v7fFgwAAAP///7f/uAXCgAZAf//GAr/7wH//xYMAAAD//z+3v7fFwoAGQH//xgK/+8B//8WDAAAA//5/t3+3hcKABkB//8YCv/vAf//GQ0AAAT/+f/8////BBgK/+8B//8XCgAaAf//FgwAAAP///7Z/toOCv/yAf//",
    "19": "FwoAOAH//TgKADEB//8XCgA4Af/8OAoAMQH//xcKADgB//s4CgAxAf//EQoAFgH/+xEKABYB//wYCv/jAf//NgsAAAL//f//"
  },
  "rules": {
    "transition_rules": {
      "After 'aten.ones.default:node_args(0):kwargs('device', 'pin_memory')' -> 'aten.expand.default:node_args(1):kwargs()' with connection 'in0=SOURCE'": {
        "probability": "1.00",
        "count": 9,
        "b64_repr": "DwH/8QAKCv/1AQAA"
      },
      "After 'aten.lift_fresh_copy.default:node_args(1):kwargs()' -> 'aten.detach.default:node_args(1):kwargs()' with connection 'in0=SOURCE'": {
        "probability": "1.00",
        "count": 19,
        "b64_repr": "EgoAAAATCgAAAQAA"
      },
      "After 'aten.masked_fill.Scalar:node_args(2):kwargs()' -> 'aten.scaled_dot_product_attention.default:node_args(4):kwargs()' with connection 'in0=SOURCE,in1=rel_-7,in2=rel_-4,in3=rel_-1'": {
        "probability": "0.99",
        "count": 87,
        "b64_repr": "FQsAGAAZDQAAAQAA",
        "exceptions": [
          "-> 'aten.mul.Tensor:node_args(1):kwargs()' with conn 'in0=SOURCE' (1 times)"
        ]
      },
      "After 'aten.scaled_dot_product_attention.default:node_args(4):kwargs()' -> 'aten.transpose.int:node_args(1):kwargs()' with connection 'in0=SOURCE'": {
        "probability": "1.00",
        "count": 87,
        "b64_repr": "GQ0AAAAYCv/vAQAA"
      },
      "After 'aten.outer.default:node_args(2):kwargs()' -> '<PATTERN ID=10>' with connection 'in0=rel_-8,in1=rel_-4,in2=SOURCE'": {
        "probability": "1.00",
        "count": 30,
        "b64_repr": "KQsAAAAGCgAAAQAA"
      },
      "After 'aten.scaled_dot_product_attention.default:node_args(4):kwargs('scale',)' -> 'aten.transpose.int:node_args(1):kwargs()' with connection 'in0=SOURCE'": {
        "probability": "1.00",
        "count": 30,
        "b64_repr": "Mg0ADAAYCv/vAQAA"
      },
      "After 'aten.erf.default:node_args(1):kwargs()' -> 'aten.add.Tensor:node_args(1):kwargs()' with connection 'in0=SOURCE'": {
        "probability": "1.00",
        "count": 30,
        "b64_repr": "MwoAAAAgCgAMAQAA"
      },
      "After 'aten.softmax.int:node_args(1):kwargs()' -> 'aten.dropout.default:node_args(1):kwargs()' with connection 'in0=SOURCE'": {
        "probability": "1.00",
        "count": 24,
        "b64_repr": "NwoAIgAOCv/yAQAA"
      },
      "After 'aten.permute.default:node_args(1):kwargs()' -> 'aten.clone.default:node_args(1):kwargs('memory_format',)' with connection 'in0=SOURCE'": {
        "probability": "1.00",
        "count": 24,
        "b64_repr": "OAoAMQA5CgAyAQAA"
      },
      "After 'aten.clone.default:node_args(1):kwargs('memory_format',)' -> 'aten.view.default:node_args(1):kwargs()' with connection 'in0=SOURCE'": {
        "probability": "1.00",
        "count": 24,
        "b64_repr": "OQoAMgAXCgAzAQAA"
      },
      "After 'aten.where.self:node_args(3):kwargs()' -> '<PATTERN ID=11>' with connection 'in0=rel_-9,in1=SOURCE,in2=rel_-1'": {
        "probability": "1.00",
        "count": 12,
        "b64_repr": "PgwAAAAGCwAAAQAA"
      },
      "After 'aten.pow.Tensor_Scalar:node_args(1):kwargs()' -> 'aten.mul.Tensor:node_args(1):kwargs()' with connection 'in0=SOURCE'": {
        "probability": "1.00",
        "count": 12,
        "b64_repr": "PwoAFAAlCgA6AQAA"
      }
    },
    "composition_rules": {
      "Composition: Op='aten.add.Tensor:node_args(2):kwargs()', Var=11, Const='None'": {
        "count": 312
      },
      "Composition: Op='aten.layer_norm.default:node_args(3):kwargs()', Var=12, Const='g[12]'": {
        "count": 72
      },
      "Composition: Op='aten.linear.default:node_args(3):kwargs()', Var=12, Const='None'": {
        "count": 911
      },
      "Composition: Op='aten.gelu.default:node_args(1):kwargs()', Var=10, Const='None'": {
        "count": 118
      },
      "Composition: Op='aten.dropout.default:node_args(1):kwargs()', Var=10, Const='g[13]'": {
        "count": 188
      },
      "Composition: Op='aten.expand.default:node_args(1):kwargs()', Var=10, Const='g[10]'": {
        "count": 69
      },
      "Composition: Op='aten._to_copy.default:node_args(1):kwargs('dtype',)', Var=10, Const='c[22]'": {
        "count": 41
      },
      "Composition: Op='aten.view.default:node_args(1):kwargs()', Var=10, Const='c[25]'": {
        "count": 162
      },
      "Composition: Op='aten.transpose.int:node_args(1):kwargs()', Var=10, Const='g[16]'": {
        "count": 540
      },
      "Composition: Op='aten.scaled_dot_product_attention.default:node_args(4):kwargs()', Var=13, Const='None'": {
        "count": 87
      },
      "Composition: Op='aten.view.default:node_args(1):kwargs()', Var=10, Const='c[26]'": {
        "count": 48
      },
      "Composition: Op='aten.add.Tensor:node_args(2):kwargs()', Var=14, Const='None'": {
        "count": 84
      },
      "Composition: Op='aten.type_as.default:node_args(2):kwargs()', Var=11, Const='None'": {
        "count": 33
      },
      "Composition: Op='aten.mul.Tensor:node_args(2):kwargs()', Var=14, Const='None'": {
        "count": 46
      },
      "Composition: Op='aten.add.Tensor:node_args(1):kwargs()', Var=10, Const='c[12]'": {
        "count": 45
      },
      "Composition: Op='aten.layer_norm.default:node_args(3):kwargs()', Var=12, Const='c[37]'": {
        "count": 61
      },
      "Composition: Op='aten.view.default:node_args(1):kwargs()', Var=10, Const='c[38]'": {
        "count": 90
      },
      "Composition: Op='aten.mul.Tensor:node_args(1):kwargs()', Var=10, Const='c[39]'": {
        "count": 30
      },
      "Composition: Op='aten.arange.default:node_args(0):kwargs('device', 'pin_memory')', Var=1, Const='g[20]'": {
        "count": 30
      },
      "Composition: Op='aten.outer.default:node_args(2):kwargs()', Var=11, Const='None'": {
        "count": 30
      },
      "Composition: Op='aten.expand.default:node_args(1):kwargs()', Var=10, Const='g[23]'": {
        "count": 44
      },
      "Composition: Op='aten.expand.default:node_args(1):kwargs()', Var=10, Const='g[22]'": {
        "count": 30
      },
      "Composition: Op='aten.scaled_dot_product_attention.default:node_args(4):kwargs('scale',)', Var=13, Const='c[12]'": {
        "count": 30
      },
      "Composition: Op='aten.view.default:node_args(1):kwargs()', Var=10, Const='c[42]'": {
        "count": 30
      },
      "Composition: Op='aten.dropout.default:node_args(1):kwargs()', Var=10, Const='g[25]'": {
        "count": 146
      },
      "Composition: Op='aten.mul.Tensor:node_args(1):kwargs()', Var=10, Const='c[43]'": {
        "count": 42
      },
      "Composition: Op='aten.div.Tensor:node_args(1):kwargs()', Var=10, Const='c[44]'": {
        "count": 30
      },
      "Composition: Op='aten.erf.default:node_args(1):kwargs()', Var=10, Const='None'": {
        "count": 30
      },
      "Composition: Op='aten.linear.default:node_args(2):kwargs()', Var=11, Const='None'": {
        "count": 39
      },
      "Composition: Op='aten.layer_norm.default:node_args(3):kwargs()', Var=12, Const='g[27]'": {
        "count": 112
      },
      "Composition: Op='aten.view.default:node_args(1):kwargs()', Var=10, Const='c[46]'": {
        "count": 162
      },
      "Composition: Op='aten.transpose.int:node_args(1):kwargs()', Var=10, Const='g[28]'": {
        "count": 24
      },
      "Composition: Op='aten.matmul.default:node_args(2):kwargs()', Var=11, Const='None'": {
        "count": 48
      },
      "Composition: Op='aten.div.Tensor:node_args(1):kwargs()', Var=10, Const='c[48]'": {
        "count": 24
      },
      "Composition: Op='aten.softmax.int:node_args(1):kwargs()', Var=10, Const='c[34]'": {
        "count": 24
      },
      "Composition: Op='aten.permute.default:node_args(1):kwargs()', Var=10, Const='c[49]'": {
        "count": 24
      },
      "Composition: Op='aten.clone.default:node_args(1):kwargs('memory_format',)', Var=10, Const='c[50]'": {
        "count": 24
      },
      "Composition: Op='aten.view.default:node_args(1):kwargs()', Var=10, Const='c[51]'": {
        "count": 54
      },
      "Composition: Op='aten.layer_norm.default:node_args(3):kwargs()', Var=12, Const='c[15]'": {
        "count": 75
      }
    },
    "structural_rules": {
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.dropout.default:node_args(1):kwargs()' (at rel -1), 'aten.layer_norm.default:node_args(3):kwargs()' (at rel -5)]": {
        "count": 91
      },
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.dropout.default:node_args(1):kwargs()' (at rel -1), 'aten.layer_norm.default:node_args(3):kwargs()' (at rel -15)]": {
        "count": 75
      },
      "Node '<PATTERN ID=10>' is formed by inputs from ['aten.mul.Tensor:node_args(1):kwargs()' (at rel -4), 'aten.outer.default:node_args(2):kwargs()' (at rel -1), 'aten.transpose.int:node_args(1):kwargs()' (at rel -8)]": {
        "count": 30
      },
      "Node 'aten.scaled_dot_product_attention.default:node_args(4):kwargs('scale',)' is formed by inputs from ['<PATTERN ID=10>' (at rel -6), 'aten._to_copy.default:node_args(1):kwargs('dtype',)' (at rel -4), 'aten.expand.default:node_args(1):kwargs()' (at rel -1), 'aten.transpose.int:node_args(1):kwargs()' (at rel -11)]": {
        "count": 30
      },
      "Node 'aten.mul.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.add.Tensor:node_args(1):kwargs()' (at rel -1), 'aten.mul.Tensor:node_args(1):kwargs()' (at rel -4)]": {
        "count": 30
      },
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.add.Tensor:node_args(2):kwargs()' (at rel -10), 'aten.dropout.default:node_args(1):kwargs()' (at rel -1)]": {
        "count": 30
      },
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.add.Tensor:node_args(2):kwargs()' (at rel -26), 'aten.dropout.default:node_args(1):kwargs()' (at rel -1)]": {
        "count": 29
      },
      "Node 'aten.matmul.default:node_args(2):kwargs()' is formed by inputs from ['aten.transpose.int:node_args(1):kwargs()' (at rel -8), 'aten.transpose.int:node_args(1):kwargs()' (at rel -1)]": {
        "count": 24
      },
      "Node 'aten.matmul.default:node_args(2):kwargs()' is formed by inputs from ['aten.dropout.default:node_args(1):kwargs()' (at rel -1), 'aten.transpose.int:node_args(1):kwargs()' (at rel -7)]": {
        "count": 24
      },
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.add.Tensor:node_args(2):kwargs()' (at rel -6), 'aten.dropout.default:node_args(1):kwargs()' (at rel -1)]": {
        "count": 24
      },
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.add.Tensor:node_args(2):kwargs()' (at rel -23), 'aten.dropout.default:node_args(1):kwargs()' (at rel -1)]": {
        "count": 23
      },
      "Node '<PATTERN ID=19>' is formed by inputs from ['aten.linear.default:node_args(2):kwargs()' (at rel -3), 'aten.linear.default:node_args(2):kwargs()' (at rel -2), 'aten.linear.default:node_args(2):kwargs()' (at rel -1)]": {
        "count": 12
      },
      "Node 'aten.where.self:node_args(3):kwargs()' is formed by inputs from ['<PATTERN ID=19>' (at rel -7), 'aten.detach.default:node_args(1):kwargs()' (at rel -1), 'aten.expand.default:node_args(1):kwargs()' (at rel -3)]": {
        "count": 12
      },
      "Node '<PATTERN ID=11>' is formed by inputs from ['<PATTERN ID=19>' (at rel -9), 'aten.unsqueeze.default:node_args(1):kwargs()' (at rel -1), 'aten.where.self:node_args(3):kwargs()' (at rel -2)]": {
        "count": 12
      },
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.linear.default:node_args(3):kwargs()' (at rel -4), 'aten.mul.Tensor:node_args(1):kwargs()' (at rel -1)]": {
        "count": 12
      },
      "Node 'aten.mul.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.add.Tensor:node_args(1):kwargs()' (at rel -1), 'aten.mul.Tensor:node_args(1):kwargs()' (at rel -7)]": {
        "count": 12
      },
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.add.Tensor:node_args(2):kwargs()' (at rel -13), 'aten.dropout.default:node_args(1):kwargs()' (at rel -1)]": {
        "count": 12
      },
      "Node 'aten.add.Tensor:node_args(2):kwargs()' is formed by inputs from ['aten.add.Tensor:node_args(2):kwargs()' (at rel -17), 'aten.dropout.default:node_args(1):kwargs()' (at rel -1)]": {
        "count": 11
      }
    }
  }
}
